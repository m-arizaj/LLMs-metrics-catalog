<!doctype html>
<html lang="en" dir="ltr" class="docs-wrapper plugin-docs plugin-id-default docs-version-current docs-doc-page docs-doc-id-metrics/efficiency/energy-metrics" data-has-hydrated="false">
<head>
<meta charset="UTF-8">
<meta name="generator" content="Docusaurus v3.9.1">
<title data-rh="true">Energy &amp; Resource Metrics | LLM Metrics Catalog</title><meta data-rh="true" name="viewport" content="width=device-width,initial-scale=1"><meta data-rh="true" name="twitter:card" content="summary_large_image"><meta data-rh="true" property="og:url" content="https://m-arizaj.github.io/LLMs-metrics-catalog/metrics/efficiency/energy-metrics"><meta data-rh="true" property="og:locale" content="en"><meta data-rh="true" name="docusaurus_locale" content="en"><meta data-rh="true" name="docsearch:language" content="en"><meta data-rh="true" name="docusaurus_version" content="current"><meta data-rh="true" name="docusaurus_tag" content="docs-default-current"><meta data-rh="true" name="docsearch:version" content="current"><meta data-rh="true" name="docsearch:docusaurus_tag" content="docs-default-current"><meta data-rh="true" property="og:title" content="Energy &amp; Resource Metrics | LLM Metrics Catalog"><meta data-rh="true" name="description" content="Introduction"><meta data-rh="true" property="og:description" content="Introduction"><link data-rh="true" rel="canonical" href="https://m-arizaj.github.io/LLMs-metrics-catalog/metrics/efficiency/energy-metrics"><link data-rh="true" rel="alternate" href="https://m-arizaj.github.io/LLMs-metrics-catalog/metrics/efficiency/energy-metrics" hreflang="en"><link data-rh="true" rel="alternate" href="https://m-arizaj.github.io/LLMs-metrics-catalog/metrics/efficiency/energy-metrics" hreflang="x-default"><link rel="stylesheet" href="/LLMs-metrics-catalog/assets/css/styles.422c2d42.css">
<script src="/LLMs-metrics-catalog/assets/js/runtime~main.686142be.js" defer="defer"></script>
<script src="/LLMs-metrics-catalog/assets/js/main.8f919ca9.js" defer="defer"></script>
</head>
<body class="navigation-with-keyboard">
<svg style="display: none;"><defs>
<symbol id="theme-svg-external-link" viewBox="0 0 24 24"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"/></symbol>
</defs></svg>
<script>!function(){var t=function(){try{return new URLSearchParams(window.location.search).get("docusaurus-theme")}catch(t){}}()||function(){try{return window.localStorage.getItem("theme")}catch(t){}}();document.documentElement.setAttribute("data-theme",t||"light"),document.documentElement.setAttribute("data-theme-choice",t||"light")}(),function(){try{const c=new URLSearchParams(window.location.search).entries();for(var[t,e]of c)if(t.startsWith("docusaurus-data-")){var a=t.replace("docusaurus-data-","data-");document.documentElement.setAttribute(a,e)}}catch(t){}}()</script><div id="__docusaurus"><div role="region" aria-label="Skip to main content"><a class="skipToContent_fXgn" href="#__docusaurus_skipToContent_fallback">Skip to main content</a></div><nav aria-label="Main" class="theme-layout-navbar navbar navbar--fixed-top"><div class="navbar__inner"><div class="theme-layout-navbar-left navbar__items"><a class="navbar__brand" href="/LLMs-metrics-catalog/"></a></div><div class="theme-layout-navbar-right navbar__items navbar__items--right"><div class="toggle_vylO colorModeToggle_DEke"><button class="clean-btn toggleButton_gllP toggleButtonDisabled_aARS" type="button" disabled="" title="system mode" aria-label="Switch between dark and light mode (currently system mode)"><svg viewBox="0 0 24 24" width="24" height="24" aria-hidden="true" class="toggleIcon_g3eP lightToggleIcon_pyhR"><path fill="currentColor" d="M12,9c1.65,0,3,1.35,3,3s-1.35,3-3,3s-3-1.35-3-3S10.35,9,12,9 M12,7c-2.76,0-5,2.24-5,5s2.24,5,5,5s5-2.24,5-5 S14.76,7,12,7L12,7z M2,13l2,0c0.55,0,1-0.45,1-1s-0.45-1-1-1l-2,0c-0.55,0-1,0.45-1,1S1.45,13,2,13z M20,13l2,0c0.55,0,1-0.45,1-1 s-0.45-1-1-1l-2,0c-0.55,0-1,0.45-1,1S19.45,13,20,13z M11,2v2c0,0.55,0.45,1,1,1s1-0.45,1-1V2c0-0.55-0.45-1-1-1S11,1.45,11,2z M11,20v2c0,0.55,0.45,1,1,1s1-0.45,1-1v-2c0-0.55-0.45-1-1-1C11.45,19,11,19.45,11,20z M5.99,4.58c-0.39-0.39-1.03-0.39-1.41,0 c-0.39,0.39-0.39,1.03,0,1.41l1.06,1.06c0.39,0.39,1.03,0.39,1.41,0s0.39-1.03,0-1.41L5.99,4.58z M18.36,16.95 c-0.39-0.39-1.03-0.39-1.41,0c-0.39,0.39-0.39,1.03,0,1.41l1.06,1.06c0.39,0.39,1.03,0.39,1.41,0c0.39-0.39,0.39-1.03,0-1.41 L18.36,16.95z M19.42,5.99c0.39-0.39,0.39-1.03,0-1.41c-0.39-0.39-1.03-0.39-1.41,0l-1.06,1.06c-0.39,0.39-0.39,1.03,0,1.41 s1.03,0.39,1.41,0L19.42,5.99z M7.05,18.36c0.39-0.39,0.39-1.03,0-1.41c-0.39-0.39-1.03-0.39-1.41,0l-1.06,1.06 c-0.39,0.39-0.39,1.03,0,1.41s1.03,0.39,1.41,0L7.05,18.36z"></path></svg><svg viewBox="0 0 24 24" width="24" height="24" aria-hidden="true" class="toggleIcon_g3eP darkToggleIcon_wfgR"><path fill="currentColor" d="M9.37,5.51C9.19,6.15,9.1,6.82,9.1,7.5c0,4.08,3.32,7.4,7.4,7.4c0.68,0,1.35-0.09,1.99-0.27C17.45,17.19,14.93,19,12,19 c-3.86,0-7-3.14-7-7C5,9.07,6.81,6.55,9.37,5.51z M12,3c-4.97,0-9,4.03-9,9s4.03,9,9,9s9-4.03,9-9c0-0.46-0.04-0.92-0.1-1.36 c-0.98,1.37-2.58,2.26-4.4,2.26c-2.98,0-5.4-2.42-5.4-5.4c0-1.81,0.89-3.42,2.26-4.4C12.92,3.04,12.46,3,12,3L12,3z"></path></svg><svg viewBox="0 0 24 24" width="24" height="24" aria-hidden="true" class="toggleIcon_g3eP systemToggleIcon_QzmC"><path fill="currentColor" d="m12 21c4.971 0 9-4.029 9-9s-4.029-9-9-9-9 4.029-9 9 4.029 9 9 9zm4.95-13.95c1.313 1.313 2.05 3.093 2.05 4.95s-0.738 3.637-2.05 4.95c-1.313 1.313-3.093 2.05-4.95 2.05v-14c1.857 0 3.637 0.737 4.95 2.05z"></path></svg></button></div><div class="navbarSearchContainer_Bca1"><div class="navbar__search searchBarContainer_NW3z" dir="ltr"><input placeholder="Search" aria-label="Search" class="navbar__search-input searchInput_YFbd" value=""><div class="loadingRing_RJI3 searchBarLoadingRing_YnHq"><div></div><div></div><div></div><div></div></div></div></div></div></div><div role="presentation" class="navbar-sidebar__backdrop"></div></nav><div id="__docusaurus_skipToContent_fallback" class="theme-layout-main main-wrapper mainWrapper_z2l0"><div class="docsWrapper_hBAB"><button aria-label="Scroll back to top" class="clean-btn theme-back-to-top-button backToTopButton_sjWU" type="button"></button><div class="docRoot_UBD9"><main class="docMainContainer_TBSr docMainContainerEnhanced_lQrH"><div class="container padding-top--md padding-bottom--lg"><div class="row"><div class="col docItemCol_VOVn"><div class="docItemContainer_Djhp"><article><div class="tocCollapsible_ETCw theme-doc-toc-mobile tocMobile_ITEo"><button type="button" class="clean-btn tocCollapsibleButton_TO0P">On this page</button></div><div class="theme-doc-markdown markdown"><header><h1>Energy &amp; Resource Metrics</h1></header><h2 class="anchor anchorWithStickyNavbar_LWe7" id="introduction">Introduction<a href="#introduction" class="hash-link" aria-label="Direct link to Introduction" title="Direct link to Introduction" translate="no">​</a></h2>
<p>This group of metrics evaluates the <strong>Efficiency</strong> and <strong>Sustainability</strong> of Large Language Models (LLMs). As LLMs grow in scale, their &quot;large parameter scale... necessitates substantial computational resources,&quot; leading to significant overhead. These metrics are not focused on task correctness, but rather on quantifying the computational, time, and energy costs required for training and inference.</p>
<p>This category includes broad dimensions like <strong>Resource Consumption</strong> , specific benchmark metrics like <strong>Energy Consumption</strong> , and holistic categories like <strong>Efficiency</strong> from the HELM benchmark.</p>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="1-resource-consumption-general-category">1. Resource Consumption (General Category)<a href="#1-resource-consumption-general-category" class="hash-link" aria-label="Direct link to 1. Resource Consumption (General Category)" title="Direct link to 1. Resource Consumption (General Category)" translate="no">​</a></h2>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="definition">Definition<a href="#definition" class="hash-link" aria-label="Direct link to Definition" title="Direct link to Definition" translate="no">​</a></h3>
<p><strong>Resource Consumption</strong> (or &quot;Resource overhead&quot;) is a comprehensive evaluation dimension that assesses the high demands of LLMs. This category is broken down into three key components:</p>
<ul>
<li><strong>Computational Power Consumption:</strong> The &quot;high demands for computing power and storage resources&quot; required for training and inference.</li>
<li><strong>Time Consumption:</strong> The &quot;extensive training time&quot; (weeks or months) and &quot;multiple rounds of parameter tuning&quot; required.</li>
<li><strong>Energy Consumption:</strong> The &quot;significant overhead&quot; from &quot;electricity cost,&quot; as high-performance devices &quot;consume substantial amounts of electricity&quot; and require cooling systems.</li>
</ul>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="purpose">Purpose<a href="#purpose" class="hash-link" aria-label="Direct link to Purpose" title="Direct link to Purpose" translate="no">​</a></h3>
<p>The purpose of evaluating this dimension is to &quot;optimize model efficiency, reduce resource consumption, and improve application efficiency&quot;.</p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="applications">Applications<a href="#applications" class="hash-link" aria-label="Direct link to Applications" title="Direct link to Applications" translate="no">​</a></h3>
<ul>
<li>Used as a high-level dimension for the &quot;comprehensive evaluation of large language models&quot;.</li>
<li>Assesses the overall training and inference &quot;resource overheads&quot;.</li>
</ul>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="2-efficiency-helm-benchmark-category">2. Efficiency (HELM Benchmark Category)<a href="#2-efficiency-helm-benchmark-category" class="hash-link" aria-label="Direct link to 2. Efficiency (HELM Benchmark Category)" title="Direct link to 2. Efficiency (HELM Benchmark Category)" translate="no">​</a></h2>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="definition-1">Definition<a href="#definition-1" class="hash-link" aria-label="Direct link to Definition" title="Direct link to Definition" translate="no">​</a></h3>
<p><strong>Efficiency</strong> is one of the seven top-level metrics in the <strong>HELM (Holistic Evaluation of Language Models)</strong> benchmark .</p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="purpose-1">Purpose<a href="#purpose-1" class="hash-link" aria-label="Direct link to Purpose" title="Direct link to Purpose" translate="no">​</a></h3>
<p>It is used to provide a &quot;holistic evaluation&quot; of model efficiency by measuring several practical proxies for computational cost .</p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="applications-1">Applications<a href="#applications-1" class="hash-link" aria-label="Direct link to Applications" title="Direct link to Applications" translate="no">​</a></h3>
<p>HELM specifically measures this category using the following sub-metrics:</p>
<ul>
<li><strong>Training Time:</strong> The time required to train the model on a proxy task .</li>
<li><strong>Inference Time:</strong> The time required to process prompts and generate outputs .</li>
<li><strong>Number of Parameters:</strong> The size of the model .</li>
</ul>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="3-energy-consumption-mercury-benchmark">3. Energy Consumption (Mercury Benchmark)<a href="#3-energy-consumption-mercury-benchmark" class="hash-link" aria-label="Direct link to 3. Energy Consumption (Mercury Benchmark)" title="Direct link to 3. Energy Consumption (Mercury Benchmark)" translate="no">​</a></h2>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="definition-2">Definition<a href="#definition-2" class="hash-link" aria-label="Direct link to Definition" title="Direct link to Definition" translate="no">​</a></h3>
<p><strong>Energy Consumption</strong> is a specific metric used within the <strong>Mercury</strong> benchmark , which is &quot;designed to assess the efficiency of code generated by Large Language Models&quot; .</p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="purpose-2">Purpose<a href="#purpose-2" class="hash-link" aria-label="Direct link to Purpose" title="Direct link to Purpose" translate="no">​</a></h3>
<p>This metric provides a direct, quantitative measure of the sustainability and efficiency of an LLM&#x27;s <em>generated code</em>, rather than the LLM itself.</p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="applications-2">Applications<a href="#applications-2" class="hash-link" aria-label="Direct link to Applications" title="Direct link to Applications" translate="no">​</a></h3>
<ul>
<li>The metric is measured by running the LLM-generated code using &quot;preset test cases... in a fixed hardware environment&quot; and &quot;recording execution time, memory usage, and <strong>energy consumption</strong>&quot; .</li>
</ul>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="4-comparative-summary">4. Comparative Summary<a href="#4-comparative-summary" class="hash-link" aria-label="Direct link to 4. Comparative Summary" title="Direct link to 4. Comparative Summary" translate="no">​</a></h2>
<table><thead><tr><th style="text-align:left">Metric</th><th style="text-align:left">Domain</th><th style="text-align:left">Scope</th><th style="text-align:left">Measured Components</th></tr></thead><tbody><tr><td style="text-align:left"><strong>Resource Consumption</strong></td><td style="text-align:left">General LLM Evaluation</td><td style="text-align:left">Model (Training &amp; Inference)</td><td style="text-align:left">Power, Time, and Energy (as a general dimension)</td></tr><tr><td style="text-align:left"><strong>Efficiency (HELM)</strong></td><td style="text-align:left">General LLM Evaluation</td><td style="text-align:left">Model (Training &amp; Inference)</td><td style="text-align:left">Training Time, Inference Time, # of Parameters</td></tr><tr><td style="text-align:left"><strong>Energy Consumption (Mercury)</strong></td><td style="text-align:left">Code Generation</td><td style="text-align:left">Generated Code (Runtime)</td><td style="text-align:left">Energy consumed by the output code during execution</td></tr></tbody></table>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="references">References<a href="#references" class="hash-link" aria-label="Direct link to References" title="Direct link to References" translate="no">​</a></h2>
<ul>
<li>
<p>L. Lin, D. Zhu and J. Shang, &quot;Overview of the Comprehensive Evaluation of Large Language Models,&quot; 2024 IEEE Smart World Congress (SWC), Nadi, Fiji, 2024, pp. 1504-1512, doi: 10.1109/SWC62898.2024.00231.</p>
</li>
<li>
<p>Liang, P., Bommasani, R., Lee, T., Tsipras, D., Soylu, D., Yasunaga, M., ... &amp; Ré, C. (2022). <em>Holistic Evaluation of Language Models</em>.<a href="https://doi.org/10.48550/arXiv.2211.09110" target="_blank" rel="noopener noreferrer">https://doi.org/10.48550/arXiv.2211.09110</a></p>
</li>
<li>
<p>Chen, L., Guo, Q., Jia, H., Zeng, Z., Wang, X., Xu, Y., ... &amp; Zhang, S. (2024). <em>A Survey on Evaluating Large Language Models in Code Generation Tasks</em>. doi: <a href="https://doi.org/10.48550/arXiv.2408.16498" target="_blank" rel="noopener noreferrer">https://doi.org/10.48550/arXiv.2408.16498</a>.</p>
</li>
</ul>
<p>Chang, Y., et al. (2023). A survey on evaluation of large language models (arXiv:2307.03109). arXiv. <a href="https://doi.org/10.48550/arXiv.2307.03109" target="_blank" rel="noopener noreferrer">https://doi.org/10.48550/arXiv.2307.03109</a></p></div></article><nav class="docusaurus-mt-lg pagination-nav" aria-label="Docs pages"></nav></div></div><div class="col col--3"><div class="tableOfContents_bqdL thin-scrollbar theme-doc-toc-desktop"><ul class="table-of-contents table-of-contents__left-border"><li><a href="#introduction" class="table-of-contents__link toc-highlight">Introduction</a></li><li><a href="#1-resource-consumption-general-category" class="table-of-contents__link toc-highlight">1. Resource Consumption (General Category)</a><ul><li><a href="#definition" class="table-of-contents__link toc-highlight">Definition</a></li><li><a href="#purpose" class="table-of-contents__link toc-highlight">Purpose</a></li><li><a href="#applications" class="table-of-contents__link toc-highlight">Applications</a></li></ul></li><li><a href="#2-efficiency-helm-benchmark-category" class="table-of-contents__link toc-highlight">2. Efficiency (HELM Benchmark Category)</a><ul><li><a href="#definition-1" class="table-of-contents__link toc-highlight">Definition</a></li><li><a href="#purpose-1" class="table-of-contents__link toc-highlight">Purpose</a></li><li><a href="#applications-1" class="table-of-contents__link toc-highlight">Applications</a></li></ul></li><li><a href="#3-energy-consumption-mercury-benchmark" class="table-of-contents__link toc-highlight">3. Energy Consumption (Mercury Benchmark)</a><ul><li><a href="#definition-2" class="table-of-contents__link toc-highlight">Definition</a></li><li><a href="#purpose-2" class="table-of-contents__link toc-highlight">Purpose</a></li><li><a href="#applications-2" class="table-of-contents__link toc-highlight">Applications</a></li></ul></li><li><a href="#4-comparative-summary" class="table-of-contents__link toc-highlight">4. Comparative Summary</a></li><li><a href="#references" class="table-of-contents__link toc-highlight">References</a></li></ul></div></div></div></div></main></div></div></div></div>
</body>
</html>