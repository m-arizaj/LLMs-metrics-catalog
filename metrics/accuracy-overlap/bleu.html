<!doctype html>
<html lang="en" dir="ltr" class="docs-wrapper plugin-docs plugin-id-default docs-version-current docs-doc-page docs-doc-id-metrics/accuracy-overlap/bleu" data-has-hydrated="false">
<head>
<meta charset="UTF-8">
<meta name="generator" content="Docusaurus v3.9.1">
<title data-rh="true">BLEU | LLM Metrics Catalog</title><meta data-rh="true" name="viewport" content="width=device-width,initial-scale=1"><meta data-rh="true" name="twitter:card" content="summary_large_image"><meta data-rh="true" property="og:url" content="https://m-arizaj.github.io/LLMs-metrics-catalog/metrics/accuracy-overlap/bleu"><meta data-rh="true" property="og:locale" content="en"><meta data-rh="true" name="docusaurus_locale" content="en"><meta data-rh="true" name="docsearch:language" content="en"><meta data-rh="true" name="docusaurus_version" content="current"><meta data-rh="true" name="docusaurus_tag" content="docs-default-current"><meta data-rh="true" name="docsearch:version" content="current"><meta data-rh="true" name="docsearch:docusaurus_tag" content="docs-default-current"><meta data-rh="true" property="og:title" content="BLEU | LLM Metrics Catalog"><meta data-rh="true" name="description" content="Introduction"><meta data-rh="true" property="og:description" content="Introduction"><link data-rh="true" rel="canonical" href="https://m-arizaj.github.io/LLMs-metrics-catalog/metrics/accuracy-overlap/bleu"><link data-rh="true" rel="alternate" href="https://m-arizaj.github.io/LLMs-metrics-catalog/metrics/accuracy-overlap/bleu" hreflang="en"><link data-rh="true" rel="alternate" href="https://m-arizaj.github.io/LLMs-metrics-catalog/metrics/accuracy-overlap/bleu" hreflang="x-default"><script data-rh="true" type="application/ld+json">{"@context":"https://schema.org","@type":"BreadcrumbList","itemListElement":[{"@type":"ListItem","position":1,"name":"BLEU","item":"https://m-arizaj.github.io/LLMs-metrics-catalog/metrics/accuracy-overlap/bleu"}]}</script><link rel="stylesheet" href="/LLMs-metrics-catalog/assets/css/styles.422c2d42.css">
<script src="/LLMs-metrics-catalog/assets/js/runtime~main.b6a28dad.js" defer="defer"></script>
<script src="/LLMs-metrics-catalog/assets/js/main.7f8e1222.js" defer="defer"></script>
</head>
<body class="navigation-with-keyboard">
<svg style="display: none;"><defs>
<symbol id="theme-svg-external-link" viewBox="0 0 24 24"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"/></symbol>
</defs></svg>
<script>!function(){var t=function(){try{return new URLSearchParams(window.location.search).get("docusaurus-theme")}catch(t){}}()||function(){try{return window.localStorage.getItem("theme")}catch(t){}}();document.documentElement.setAttribute("data-theme",t||"light"),document.documentElement.setAttribute("data-theme-choice",t||"light")}(),function(){try{const c=new URLSearchParams(window.location.search).entries();for(var[t,e]of c)if(t.startsWith("docusaurus-data-")){var a=t.replace("docusaurus-data-","data-");document.documentElement.setAttribute(a,e)}}catch(t){}}()</script><div id="__docusaurus"><div role="region" aria-label="Skip to main content"><a class="skipToContent_fXgn" href="#__docusaurus_skipToContent_fallback">Skip to main content</a></div><nav aria-label="Main" class="theme-layout-navbar navbar navbar--fixed-top"><div class="navbar__inner"><div class="theme-layout-navbar-left navbar__items"><a class="navbar__brand" href="/LLMs-metrics-catalog/"></a></div><div class="theme-layout-navbar-right navbar__items navbar__items--right"><div class="toggle_vylO colorModeToggle_DEke"><button class="clean-btn toggleButton_gllP toggleButtonDisabled_aARS" type="button" disabled="" title="system mode" aria-label="Switch between dark and light mode (currently system mode)"><svg viewBox="0 0 24 24" width="24" height="24" aria-hidden="true" class="toggleIcon_g3eP lightToggleIcon_pyhR"><path fill="currentColor" d="M12,9c1.65,0,3,1.35,3,3s-1.35,3-3,3s-3-1.35-3-3S10.35,9,12,9 M12,7c-2.76,0-5,2.24-5,5s2.24,5,5,5s5-2.24,5-5 S14.76,7,12,7L12,7z M2,13l2,0c0.55,0,1-0.45,1-1s-0.45-1-1-1l-2,0c-0.55,0-1,0.45-1,1S1.45,13,2,13z M20,13l2,0c0.55,0,1-0.45,1-1 s-0.45-1-1-1l-2,0c-0.55,0-1,0.45-1,1S19.45,13,20,13z M11,2v2c0,0.55,0.45,1,1,1s1-0.45,1-1V2c0-0.55-0.45-1-1-1S11,1.45,11,2z M11,20v2c0,0.55,0.45,1,1,1s1-0.45,1-1v-2c0-0.55-0.45-1-1-1C11.45,19,11,19.45,11,20z M5.99,4.58c-0.39-0.39-1.03-0.39-1.41,0 c-0.39,0.39-0.39,1.03,0,1.41l1.06,1.06c0.39,0.39,1.03,0.39,1.41,0s0.39-1.03,0-1.41L5.99,4.58z M18.36,16.95 c-0.39-0.39-1.03-0.39-1.41,0c-0.39,0.39-0.39,1.03,0,1.41l1.06,1.06c0.39,0.39,1.03,0.39,1.41,0c0.39-0.39,0.39-1.03,0-1.41 L18.36,16.95z M19.42,5.99c0.39-0.39,0.39-1.03,0-1.41c-0.39-0.39-1.03-0.39-1.41,0l-1.06,1.06c-0.39,0.39-0.39,1.03,0,1.41 s1.03,0.39,1.41,0L19.42,5.99z M7.05,18.36c0.39-0.39,0.39-1.03,0-1.41c-0.39-0.39-1.03-0.39-1.41,0l-1.06,1.06 c-0.39,0.39-0.39,1.03,0,1.41s1.03,0.39,1.41,0L7.05,18.36z"></path></svg><svg viewBox="0 0 24 24" width="24" height="24" aria-hidden="true" class="toggleIcon_g3eP darkToggleIcon_wfgR"><path fill="currentColor" d="M9.37,5.51C9.19,6.15,9.1,6.82,9.1,7.5c0,4.08,3.32,7.4,7.4,7.4c0.68,0,1.35-0.09,1.99-0.27C17.45,17.19,14.93,19,12,19 c-3.86,0-7-3.14-7-7C5,9.07,6.81,6.55,9.37,5.51z M12,3c-4.97,0-9,4.03-9,9s4.03,9,9,9s9-4.03,9-9c0-0.46-0.04-0.92-0.1-1.36 c-0.98,1.37-2.58,2.26-4.4,2.26c-2.98,0-5.4-2.42-5.4-5.4c0-1.81,0.89-3.42,2.26-4.4C12.92,3.04,12.46,3,12,3L12,3z"></path></svg><svg viewBox="0 0 24 24" width="24" height="24" aria-hidden="true" class="toggleIcon_g3eP systemToggleIcon_QzmC"><path fill="currentColor" d="m12 21c4.971 0 9-4.029 9-9s-4.029-9-9-9-9 4.029-9 9 4.029 9 9 9zm4.95-13.95c1.313 1.313 2.05 3.093 2.05 4.95s-0.738 3.637-2.05 4.95c-1.313 1.313-3.093 2.05-4.95 2.05v-14c1.857 0 3.637 0.737 4.95 2.05z"></path></svg></button></div><div class="navbarSearchContainer_Bca1"><div class="navbar__search searchBarContainer_NW3z" dir="ltr"><input placeholder="Search" aria-label="Search" class="navbar__search-input searchInput_YFbd" value=""><div class="loadingRing_RJI3 searchBarLoadingRing_YnHq"><div></div><div></div><div></div><div></div></div></div></div></div></div><div role="presentation" class="navbar-sidebar__backdrop"></div></nav><div id="__docusaurus_skipToContent_fallback" class="theme-layout-main main-wrapper mainWrapper_z2l0"><div class="docsWrapper_hBAB"><button aria-label="Scroll back to top" class="clean-btn theme-back-to-top-button backToTopButton_sjWU" type="button"></button><div class="docRoot_UBD9"><aside class="theme-doc-sidebar-container docSidebarContainer_YfHR"><div class="sidebarViewport_aRkj"><div class="sidebar_njMd"><nav aria-label="Docs sidebar" class="menu thin-scrollbar menu_SIkG"><ul class="theme-doc-sidebar-menu menu__list"><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-1 menu__list-item"><a class="menu__link" href="/LLMs-metrics-catalog/intro"><span title="Introduction" class="linkLabel_WmDU">Introduction</span></a></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist menu__link--sublist-caret menu__link--active" role="button" aria-expanded="true" href="/LLMs-metrics-catalog/metrics/accuracy-overlap/bleu"><span title="Core Accuracy &amp; Overlap Metrics" class="categoryLinkLabel_W154">Core Accuracy &amp; Overlap Metrics</span></a></div><ul class="menu__list"><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link menu__link--active" aria-current="page" tabindex="0" href="/LLMs-metrics-catalog/metrics/accuracy-overlap/bleu"><span title="BLEU" class="linkLabel_WmDU">BLEU</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/LLMs-metrics-catalog/metrics/accuracy-overlap/accuracy"><span title="Accuracy" class="linkLabel_WmDU">Accuracy</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/LLMs-metrics-catalog/metrics/accuracy-overlap/pass-at-k"><span title="Pass@k" class="linkLabel_WmDU">Pass@k</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/LLMs-metrics-catalog/metrics/accuracy-overlap/f1-score"><span title="F1-Score" class="linkLabel_WmDU">F1-Score</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/LLMs-metrics-catalog/metrics/accuracy-overlap/exact-match"><span title="Exact Match" class="linkLabel_WmDU">Exact Match</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/LLMs-metrics-catalog/metrics/accuracy-overlap/rouge"><span title="ROUGE" class="linkLabel_WmDU">ROUGE</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/LLMs-metrics-catalog/metrics/accuracy-overlap/recall"><span title="Recall" class="linkLabel_WmDU">Recall</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/LLMs-metrics-catalog/metrics/accuracy-overlap/precision"><span title="Precision" class="linkLabel_WmDU">Precision</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/LLMs-metrics-catalog/metrics/accuracy-overlap/meteor"><span title="Meteor" class="linkLabel_WmDU">Meteor</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/LLMs-metrics-catalog/metrics/accuracy-overlap/edit-distance"><span title="Edit Distance" class="linkLabel_WmDU">Edit Distance</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/LLMs-metrics-catalog/metrics/accuracy-overlap/mrr"><span title="Mean Reciprocal Rank" class="linkLabel_WmDU">Mean Reciprocal Rank</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/LLMs-metrics-catalog/metrics/accuracy-overlap/swe"><span title="SWE-Judge Score" class="linkLabel_WmDU">SWE-Judge Score</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/LLMs-metrics-catalog/metrics/accuracy-overlap/bertscore"><span title="BERTScore" class="linkLabel_WmDU">BERTScore</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/LLMs-metrics-catalog/metrics/accuracy-overlap/coverage"><span title="Coverage" class="linkLabel_WmDU">Coverage</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/LLMs-metrics-catalog/metrics/accuracy-overlap/chrf"><span title="chrF" class="linkLabel_WmDU">chrF</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/LLMs-metrics-catalog/metrics/accuracy-overlap/codescore"><span title="CodeScore" class="linkLabel_WmDU">CodeScore</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/LLMs-metrics-catalog/metrics/accuracy-overlap/moverscore"><span title="MoverScore" class="linkLabel_WmDU">MoverScore</span></a></li></ul></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist menu__link--sublist-caret" role="button" aria-expanded="true" href="/LLMs-metrics-catalog/metrics/statistical/ice-score"><span title="Statistical &amp; Correlation Metrics" class="categoryLinkLabel_W154">Statistical &amp; Correlation Metrics</span></a></div><ul class="menu__list"><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/LLMs-metrics-catalog/metrics/statistical/ice-score"><span title="ICE-Score" class="linkLabel_WmDU">ICE-Score</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/LLMs-metrics-catalog/metrics/statistical/kendall"><span title="Kendall’s τ" class="linkLabel_WmDU">Kendall’s τ</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/LLMs-metrics-catalog/metrics/statistical/spearman"><span title="Spearman’s ρ" class="linkLabel_WmDU">Spearman’s ρ</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/LLMs-metrics-catalog/metrics/statistical/pearson"><span title="Pearson’s r" class="linkLabel_WmDU">Pearson’s r</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/LLMs-metrics-catalog/metrics/statistical/cohen"><span title="Cohen&#x27;s Score" class="linkLabel_WmDU">Cohen&#x27;s Score</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/LLMs-metrics-catalog/metrics/statistical/smape"><span title="Smape" class="linkLabel_WmDU">Smape</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/LLMs-metrics-catalog/metrics/statistical/rate"><span title="Rate Metrics" class="linkLabel_WmDU">Rate Metrics</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/LLMs-metrics-catalog/metrics/statistical/average"><span title="Average Metrics" class="linkLabel_WmDU">Average Metrics</span></a></li></ul></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist menu__link--sublist-caret" role="button" aria-expanded="true" href="/LLMs-metrics-catalog/metrics/code-structural/ast-metrics"><span title="Code Quality &amp; Structural Metrics" class="categoryLinkLabel_W154">Code Quality &amp; Structural Metrics</span></a></div><ul class="menu__list"><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/LLMs-metrics-catalog/metrics/code-structural/ast-metrics"><span title="AST Metrics" class="linkLabel_WmDU">AST Metrics</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/LLMs-metrics-catalog/metrics/code-structural/edition-metrics"><span title="Edition Metrics" class="linkLabel_WmDU">Edition Metrics</span></a></li></ul></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist menu__link--sublist-caret" role="button" aria-expanded="true" href="/LLMs-metrics-catalog/metrics/functional-test/error"><span title="Functional &amp; Test-based Evaluation" class="categoryLinkLabel_W154">Functional &amp; Test-based Evaluation</span></a></div><ul class="menu__list"><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/LLMs-metrics-catalog/metrics/functional-test/error"><span title="Error Metrics" class="linkLabel_WmDU">Error Metrics</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/LLMs-metrics-catalog/metrics/functional-test/percentage"><span title="Percentage Metrics" class="linkLabel_WmDU">Percentage Metrics</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/LLMs-metrics-catalog/metrics/functional-test/number"><span title="Number Metrics" class="linkLabel_WmDU">Number Metrics</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/LLMs-metrics-catalog/metrics/functional-test/test"><span title="Test Metrics" class="linkLabel_WmDU">Test Metrics</span></a></li></ul></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist menu__link--sublist-caret" role="button" aria-expanded="false" href="/LLMs-metrics-catalog/metrics/human"><span title="Human &amp; Subjective Evaluation" class="categoryLinkLabel_W154">Human &amp; Subjective Evaluation</span></a></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist menu__link--sublist-caret" role="button" aria-expanded="false" href="/LLMs-metrics-catalog/metrics/generative/amber-score"><span title="Generative &amp; Distribution Metrics" class="categoryLinkLabel_W154">Generative &amp; Distribution Metrics</span></a></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist menu__link--sublist-caret" role="button" aria-expanded="false" href="/LLMs-metrics-catalog/metrics/logical/cog-metric"><span title="Logical Reasoning &amp; Verification" class="categoryLinkLabel_W154">Logical Reasoning &amp; Verification</span></a></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist menu__link--sublist-caret" role="button" aria-expanded="false" href="/LLMs-metrics-catalog/metrics/robustness/ct-score"><span title="Robustness, Security &amp; Reliability" class="categoryLinkLabel_W154">Robustness, Security &amp; Reliability</span></a></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist menu__link--sublist-caret" role="button" aria-expanded="false" href="/LLMs-metrics-catalog/metrics/efficiency/time"><span title="Efficiency &amp; Resource Usage" class="categoryLinkLabel_W154">Efficiency &amp; Resource Usage</span></a></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist menu__link--sublist-caret" role="button" aria-expanded="false" href="/LLMs-metrics-catalog/metrics/architectural/composite"><span title="Architectural &amp; System-level Metrics" class="categoryLinkLabel_W154">Architectural &amp; System-level Metrics</span></a></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist menu__link--sublist-caret" role="button" aria-expanded="false" href="/LLMs-metrics-catalog/metrics/creativity/dialogue-similarities"><span title="Creativity, Diversity &amp; Novelty" class="categoryLinkLabel_W154">Creativity, Diversity &amp; Novelty</span></a></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist menu__link--sublist-caret" role="button" aria-expanded="false" href="/LLMs-metrics-catalog/metrics/ranking/elo-score"><span title="Ranking, Reward &amp; Optimization" class="categoryLinkLabel_W154">Ranking, Reward &amp; Optimization</span></a></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist menu__link--sublist-caret" role="button" aria-expanded="false" href="/LLMs-metrics-catalog/metrics/semantic/hallucination"><span title="Semantic, Coherence &amp; Hallucination" class="categoryLinkLabel_W154">Semantic, Coherence &amp; Hallucination</span></a></div></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-1 menu__list-item"><a class="menu__link" href="/LLMs-metrics-catalog/references"><span title="References" class="linkLabel_WmDU">References</span></a></li></ul></nav></div></div></aside><main class="docMainContainer_TBSr"><div class="container padding-top--md padding-bottom--lg"><div class="row"><div class="col docItemCol_VOVn"><div class="docItemContainer_Djhp"><article><nav class="theme-doc-breadcrumbs breadcrumbsContainer_Z_bl" aria-label="Breadcrumbs"><ul class="breadcrumbs"><li class="breadcrumbs__item"><a aria-label="Home page" class="breadcrumbs__link" href="/LLMs-metrics-catalog/"><svg viewBox="0 0 24 24" class="breadcrumbHomeIcon_YNFT"><path d="M10 19v-5h4v5c0 .55.45 1 1 1h3c.55 0 1-.45 1-1v-7h1.7c.46 0 .68-.57.33-.87L12.67 3.6c-.38-.34-.96-.34-1.34 0l-8.36 7.53c-.34.3-.13.87.33.87H5v7c0 .55.45 1 1 1h3c.55 0 1-.45 1-1z" fill="currentColor"></path></svg></a></li><li class="breadcrumbs__item"><span class="breadcrumbs__link">Core Accuracy &amp; Overlap Metrics</span></li><li class="breadcrumbs__item breadcrumbs__item--active"><span class="breadcrumbs__link">BLEU</span></li></ul></nav><div class="tocCollapsible_ETCw theme-doc-toc-mobile tocMobile_ITEo"><button type="button" class="clean-btn tocCollapsibleButton_TO0P">On this page</button></div><div class="theme-doc-markdown markdown"><header><h1>BLEU</h1></header><h2 class="anchor anchorWithStickyNavbar_LWe7" id="introduction">Introduction<a href="#introduction" class="hash-link" aria-label="Direct link to Introduction" title="Direct link to Introduction" translate="no">​</a></h2>
<p>BLEU (<em>Bilingual Evaluation Understudy</em>) is one of the most influential automatic evaluation metrics in Natural Language Processing (NLP). Introduced by <strong>Papineni et al. (2002)</strong>, it provided a scalable and reproducible way to compare system outputs with human references using <em>n-gram overlap</em> rather than subjective human scoring. Since its publication, BLEU has become a cornerstone for evaluating not only machine translation and text generation, but also code generation and other software engineering tasks as Large Language Models began producing structured, programmatic outputs.<br>
<!-- -->Its core idea, precision over short token sequences, has inspired several specialized variants such as CodeBLEU, CrystalBLEU, Smoothed BLEU, and WeightBLEU, each adapting the metric to better capture syntactic and semantic aspects of specific domains.</p>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="1-bleu-bilingual-evaluation-understudy">1. BLEU (Bilingual Evaluation Understudy)<a href="#1-bleu-bilingual-evaluation-understudy" class="hash-link" aria-label="Direct link to 1. BLEU (Bilingual Evaluation Understudy)" title="Direct link to 1. BLEU (Bilingual Evaluation Understudy)" translate="no">​</a></h2>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="definition">Definition<a href="#definition" class="hash-link" aria-label="Direct link to Definition" title="Direct link to Definition" translate="no">​</a></h3>
<p>BLEU measures the correspondence between a candidate text (or code) and one or more reference texts using modified n-gram precision and a brevity penalty.</p>
<span class="katex"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><mi>B</mi><mi>L</mi><mi>E</mi><mi>U</mi><mo>=</mo><mi>B</mi><mi>P</mi><mo>⋅</mo><mi>exp</mi><mo>⁡</mo><mtext> ⁣</mtext><mrow><mo fence="true">(</mo><munderover><mo>∑</mo><mrow><mi>n</mi><mo>=</mo><mn>1</mn></mrow><mi>N</mi></munderover><msub><mi>w</mi><mi>n</mi></msub><mi>log</mi><mo>⁡</mo><msub><mi>p</mi><mi>n</mi></msub><mo fence="true">)</mo></mrow></mrow><annotation encoding="application/x-tex">BLEU = BP \cdot \exp\!\left(\sum_{n=1}^{N} w_n \log p_n\right)</annotation></semantics></math></span>
<p>where:</p>
<ul>
<li><span class="katex"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>p</mi><mi>n</mi></msub></mrow><annotation encoding="application/x-tex">p_n</annotation></semantics></math></span> = modified precision for n-grams of size n,</li>
<li><span class="katex"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>w</mi><mi>n</mi></msub></mrow><annotation encoding="application/x-tex">w_n</annotation></semantics></math></span> = weight assigned to each n-gram order (commonly 1/N),</li>
<li><span class="katex"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>B</mi><mi>P</mi><mo>=</mo><mi>min</mi><mo>⁡</mo><mo stretchy="false">(</mo><mn>1</mn><mo separator="true">,</mo><msup><mi>e</mi><mrow><mn>1</mn><mo>−</mo><mi>r</mi><mi mathvariant="normal">/</mi><mi>c</mi></mrow></msup><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">BP = \min(1, e^{1 - r/c})</annotation></semantics></math></span> = brevity penalty (r = reference length, c = candidate length).<br>
<em>(Papineni et al., 2002)</em></li>
</ul>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="purpose">Purpose<a href="#purpose" class="hash-link" aria-label="Direct link to Purpose" title="Direct link to Purpose" translate="no">​</a></h3>
<p>Originally designed for machine translation, BLEU became a general benchmark for textual similarity in natural language generation and software engineering, providing a fast and language-independent evaluation method.</p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="applications">Applications<a href="#applications" class="hash-link" aria-label="Direct link to Applications" title="Direct link to Applications" translate="no">​</a></h3>
<p>BLEU appears across multiple contexts:</p>
<ul>
<li>Natural Language Generation and NLP evaluation – fluency and informativeness.</li>
<li>Software Engineering – code generation, summarization, repair, translation, commit message generation, and documentation evaluation.</li>
</ul>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="limitations">Limitations<a href="#limitations" class="hash-link" aria-label="Direct link to Limitations" title="Direct link to Limitations" translate="no">​</a></h3>
<ul>
<li>Focuses on surface overlap rather than semantic or functional accuracy.</li>
<li>Sensitive to tokenization and reference selection.</li>
<li>Requires multiple references for robust human correlation.</li>
</ul>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="2-codebleu">2. CodeBLEU<a href="#2-codebleu" class="hash-link" aria-label="Direct link to 2. CodeBLEU" title="Direct link to 2. CodeBLEU" translate="no">​</a></h2>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="definition-1">Definition<a href="#definition-1" class="hash-link" aria-label="Direct link to Definition" title="Direct link to Definition" translate="no">​</a></h3>
<p><strong>CodeBLEU (Ren et al., 2020)</strong> extends BLEU to software engineering tasks by integrating additional structural and semantic dimensions:</p>
<ol>
<li>Weighted n-gram match – gives higher weight to language keywords.</li>
<li>AST-based structural match – measures syntactic correctness.</li>
<li>Data-flow match – evaluates semantic and logical consistency.</li>
</ol>
<p><span class="katex"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>C</mi><mi>o</mi><mi>d</mi><mi>e</mi><mi>B</mi><mi>L</mi><mi>E</mi><mi>U</mi><mo>=</mo><mi>α</mi><msub><mi>P</mi><mrow><mi>n</mi><mi>g</mi></mrow></msub><mo>+</mo><mi>β</mi><msub><mi>P</mi><mrow><mi>w</mi><mi>n</mi><mi>g</mi></mrow></msub><mo>+</mo><mi>γ</mi><msub><mi>P</mi><mrow><mi>a</mi><mi>s</mi><mi>t</mi></mrow></msub><mo>+</mo><mi>δ</mi><msub><mi>P</mi><mrow><mi>d</mi><mi>f</mi></mrow></msub></mrow><annotation encoding="application/x-tex">CodeBLEU = \alpha P_{ng} + \beta P_{wng} + \gamma P_{ast} + \delta P_{df}</annotation></semantics></math></span></p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="advantages">Advantages<a href="#advantages" class="hash-link" aria-label="Direct link to Advantages" title="Direct link to Advantages" translate="no">​</a></h3>
<ul>
<li>Better correlation with functional correctness in code outputs.</li>
<li>Reduces false positives caused by superficial textual overlap.</li>
</ul>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="use-cases">Use Cases<a href="#use-cases" class="hash-link" aria-label="Direct link to Use Cases" title="Direct link to Use Cases" translate="no">​</a></h3>
<p>Used extensively in code generation, translation, and summarization tasks where syntax and semantics both matter.</p>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="3-crystalbleu">3. CrystalBLEU<a href="#3-crystalbleu" class="hash-link" aria-label="Direct link to 3. CrystalBLEU" title="Direct link to 3. CrystalBLEU" translate="no">​</a></h2>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="definition-2">Definition<a href="#definition-2" class="hash-link" aria-label="Direct link to Definition" title="Direct link to Definition" translate="no">​</a></h3>
<p><strong>CrystalBLEU</strong> (Eghbali &amp; Pradel, 2022) refines BLEU by excluding high-frequency trivial n-grams that appear broadly across programming corpora, reducing score inflation.</p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="advantages-1">Advantages<a href="#advantages-1" class="hash-link" aria-label="Direct link to Advantages" title="Direct link to Advantages" translate="no">​</a></h3>
<ul>
<li>More reliable indicator of semantic similarity in code.</li>
<li>Distinguishes genuine logical equivalence from shared boilerplate.</li>
</ul>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="use-cases-1">Use Cases<a href="#use-cases-1" class="hash-link" aria-label="Direct link to Use Cases" title="Direct link to Use Cases" translate="no">​</a></h3>
<p>Evaluation of model-generated code similarity or variant synthesis.</p>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="4-smoothed-bleu--smoothed-4-gram-bleu">4. Smoothed BLEU / Smoothed 4-gram BLEU<a href="#4-smoothed-bleu--smoothed-4-gram-bleu" class="hash-link" aria-label="Direct link to 4. Smoothed BLEU / Smoothed 4-gram BLEU" title="Direct link to 4. Smoothed BLEU / Smoothed 4-gram BLEU" translate="no">​</a></h2>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="definition-3">Definition<a href="#definition-3" class="hash-link" aria-label="Direct link to Definition" title="Direct link to Definition" translate="no">​</a></h3>
<p>Smoothed BLEU variants modify the computation of higher-order n-gram precision values by adding a small smoothing constant.<br>
<!-- -->This avoids zero scores in short outputs with sparse matches.</p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="use-cases-2">Use Cases<a href="#use-cases-2" class="hash-link" aria-label="Direct link to Use Cases" title="Direct link to Use Cases" translate="no">​</a></h3>
<p>Particularly useful for code summarization, short documentation generation, or low-resource text generation.</p>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="5-weightbleu">5. WeightBLEU<a href="#5-weightbleu" class="hash-link" aria-label="Direct link to 5. WeightBLEU" title="Direct link to 5. WeightBLEU" translate="no">​</a></h2>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="definition-4">Definition<a href="#definition-4" class="hash-link" aria-label="Direct link to Definition" title="Direct link to Definition" translate="no">​</a></h3>
<p>WeightBLEU reweights n-gram or token contributions based on their importance in the task context, such as giving higher priority to syntax or control-flow keywords in code.<br>
<!-- -->It preserves the BLEU formulation but adapts the weight vector <span class="katex"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>w</mi><mi>n</mi></msub></mrow><annotation encoding="application/x-tex">w_n</annotation></semantics></math></span> or per-token weights.</p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="use-cases-3">Use Cases<a href="#use-cases-3" class="hash-link" aria-label="Direct link to Use Cases" title="Direct link to Use Cases" translate="no">​</a></h3>
<p>Applied in code migration and generation tasks where token significance varies.</p>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="6-comparative-summary">6. Comparative Summary<a href="#6-comparative-summary" class="hash-link" aria-label="Direct link to 6. Comparative Summary" title="Direct link to 6. Comparative Summary" translate="no">​</a></h2>
<table><thead><tr><th>Metric</th><th>Based on</th><th>Extension Goal</th><th>Added Feature(s)</th><th>Typical Domain</th></tr></thead><tbody><tr><td><strong>BLEU</strong></td><td>–</td><td>Baseline precision-based metric</td><td>Modified n-gram precision, brevity penalty</td><td>NLP, SE</td></tr><tr><td><strong>CodeBLEU</strong></td><td>BLEU</td><td>Incorporate syntax and semantics</td><td>Weighted n-gram, AST, data-flow matches</td><td>SE</td></tr><tr><td><strong>CrystalBLEU</strong></td><td>BLEU</td><td>Filter trivial overlaps</td><td>Removes common/high-frequency n-grams</td><td>SE</td></tr><tr><td><strong>Smoothed BLEU</strong></td><td>BLEU</td><td>Stabilize scores for short outputs</td><td>Adds smoothing for higher-order n-grams</td><td>NLP, SE</td></tr><tr><td><strong>WeightBLEU</strong></td><td>BLEU</td><td>Token-importance weighting</td><td>Variable n-gram and token weights</td><td>SE</td></tr></tbody></table>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="references">References<a href="#references" class="hash-link" aria-label="Direct link to References" title="Direct link to References" translate="no">​</a></h2>
<ul>
<li>Papineni, K., Roukos, S., Ward, T., &amp; Zhu, W.-J. (2002).<br>
<em>BLEU: A Method for Automatic Evaluation of Machine Translation.</em><br>
<em>Proceedings of the 40th Annual Meeting of the Association for Computational Linguistics (ACL).</em><br>
<a href="https://aclanthology.org/P02-1040.pdf" target="_blank" rel="noopener noreferrer">https://aclanthology.org/P02-1040.pdf</a></li>
<li>Eghbali, A., &amp; Pradel, M. (2022). <em>CrystalBLEU: Precisely and Efficiently Measuring the Similarity of Code.</em>
<a href="https://doi.org/10.1145/3551349.3556903" target="_blank" rel="noopener noreferrer">https://doi.org/10.1145/3551349.3556903</a></li>
</ul>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="additional-references-in-dataset">Additional References in Dataset<a href="#additional-references-in-dataset" class="hash-link" aria-label="Direct link to Additional References in Dataset" title="Direct link to Additional References in Dataset" translate="no">​</a></h3>
<ul>
<li>1, 2, 3, 6, 7, 9, 10, 11, 12, 15, 18, 19, 23, 25, 26, 31, 32, 34, 37, 40, 43, 45, 46, 47, 50, 51, 58, 60, 68</li>
</ul></div></article><nav class="docusaurus-mt-lg pagination-nav" aria-label="Docs pages"><a class="pagination-nav__link pagination-nav__link--prev" href="/LLMs-metrics-catalog/intro"><div class="pagination-nav__sublabel">Previous</div><div class="pagination-nav__label">Introduction</div></a><a class="pagination-nav__link pagination-nav__link--next" href="/LLMs-metrics-catalog/metrics/accuracy-overlap/accuracy"><div class="pagination-nav__sublabel">Next</div><div class="pagination-nav__label">Accuracy</div></a></nav></div></div><div class="col col--3"><div class="tableOfContents_bqdL thin-scrollbar theme-doc-toc-desktop"><ul class="table-of-contents table-of-contents__left-border"><li><a href="#introduction" class="table-of-contents__link toc-highlight">Introduction</a></li><li><a href="#1-bleu-bilingual-evaluation-understudy" class="table-of-contents__link toc-highlight">1. BLEU (Bilingual Evaluation Understudy)</a><ul><li><a href="#definition" class="table-of-contents__link toc-highlight">Definition</a></li><li><a href="#purpose" class="table-of-contents__link toc-highlight">Purpose</a></li><li><a href="#applications" class="table-of-contents__link toc-highlight">Applications</a></li><li><a href="#limitations" class="table-of-contents__link toc-highlight">Limitations</a></li></ul></li><li><a href="#2-codebleu" class="table-of-contents__link toc-highlight">2. CodeBLEU</a><ul><li><a href="#definition-1" class="table-of-contents__link toc-highlight">Definition</a></li><li><a href="#advantages" class="table-of-contents__link toc-highlight">Advantages</a></li><li><a href="#use-cases" class="table-of-contents__link toc-highlight">Use Cases</a></li></ul></li><li><a href="#3-crystalbleu" class="table-of-contents__link toc-highlight">3. CrystalBLEU</a><ul><li><a href="#definition-2" class="table-of-contents__link toc-highlight">Definition</a></li><li><a href="#advantages-1" class="table-of-contents__link toc-highlight">Advantages</a></li><li><a href="#use-cases-1" class="table-of-contents__link toc-highlight">Use Cases</a></li></ul></li><li><a href="#4-smoothed-bleu--smoothed-4-gram-bleu" class="table-of-contents__link toc-highlight">4. Smoothed BLEU / Smoothed 4-gram BLEU</a><ul><li><a href="#definition-3" class="table-of-contents__link toc-highlight">Definition</a></li><li><a href="#use-cases-2" class="table-of-contents__link toc-highlight">Use Cases</a></li></ul></li><li><a href="#5-weightbleu" class="table-of-contents__link toc-highlight">5. WeightBLEU</a><ul><li><a href="#definition-4" class="table-of-contents__link toc-highlight">Definition</a></li><li><a href="#use-cases-3" class="table-of-contents__link toc-highlight">Use Cases</a></li></ul></li><li><a href="#6-comparative-summary" class="table-of-contents__link toc-highlight">6. Comparative Summary</a></li><li><a href="#references" class="table-of-contents__link toc-highlight">References</a><ul><li><a href="#additional-references-in-dataset" class="table-of-contents__link toc-highlight">Additional References in Dataset</a></li></ul></li></ul></div></div></div></div></main></div></div></div></div>
</body>
</html>