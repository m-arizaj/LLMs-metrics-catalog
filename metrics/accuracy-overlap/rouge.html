<!doctype html>
<html lang="en" dir="ltr" class="docs-wrapper plugin-docs plugin-id-default docs-version-current docs-doc-page docs-doc-id-metrics/accuracy-overlap/rouge" data-has-hydrated="false">
<head>
<meta charset="UTF-8">
<meta name="generator" content="Docusaurus v3.9.1">
<title data-rh="true">ROUGE | LLM Metrics Catalog</title><meta data-rh="true" name="viewport" content="width=device-width,initial-scale=1"><meta data-rh="true" name="twitter:card" content="summary_large_image"><meta data-rh="true" property="og:url" content="https://m-arizaj.github.io/LLMs-metrics-catalog/metrics/accuracy-overlap/rouge"><meta data-rh="true" property="og:locale" content="en"><meta data-rh="true" name="docusaurus_locale" content="en"><meta data-rh="true" name="docsearch:language" content="en"><meta data-rh="true" name="docusaurus_version" content="current"><meta data-rh="true" name="docusaurus_tag" content="docs-default-current"><meta data-rh="true" name="docsearch:version" content="current"><meta data-rh="true" name="docsearch:docusaurus_tag" content="docs-default-current"><meta data-rh="true" property="og:title" content="ROUGE | LLM Metrics Catalog"><meta data-rh="true" name="description" content="Definition"><meta data-rh="true" property="og:description" content="Definition"><link data-rh="true" rel="canonical" href="https://m-arizaj.github.io/LLMs-metrics-catalog/metrics/accuracy-overlap/rouge"><link data-rh="true" rel="alternate" href="https://m-arizaj.github.io/LLMs-metrics-catalog/metrics/accuracy-overlap/rouge" hreflang="en"><link data-rh="true" rel="alternate" href="https://m-arizaj.github.io/LLMs-metrics-catalog/metrics/accuracy-overlap/rouge" hreflang="x-default"><script data-rh="true" type="application/ld+json">{"@context":"https://schema.org","@type":"BreadcrumbList","itemListElement":[{"@type":"ListItem","position":1,"name":"ROUGE","item":"https://m-arizaj.github.io/LLMs-metrics-catalog/metrics/accuracy-overlap/rouge"}]}</script><link rel="stylesheet" href="/LLMs-metrics-catalog/assets/css/styles.31db4f94.css">
<script src="/LLMs-metrics-catalog/assets/js/runtime~main.16c43ec5.js" defer="defer"></script>
<script src="/LLMs-metrics-catalog/assets/js/main.aaa42f77.js" defer="defer"></script>
</head>
<body class="navigation-with-keyboard">
<svg style="display: none;"><defs>
<symbol id="theme-svg-external-link" viewBox="0 0 24 24"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"/></symbol>
</defs></svg>
<script>!function(){var t=function(){try{return new URLSearchParams(window.location.search).get("docusaurus-theme")}catch(t){}}()||function(){try{return window.localStorage.getItem("theme")}catch(t){}}();document.documentElement.setAttribute("data-theme",t||"light"),document.documentElement.setAttribute("data-theme-choice",t||"light")}(),function(){try{const c=new URLSearchParams(window.location.search).entries();for(var[t,e]of c)if(t.startsWith("docusaurus-data-")){var a=t.replace("docusaurus-data-","data-");document.documentElement.setAttribute(a,e)}}catch(t){}}()</script><div id="__docusaurus"><div role="region" aria-label="Skip to main content"><a class="skipToContent_fXgn" href="#__docusaurus_skipToContent_fallback">Skip to main content</a></div><nav aria-label="Main" class="theme-layout-navbar navbar navbar--fixed-top"><div class="navbar__inner"><div class="theme-layout-navbar-left navbar__items"><a class="navbar__brand" href="/LLMs-metrics-catalog/"></a></div><div class="theme-layout-navbar-right navbar__items navbar__items--right"><div class="toggle_vylO colorModeToggle_DEke"><button class="clean-btn toggleButton_gllP toggleButtonDisabled_aARS" type="button" disabled="" title="system mode" aria-label="Switch between dark and light mode (currently system mode)"><svg viewBox="0 0 24 24" width="24" height="24" aria-hidden="true" class="toggleIcon_g3eP lightToggleIcon_pyhR"><path fill="currentColor" d="M12,9c1.65,0,3,1.35,3,3s-1.35,3-3,3s-3-1.35-3-3S10.35,9,12,9 M12,7c-2.76,0-5,2.24-5,5s2.24,5,5,5s5-2.24,5-5 S14.76,7,12,7L12,7z M2,13l2,0c0.55,0,1-0.45,1-1s-0.45-1-1-1l-2,0c-0.55,0-1,0.45-1,1S1.45,13,2,13z M20,13l2,0c0.55,0,1-0.45,1-1 s-0.45-1-1-1l-2,0c-0.55,0-1,0.45-1,1S19.45,13,20,13z M11,2v2c0,0.55,0.45,1,1,1s1-0.45,1-1V2c0-0.55-0.45-1-1-1S11,1.45,11,2z M11,20v2c0,0.55,0.45,1,1,1s1-0.45,1-1v-2c0-0.55-0.45-1-1-1C11.45,19,11,19.45,11,20z M5.99,4.58c-0.39-0.39-1.03-0.39-1.41,0 c-0.39,0.39-0.39,1.03,0,1.41l1.06,1.06c0.39,0.39,1.03,0.39,1.41,0s0.39-1.03,0-1.41L5.99,4.58z M18.36,16.95 c-0.39-0.39-1.03-0.39-1.41,0c-0.39,0.39-0.39,1.03,0,1.41l1.06,1.06c0.39,0.39,1.03,0.39,1.41,0c0.39-0.39,0.39-1.03,0-1.41 L18.36,16.95z M19.42,5.99c0.39-0.39,0.39-1.03,0-1.41c-0.39-0.39-1.03-0.39-1.41,0l-1.06,1.06c-0.39,0.39-0.39,1.03,0,1.41 s1.03,0.39,1.41,0L19.42,5.99z M7.05,18.36c0.39-0.39,0.39-1.03,0-1.41c-0.39-0.39-1.03-0.39-1.41,0l-1.06,1.06 c-0.39,0.39-0.39,1.03,0,1.41s1.03,0.39,1.41,0L7.05,18.36z"></path></svg><svg viewBox="0 0 24 24" width="24" height="24" aria-hidden="true" class="toggleIcon_g3eP darkToggleIcon_wfgR"><path fill="currentColor" d="M9.37,5.51C9.19,6.15,9.1,6.82,9.1,7.5c0,4.08,3.32,7.4,7.4,7.4c0.68,0,1.35-0.09,1.99-0.27C17.45,17.19,14.93,19,12,19 c-3.86,0-7-3.14-7-7C5,9.07,6.81,6.55,9.37,5.51z M12,3c-4.97,0-9,4.03-9,9s4.03,9,9,9s9-4.03,9-9c0-0.46-0.04-0.92-0.1-1.36 c-0.98,1.37-2.58,2.26-4.4,2.26c-2.98,0-5.4-2.42-5.4-5.4c0-1.81,0.89-3.42,2.26-4.4C12.92,3.04,12.46,3,12,3L12,3z"></path></svg><svg viewBox="0 0 24 24" width="24" height="24" aria-hidden="true" class="toggleIcon_g3eP systemToggleIcon_QzmC"><path fill="currentColor" d="m12 21c4.971 0 9-4.029 9-9s-4.029-9-9-9-9 4.029-9 9 4.029 9 9 9zm4.95-13.95c1.313 1.313 2.05 3.093 2.05 4.95s-0.738 3.637-2.05 4.95c-1.313 1.313-3.093 2.05-4.95 2.05v-14c1.857 0 3.637 0.737 4.95 2.05z"></path></svg></button></div><div class="navbarSearchContainer_Bca1"></div></div></div><div role="presentation" class="navbar-sidebar__backdrop"></div></nav><div id="__docusaurus_skipToContent_fallback" class="theme-layout-main main-wrapper mainWrapper_z2l0"><div class="docsWrapper_hBAB"><button aria-label="Scroll back to top" class="clean-btn theme-back-to-top-button backToTopButton_sjWU" type="button"></button><div class="docRoot_UBD9"><aside class="theme-doc-sidebar-container docSidebarContainer_YfHR"><div class="sidebarViewport_aRkj"><div class="sidebar_njMd"><nav aria-label="Docs sidebar" class="menu thin-scrollbar menu_SIkG"><ul class="theme-doc-sidebar-menu menu__list"><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-1 menu__list-item"><a class="menu__link" href="/LLMs-metrics-catalog/intro"><span title="Introduction" class="linkLabel_WmDU">Introduction</span></a></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist menu__link--sublist-caret menu__link--active" role="button" aria-expanded="true" href="/LLMs-metrics-catalog/metrics/accuracy-overlap/bleu"><span title="Core Accuracy &amp; Overlap Metrics" class="categoryLinkLabel_W154">Core Accuracy &amp; Overlap Metrics</span></a></div><ul class="menu__list"><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/LLMs-metrics-catalog/metrics/accuracy-overlap/bleu"><span title="BLEU" class="linkLabel_WmDU">BLEU</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/LLMs-metrics-catalog/metrics/accuracy-overlap/accuracy"><span title="Accuracy" class="linkLabel_WmDU">Accuracy</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/LLMs-metrics-catalog/metrics/accuracy-overlap/pass-at-k"><span title="Pass@k" class="linkLabel_WmDU">Pass@k</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/LLMs-metrics-catalog/metrics/accuracy-overlap/f1-score"><span title="F1-Score" class="linkLabel_WmDU">F1-Score</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link menu__link--active" aria-current="page" tabindex="0" href="/LLMs-metrics-catalog/metrics/accuracy-overlap/rouge"><span title="ROUGE" class="linkLabel_WmDU">ROUGE</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/LLMs-metrics-catalog/metrics/accuracy-overlap/recall"><span title="Recall" class="linkLabel_WmDU">Recall</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/LLMs-metrics-catalog/metrics/accuracy-overlap/precision"><span title="Precision" class="linkLabel_WmDU">Precision</span></a></li></ul></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist menu__link--sublist-caret" role="button" aria-expanded="true" href="/LLMs-metrics-catalog/metrics/statistical/ice-score"><span title="Statistical &amp; Correlation Metrics" class="categoryLinkLabel_W154">Statistical &amp; Correlation Metrics</span></a></div><ul class="menu__list"><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/LLMs-metrics-catalog/metrics/statistical/ice-score"><span title="ICE-Score" class="linkLabel_WmDU">ICE-Score</span></a></li></ul></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist menu__link--sublist-caret" role="button" aria-expanded="true" href="/LLMs-metrics-catalog/metrics/code-structural/ast-metrics"><span title="Code Quality &amp; Structural Metrics" class="categoryLinkLabel_W154">Code Quality &amp; Structural Metrics</span></a></div><ul class="menu__list"><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/LLMs-metrics-catalog/metrics/code-structural/ast-metrics"><span title="AST Metrics" class="linkLabel_WmDU">AST Metrics</span></a></li></ul></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist menu__link--sublist-caret" role="button" aria-expanded="true" href="/LLMs-metrics-catalog/metrics/functional-test/error"><span title="Functional &amp; Test-based Evaluation" class="categoryLinkLabel_W154">Functional &amp; Test-based Evaluation</span></a></div><ul class="menu__list"><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/LLMs-metrics-catalog/metrics/functional-test/error"><span title="Error Metrics" class="linkLabel_WmDU">Error Metrics</span></a></li></ul></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist menu__link--sublist-caret" role="button" aria-expanded="false" href="/LLMs-metrics-catalog/metrics/human/toxicity"><span title="Human &amp; Subjective Evaluation" class="categoryLinkLabel_W154">Human &amp; Subjective Evaluation</span></a></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist menu__link--sublist-caret" role="button" aria-expanded="false" href="/LLMs-metrics-catalog/metrics/generative/amber-score"><span title="Generative &amp; Distribution Metrics" class="categoryLinkLabel_W154">Generative &amp; Distribution Metrics</span></a></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist menu__link--sublist-caret" role="button" aria-expanded="false" href="/LLMs-metrics-catalog/metrics/logical/cog-metric"><span title="Logical Reasoning &amp; Verification" class="categoryLinkLabel_W154">Logical Reasoning &amp; Verification</span></a></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist menu__link--sublist-caret" role="button" aria-expanded="false" href="/LLMs-metrics-catalog/metrics/robustness/ct-score"><span title="Robustness, Security &amp; Reliability" class="categoryLinkLabel_W154">Robustness, Security &amp; Reliability</span></a></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist menu__link--sublist-caret" role="button" aria-expanded="false" href="/LLMs-metrics-catalog/metrics/efficiency/time"><span title="Efficiency &amp; Resource Usage" class="categoryLinkLabel_W154">Efficiency &amp; Resource Usage</span></a></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist menu__link--sublist-caret" role="button" aria-expanded="false" href="/LLMs-metrics-catalog/metrics/architectural/composite"><span title="Architectural &amp; System-level Metrics" class="categoryLinkLabel_W154">Architectural &amp; System-level Metrics</span></a></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist menu__link--sublist-caret" role="button" aria-expanded="false" href="/LLMs-metrics-catalog/metrics/creativity/dialogue"><span title="Creativity, Diversity &amp; Novelty" class="categoryLinkLabel_W154">Creativity, Diversity &amp; Novelty</span></a></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist menu__link--sublist-caret" role="button" aria-expanded="false" href="/LLMs-metrics-catalog/metrics/ranking/elo-score"><span title="Ranking, Reward &amp; Optimization" class="categoryLinkLabel_W154">Ranking, Reward &amp; Optimization</span></a></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist menu__link--sublist-caret" role="button" aria-expanded="false" href="/LLMs-metrics-catalog/metrics/semantic/hallucination"><span title="Semantic, Coherence &amp; Hallucination" class="categoryLinkLabel_W154">Semantic, Coherence &amp; Hallucination</span></a></div></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-1 menu__list-item"><a class="menu__link" href="/LLMs-metrics-catalog/references"><span title="References" class="linkLabel_WmDU">References</span></a></li></ul></nav></div></div></aside><main class="docMainContainer_TBSr"><div class="container padding-top--md padding-bottom--lg"><div class="row"><div class="col docItemCol_VOVn"><div class="docItemContainer_Djhp"><article><nav class="theme-doc-breadcrumbs breadcrumbsContainer_Z_bl" aria-label="Breadcrumbs"><ul class="breadcrumbs"><li class="breadcrumbs__item"><a aria-label="Home page" class="breadcrumbs__link" href="/LLMs-metrics-catalog/"><svg viewBox="0 0 24 24" class="breadcrumbHomeIcon_YNFT"><path d="M10 19v-5h4v5c0 .55.45 1 1 1h3c.55 0 1-.45 1-1v-7h1.7c.46 0 .68-.57.33-.87L12.67 3.6c-.38-.34-.96-.34-1.34 0l-8.36 7.53c-.34.3-.13.87.33.87H5v7c0 .55.45 1 1 1h3c.55 0 1-.45 1-1z" fill="currentColor"></path></svg></a></li><li class="breadcrumbs__item"><span class="breadcrumbs__link">Core Accuracy &amp; Overlap Metrics</span></li><li class="breadcrumbs__item breadcrumbs__item--active"><span class="breadcrumbs__link">ROUGE</span></li></ul></nav><div class="tocCollapsible_ETCw theme-doc-toc-mobile tocMobile_ITEo"><button type="button" class="clean-btn tocCollapsibleButton_TO0P">On this page</button></div><div class="theme-doc-markdown markdown"><header><h1>ROUGE</h1></header><h2 class="anchor anchorWithStickyNavbar_LWe7" id="definition">Definition<a href="#definition" class="hash-link" aria-label="Direct link to Definition" title="Direct link to Definition" translate="no">​</a></h2>
<p>ROUGE (Recall-Oriented Understudy for Gisting Evaluation) is a set of metrics used for evaluating automatic summarization and machine translation, also applied to code generation . It works by comparing an automatically produced summary or output (candidate) against one or more reference summaries (typically human-written). Key variants include:</p>
<ul>
<li><strong>ROUGE-N:</strong> Measures the overlap of n-grams (sequences of n words/tokens) .</li>
<li><strong>ROUGE-L:</strong> Measures the Longest Common Subsequence (LCS) between the candidate and reference(s).</li>
</ul>
<p>As the name suggests, ROUGE primarily focuses on <strong>recall</strong>—how much of the information in the reference(s) is captured by the candidate . Precision and F1 versions also exist.</p>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="formula-general-idea---rouge-n-recall">Formula (General Idea - ROUGE-N Recall)<a href="#formula-general-idea---rouge-n-recall" class="hash-link" aria-label="Direct link to Formula (General Idea - ROUGE-N Recall)" title="Direct link to Formula (General Idea - ROUGE-N Recall)" translate="no">​</a></h2>
<span class="katex"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><msub><mtext>ROUGE-N</mtext><mtext>recall</mtext></msub><mo>=</mo><mfrac><mrow><munder><mo>∑</mo><mrow><mi>S</mi><mo>∈</mo><mo stretchy="false">{</mo><mtext>Reference Summaries</mtext><mo stretchy="false">}</mo></mrow></munder><munder><mo>∑</mo><mrow><msub><mtext>gram</mtext><mi>n</mi></msub><mo>∈</mo><mi>S</mi></mrow></munder><msub><mtext>Count</mtext><mtext>match</mtext></msub><mo stretchy="false">(</mo><msub><mtext>gram</mtext><mi>n</mi></msub><mo stretchy="false">)</mo></mrow><mrow><munder><mo>∑</mo><mrow><mi>S</mi><mo>∈</mo><mo stretchy="false">{</mo><mtext>Reference Summaries</mtext><mo stretchy="false">}</mo></mrow></munder><munder><mo>∑</mo><mrow><msub><mtext>gram</mtext><mi>n</mi></msub><mo>∈</mo><mi>S</mi></mrow></munder><mtext>Count</mtext><mo stretchy="false">(</mo><msub><mtext>gram</mtext><mi>n</mi></msub><mo stretchy="false">)</mo></mrow></mfrac></mrow><annotation encoding="application/x-tex">\text{ROUGE-N}_{\text{recall}} = \frac{\sum_{S \in \{\text{Reference Summaries}\}} \sum_{\text{gram}_n \in S} \text{Count}_{\text{match}}(\text{gram}_n)}{\sum_{S \in \{\text{Reference Summaries}\}} \sum_{\text{gram}_n \in S} \text{Count}(\text{gram}_n)}</annotation></semantics></math></span>
<p>Where:</p>
<ul>
<li><span class="katex"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>n</mi></mrow><annotation encoding="application/x-tex">n</annotation></semantics></math></span> is the length of the n-gram (e.g., 1 for ROUGE-1, 2 for ROUGE-2).</li>
<li><span class="katex"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mtext>Count</mtext><mtext>match</mtext></msub><mo stretchy="false">(</mo><msub><mtext>gram</mtext><mi>n</mi></msub><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">\text{Count}_{\text{match}}(\text{gram}_n)</annotation></semantics></math></span> is the number of times an n-gram from the reference appears in the candidate.</li>
<li><span class="katex"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mtext>Count</mtext><mo stretchy="false">(</mo><msub><mtext>gram</mtext><mi>n</mi></msub><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">\text{Count}(\text{gram}_n)</annotation></semantics></math></span> is the total number of n-grams in the reference summary.</li>
</ul>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="purpose">Purpose<a href="#purpose" class="hash-link" aria-label="Direct link to Purpose" title="Direct link to Purpose" translate="no">​</a></h2>
<p>To evaluate the quality of generated text/code by measuring the recall of n-grams or LCS compared to reference(s). Often used to assess content overlap, especially in summarization tasks.</p>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="domains">Domains<a href="#domains" class="hash-link" aria-label="Direct link to Domains" title="Direct link to Domains" translate="no">​</a></h2>
<ul>
<li>Automatic Summarization  (Primary use)</li>
<li>Machine Translation</li>
<li>Code Generation</li>
<li>Code Summarization</li>
<li>Commit Message Generation</li>
<li>Documentation Generation</li>
<li>Text Generation</li>
</ul>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="benchmarks">Benchmarks<a href="#benchmarks" class="hash-link" aria-label="Direct link to Benchmarks" title="Direct link to Benchmarks" translate="no">​</a></h2>
<ul>
<li>CodeXGLUE</li>
<li>CNN/DailyMail, XSUM</li>
<li>TL-CodeSum</li>
<li>CodeSearchNet</li>
<li>BIG-bench</li>
<li>GEM, GLGE</li>
<li>PubMed, PMC, BioMedSumm</li>
<li>(Various NLP benchmarks)</li>
</ul>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="advantages">Advantages<a href="#advantages" class="hash-link" aria-label="Direct link to Advantages" title="Direct link to Advantages" translate="no">​</a></h2>
<ul>
<li>Standard metric, especially for summarization tasks.</li>
<li>Correlates reasonably well with human judgments of content overlap (recall).</li>
<li>Relatively simple to compute.</li>
</ul>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="limitations">Limitations<a href="#limitations" class="hash-link" aria-label="Direct link to Limitations" title="Direct link to Limitations" translate="no">​</a></h2>
<ul>
<li>Like BLEU, has <strong>low semantic sensitivity</strong>; focuses on exact word/token matches, not meaning.</li>
<li>Does not directly assess fluency, coherence, or factual correctness.</li>
<li>For code, <strong>does not reflect functional correctness</strong> or buildability. High ROUGE doesn&#x27;t mean the code works.</li>
<li>ROUGE-L (LCS) can reward sequences in the correct order but doesn&#x27;t require contiguity, which might be less relevant for code structure than n-grams.</li>
</ul>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="key-references">Key References<a href="#key-references" class="hash-link" aria-label="Direct link to Key References" title="Direct link to Key References" translate="no">​</a></h2>
<ul>
<li>Lin, C.-Y., 2004  (Original ROUGE paper)</li>
<li>File: Evaluating Large Language Models for Functional.pdf</li>
<li>(Excel Data: Papers 1, 2, 3, 4, 6, 7, 9, 11, 12, 18, 19, 25, 40, 48)</li>
</ul></div></article><nav class="docusaurus-mt-lg pagination-nav" aria-label="Docs pages"><a class="pagination-nav__link pagination-nav__link--prev" href="/LLMs-metrics-catalog/metrics/accuracy-overlap/f1-score"><div class="pagination-nav__sublabel">Previous</div><div class="pagination-nav__label">F1-Score</div></a><a class="pagination-nav__link pagination-nav__link--next" href="/LLMs-metrics-catalog/metrics/accuracy-overlap/recall"><div class="pagination-nav__sublabel">Next</div><div class="pagination-nav__label">Recall</div></a></nav></div></div><div class="col col--3"><div class="tableOfContents_bqdL thin-scrollbar theme-doc-toc-desktop"><ul class="table-of-contents table-of-contents__left-border"><li><a href="#definition" class="table-of-contents__link toc-highlight">Definition</a></li><li><a href="#formula-general-idea---rouge-n-recall" class="table-of-contents__link toc-highlight">Formula (General Idea - ROUGE-N Recall)</a></li><li><a href="#purpose" class="table-of-contents__link toc-highlight">Purpose</a></li><li><a href="#domains" class="table-of-contents__link toc-highlight">Domains</a></li><li><a href="#benchmarks" class="table-of-contents__link toc-highlight">Benchmarks</a></li><li><a href="#advantages" class="table-of-contents__link toc-highlight">Advantages</a></li><li><a href="#limitations" class="table-of-contents__link toc-highlight">Limitations</a></li><li><a href="#key-references" class="table-of-contents__link toc-highlight">Key References</a></li></ul></div></div></div></div></main></div></div></div></div>
</body>
</html>