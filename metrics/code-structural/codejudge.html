<!doctype html>
<html lang="en" dir="ltr" class="docs-wrapper plugin-docs plugin-id-default docs-version-current docs-doc-page docs-doc-id-metrics/code-structural/codejudge" data-has-hydrated="false">
<head>
<meta charset="UTF-8">
<meta name="generator" content="Docusaurus v3.9.1">
<title data-rh="true">CodeJudge | LLM Metrics Catalog</title><meta data-rh="true" name="viewport" content="width=device-width,initial-scale=1"><meta data-rh="true" name="twitter:card" content="summary_large_image"><meta data-rh="true" property="og:url" content="https://m-arizaj.github.io/LLMs-metrics-catalog/metrics/code-structural/codejudge"><meta data-rh="true" property="og:locale" content="en"><meta data-rh="true" name="docusaurus_locale" content="en"><meta data-rh="true" name="docsearch:language" content="en"><meta data-rh="true" name="docusaurus_version" content="current"><meta data-rh="true" name="docusaurus_tag" content="docs-default-current"><meta data-rh="true" name="docsearch:version" content="current"><meta data-rh="true" name="docsearch:docusaurus_tag" content="docs-default-current"><meta data-rh="true" property="og:title" content="CodeJudge | LLM Metrics Catalog"><meta data-rh="true" name="description" content="Introduction"><meta data-rh="true" property="og:description" content="Introduction"><link data-rh="true" rel="canonical" href="https://m-arizaj.github.io/LLMs-metrics-catalog/metrics/code-structural/codejudge"><link data-rh="true" rel="alternate" href="https://m-arizaj.github.io/LLMs-metrics-catalog/metrics/code-structural/codejudge" hreflang="en"><link data-rh="true" rel="alternate" href="https://m-arizaj.github.io/LLMs-metrics-catalog/metrics/code-structural/codejudge" hreflang="x-default"><script data-rh="true" type="application/ld+json">{"@context":"https://schema.org","@type":"BreadcrumbList","itemListElement":[{"@type":"ListItem","position":1,"name":"CodeJudge","item":"https://m-arizaj.github.io/LLMs-metrics-catalog/metrics/code-structural/codejudge"}]}</script><link rel="stylesheet" href="/LLMs-metrics-catalog/assets/css/styles.422c2d42.css">
<script src="/LLMs-metrics-catalog/assets/js/runtime~main.686142be.js" defer="defer"></script>
<script src="/LLMs-metrics-catalog/assets/js/main.8f919ca9.js" defer="defer"></script>
</head>
<body class="navigation-with-keyboard">
<svg style="display: none;"><defs>
<symbol id="theme-svg-external-link" viewBox="0 0 24 24"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"/></symbol>
</defs></svg>
<script>!function(){var t=function(){try{return new URLSearchParams(window.location.search).get("docusaurus-theme")}catch(t){}}()||function(){try{return window.localStorage.getItem("theme")}catch(t){}}();document.documentElement.setAttribute("data-theme",t||"light"),document.documentElement.setAttribute("data-theme-choice",t||"light")}(),function(){try{const c=new URLSearchParams(window.location.search).entries();for(var[t,e]of c)if(t.startsWith("docusaurus-data-")){var a=t.replace("docusaurus-data-","data-");document.documentElement.setAttribute(a,e)}}catch(t){}}()</script><div id="__docusaurus"><div role="region" aria-label="Skip to main content"><a class="skipToContent_fXgn" href="#__docusaurus_skipToContent_fallback">Skip to main content</a></div><nav aria-label="Main" class="theme-layout-navbar navbar navbar--fixed-top"><div class="navbar__inner"><div class="theme-layout-navbar-left navbar__items"><a class="navbar__brand" href="/LLMs-metrics-catalog/"></a></div><div class="theme-layout-navbar-right navbar__items navbar__items--right"><div class="toggle_vylO colorModeToggle_DEke"><button class="clean-btn toggleButton_gllP toggleButtonDisabled_aARS" type="button" disabled="" title="system mode" aria-label="Switch between dark and light mode (currently system mode)"><svg viewBox="0 0 24 24" width="24" height="24" aria-hidden="true" class="toggleIcon_g3eP lightToggleIcon_pyhR"><path fill="currentColor" d="M12,9c1.65,0,3,1.35,3,3s-1.35,3-3,3s-3-1.35-3-3S10.35,9,12,9 M12,7c-2.76,0-5,2.24-5,5s2.24,5,5,5s5-2.24,5-5 S14.76,7,12,7L12,7z M2,13l2,0c0.55,0,1-0.45,1-1s-0.45-1-1-1l-2,0c-0.55,0-1,0.45-1,1S1.45,13,2,13z M20,13l2,0c0.55,0,1-0.45,1-1 s-0.45-1-1-1l-2,0c-0.55,0-1,0.45-1,1S19.45,13,20,13z M11,2v2c0,0.55,0.45,1,1,1s1-0.45,1-1V2c0-0.55-0.45-1-1-1S11,1.45,11,2z M11,20v2c0,0.55,0.45,1,1,1s1-0.45,1-1v-2c0-0.55-0.45-1-1-1C11.45,19,11,19.45,11,20z M5.99,4.58c-0.39-0.39-1.03-0.39-1.41,0 c-0.39,0.39-0.39,1.03,0,1.41l1.06,1.06c0.39,0.39,1.03,0.39,1.41,0s0.39-1.03,0-1.41L5.99,4.58z M18.36,16.95 c-0.39-0.39-1.03-0.39-1.41,0c-0.39,0.39-0.39,1.03,0,1.41l1.06,1.06c0.39,0.39,1.03,0.39,1.41,0c0.39-0.39,0.39-1.03,0-1.41 L18.36,16.95z M19.42,5.99c0.39-0.39,0.39-1.03,0-1.41c-0.39-0.39-1.03-0.39-1.41,0l-1.06,1.06c-0.39,0.39-0.39,1.03,0,1.41 s1.03,0.39,1.41,0L19.42,5.99z M7.05,18.36c0.39-0.39,0.39-1.03,0-1.41c-0.39-0.39-1.03-0.39-1.41,0l-1.06,1.06 c-0.39,0.39-0.39,1.03,0,1.41s1.03,0.39,1.41,0L7.05,18.36z"></path></svg><svg viewBox="0 0 24 24" width="24" height="24" aria-hidden="true" class="toggleIcon_g3eP darkToggleIcon_wfgR"><path fill="currentColor" d="M9.37,5.51C9.19,6.15,9.1,6.82,9.1,7.5c0,4.08,3.32,7.4,7.4,7.4c0.68,0,1.35-0.09,1.99-0.27C17.45,17.19,14.93,19,12,19 c-3.86,0-7-3.14-7-7C5,9.07,6.81,6.55,9.37,5.51z M12,3c-4.97,0-9,4.03-9,9s4.03,9,9,9s9-4.03,9-9c0-0.46-0.04-0.92-0.1-1.36 c-0.98,1.37-2.58,2.26-4.4,2.26c-2.98,0-5.4-2.42-5.4-5.4c0-1.81,0.89-3.42,2.26-4.4C12.92,3.04,12.46,3,12,3L12,3z"></path></svg><svg viewBox="0 0 24 24" width="24" height="24" aria-hidden="true" class="toggleIcon_g3eP systemToggleIcon_QzmC"><path fill="currentColor" d="m12 21c4.971 0 9-4.029 9-9s-4.029-9-9-9-9 4.029-9 9 4.029 9 9 9zm4.95-13.95c1.313 1.313 2.05 3.093 2.05 4.95s-0.738 3.637-2.05 4.95c-1.313 1.313-3.093 2.05-4.95 2.05v-14c1.857 0 3.637 0.737 4.95 2.05z"></path></svg></button></div><div class="navbarSearchContainer_Bca1"><div class="navbar__search searchBarContainer_NW3z" dir="ltr"><input placeholder="Search" aria-label="Search" class="navbar__search-input searchInput_YFbd" value=""><div class="loadingRing_RJI3 searchBarLoadingRing_YnHq"><div></div><div></div><div></div><div></div></div></div></div></div></div><div role="presentation" class="navbar-sidebar__backdrop"></div></nav><div id="__docusaurus_skipToContent_fallback" class="theme-layout-main main-wrapper mainWrapper_z2l0"><div class="docsWrapper_hBAB"><button aria-label="Scroll back to top" class="clean-btn theme-back-to-top-button backToTopButton_sjWU" type="button"></button><div class="docRoot_UBD9"><aside class="theme-doc-sidebar-container docSidebarContainer_YfHR"><div class="sidebarViewport_aRkj"><div class="sidebar_njMd"><nav aria-label="Docs sidebar" class="menu thin-scrollbar menu_SIkG"><ul class="theme-doc-sidebar-menu menu__list"><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-1 menu__list-item"><a class="menu__link" href="/LLMs-metrics-catalog/intro"><span title="Introduction" class="linkLabel_WmDU">Introduction</span></a></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist menu__link--sublist-caret" role="button" aria-expanded="true" href="/LLMs-metrics-catalog/metrics/accuracy-overlap/bleu"><span title="Core Accuracy &amp; Overlap Metrics" class="categoryLinkLabel_W154">Core Accuracy &amp; Overlap Metrics</span></a></div><ul class="menu__list"><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/LLMs-metrics-catalog/metrics/accuracy-overlap/bleu"><span title="BLEU" class="linkLabel_WmDU">BLEU</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/LLMs-metrics-catalog/metrics/accuracy-overlap/accuracy"><span title="Accuracy" class="linkLabel_WmDU">Accuracy</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/LLMs-metrics-catalog/metrics/accuracy-overlap/pass-at-k"><span title="Pass@k" class="linkLabel_WmDU">Pass@k</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/LLMs-metrics-catalog/metrics/accuracy-overlap/f1-score"><span title="F1-Score" class="linkLabel_WmDU">F1-Score</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/LLMs-metrics-catalog/metrics/accuracy-overlap/exact-match"><span title="Exact Match" class="linkLabel_WmDU">Exact Match</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/LLMs-metrics-catalog/metrics/accuracy-overlap/rouge"><span title="ROUGE" class="linkLabel_WmDU">ROUGE</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/LLMs-metrics-catalog/metrics/accuracy-overlap/recall"><span title="Recall" class="linkLabel_WmDU">Recall</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/LLMs-metrics-catalog/metrics/accuracy-overlap/precision"><span title="Precision" class="linkLabel_WmDU">Precision</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/LLMs-metrics-catalog/metrics/accuracy-overlap/meteor"><span title="Meteor" class="linkLabel_WmDU">Meteor</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/LLMs-metrics-catalog/metrics/accuracy-overlap/edit-distance"><span title="Edit Distance" class="linkLabel_WmDU">Edit Distance</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/LLMs-metrics-catalog/metrics/accuracy-overlap/mrr"><span title="Mean Reciprocal Rank" class="linkLabel_WmDU">Mean Reciprocal Rank</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/LLMs-metrics-catalog/metrics/accuracy-overlap/swe"><span title="SWE-Judge Score" class="linkLabel_WmDU">SWE-Judge Score</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/LLMs-metrics-catalog/metrics/accuracy-overlap/bertscore"><span title="BERTScore" class="linkLabel_WmDU">BERTScore</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/LLMs-metrics-catalog/metrics/accuracy-overlap/coverage"><span title="Coverage" class="linkLabel_WmDU">Coverage</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/LLMs-metrics-catalog/metrics/accuracy-overlap/chrf"><span title="chrF" class="linkLabel_WmDU">chrF</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/LLMs-metrics-catalog/metrics/accuracy-overlap/codescore"><span title="CodeScore" class="linkLabel_WmDU">CodeScore</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/LLMs-metrics-catalog/metrics/accuracy-overlap/moverscore"><span title="MoverScore" class="linkLabel_WmDU">MoverScore</span></a></li></ul></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist menu__link--sublist-caret" role="button" aria-expanded="true" href="/LLMs-metrics-catalog/metrics/statistical/ice-score"><span title="Statistical &amp; Correlation Metrics" class="categoryLinkLabel_W154">Statistical &amp; Correlation Metrics</span></a></div><ul class="menu__list"><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/LLMs-metrics-catalog/metrics/statistical/ice-score"><span title="ICE-Score" class="linkLabel_WmDU">ICE-Score</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/LLMs-metrics-catalog/metrics/statistical/kendall"><span title="Kendall’s τ" class="linkLabel_WmDU">Kendall’s τ</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/LLMs-metrics-catalog/metrics/statistical/spearman"><span title="Spearman’s ρ" class="linkLabel_WmDU">Spearman’s ρ</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/LLMs-metrics-catalog/metrics/statistical/pearson"><span title="Pearson’s r" class="linkLabel_WmDU">Pearson’s r</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/LLMs-metrics-catalog/metrics/statistical/cohen"><span title="Cohen&#x27;s Score" class="linkLabel_WmDU">Cohen&#x27;s Score</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/LLMs-metrics-catalog/metrics/statistical/smape"><span title="Smape" class="linkLabel_WmDU">Smape</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/LLMs-metrics-catalog/metrics/statistical/rate"><span title="Rate Metrics" class="linkLabel_WmDU">Rate Metrics</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/LLMs-metrics-catalog/metrics/statistical/average"><span title="Average Metrics" class="linkLabel_WmDU">Average Metrics</span></a></li></ul></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist menu__link--sublist-caret menu__link--active" role="button" aria-expanded="true" href="/LLMs-metrics-catalog/metrics/code-structural/ast-metrics"><span title="Code Quality &amp; Structural Metrics" class="categoryLinkLabel_W154">Code Quality &amp; Structural Metrics</span></a></div><ul class="menu__list"><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/LLMs-metrics-catalog/metrics/code-structural/ast-metrics"><span title="AST Metrics" class="linkLabel_WmDU">AST Metrics</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/LLMs-metrics-catalog/metrics/code-structural/edition-metrics"><span title="Edition Metrics" class="linkLabel_WmDU">Edition Metrics</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/LLMs-metrics-catalog/metrics/code-structural/bugs"><span title="Bug Metrics" class="linkLabel_WmDU">Bug Metrics</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link menu__link--active" aria-current="page" tabindex="0" href="/LLMs-metrics-catalog/metrics/code-structural/codejudge"><span title="CodeJudge" class="linkLabel_WmDU">CodeJudge</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/LLMs-metrics-catalog/metrics/code-structural/compilation"><span title="Compilation Metrics" class="linkLabel_WmDU">Compilation Metrics</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/LLMs-metrics-catalog/metrics/code-structural/complexity"><span title="Complexity Metrics" class="linkLabel_WmDU">Complexity Metrics</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/LLMs-metrics-catalog/metrics/code-structural/code-style"><span title="Code Style Adherence" class="linkLabel_WmDU">Code Style Adherence</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/LLMs-metrics-catalog/metrics/code-structural/cohesion"><span title="Cohesion and Decoupling" class="linkLabel_WmDU">Cohesion and Decoupling</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/LLMs-metrics-catalog/metrics/code-structural/correctness"><span title="Correctness" class="linkLabel_WmDU">Correctness</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/LLMs-metrics-catalog/metrics/code-structural/count"><span title="Count Metrics" class="linkLabel_WmDU">Count Metrics</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/LLMs-metrics-catalog/metrics/code-structural/build"><span title="Build Metrics" class="linkLabel_WmDU">Build Metrics</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/LLMs-metrics-catalog/metrics/code-structural/ranked-retrieval"><span title="Ranked Retrieval" class="linkLabel_WmDU">Ranked Retrieval</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/LLMs-metrics-catalog/metrics/code-structural/dataflow"><span title="Data-Flow Match" class="linkLabel_WmDU">Data-Flow Match</span></a></li></ul></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist menu__link--sublist-caret" role="button" aria-expanded="true" href="/LLMs-metrics-catalog/metrics/functional-test/error"><span title="Functional &amp; Test-based Evaluation" class="categoryLinkLabel_W154">Functional &amp; Test-based Evaluation</span></a></div><ul class="menu__list"><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/LLMs-metrics-catalog/metrics/functional-test/error"><span title="Error Metrics" class="linkLabel_WmDU">Error Metrics</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/LLMs-metrics-catalog/metrics/functional-test/percentage"><span title="Percentage Metrics" class="linkLabel_WmDU">Percentage Metrics</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/LLMs-metrics-catalog/metrics/functional-test/number"><span title="Number Metrics" class="linkLabel_WmDU">Number Metrics</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/LLMs-metrics-catalog/metrics/functional-test/test"><span title="Test Metrics" class="linkLabel_WmDU">Test Metrics</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/LLMs-metrics-catalog/metrics/functional-test/reasoning-depth"><span title="Reasoning Depth" class="linkLabel_WmDU">Reasoning Depth</span></a></li></ul></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist menu__link--sublist-caret" role="button" aria-expanded="false" href="/LLMs-metrics-catalog/metrics/human"><span title="Human &amp; Subjective Evaluation" class="categoryLinkLabel_W154">Human &amp; Subjective Evaluation</span></a></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist menu__link--sublist-caret" role="button" aria-expanded="false" href="/LLMs-metrics-catalog/metrics/generative/amber-score"><span title="Generative &amp; Distribution Metrics" class="categoryLinkLabel_W154">Generative &amp; Distribution Metrics</span></a></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist menu__link--sublist-caret" role="button" aria-expanded="false" href="/LLMs-metrics-catalog/metrics/logical/cog-metric"><span title="Logical Reasoning &amp; Verification" class="categoryLinkLabel_W154">Logical Reasoning &amp; Verification</span></a></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist menu__link--sublist-caret" role="button" aria-expanded="false" href="/LLMs-metrics-catalog/metrics/robustness/ct-score"><span title="Robustness, Security &amp; Reliability" class="categoryLinkLabel_W154">Robustness, Security &amp; Reliability</span></a></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist menu__link--sublist-caret" role="button" aria-expanded="false" href="/LLMs-metrics-catalog/metrics/efficiency/time"><span title="Efficiency &amp; Resource Usage" class="categoryLinkLabel_W154">Efficiency &amp; Resource Usage</span></a></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist menu__link--sublist-caret" role="button" aria-expanded="false" href="/LLMs-metrics-catalog/metrics/architectural/composite"><span title="Architectural &amp; System-level Metrics" class="categoryLinkLabel_W154">Architectural &amp; System-level Metrics</span></a></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist menu__link--sublist-caret" role="button" aria-expanded="false" href="/LLMs-metrics-catalog/metrics/creativity/dialogue-similarities"><span title="Creativity, Diversity &amp; Novelty" class="categoryLinkLabel_W154">Creativity, Diversity &amp; Novelty</span></a></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist menu__link--sublist-caret" role="button" aria-expanded="false" href="/LLMs-metrics-catalog/metrics/ranking/elo-score"><span title="Ranking, Reward &amp; Optimization" class="categoryLinkLabel_W154">Ranking, Reward &amp; Optimization</span></a></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist menu__link--sublist-caret" role="button" aria-expanded="false" href="/LLMs-metrics-catalog/metrics/semantic/hallucination"><span title="Semantic, Coherence &amp; Hallucination" class="categoryLinkLabel_W154">Semantic, Coherence &amp; Hallucination</span></a></div></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-1 menu__list-item"><a class="menu__link" href="/LLMs-metrics-catalog/references"><span title="References" class="linkLabel_WmDU">References</span></a></li></ul></nav></div></div></aside><main class="docMainContainer_TBSr"><div class="container padding-top--md padding-bottom--lg"><div class="row"><div class="col docItemCol_VOVn"><div class="docItemContainer_Djhp"><article><nav class="theme-doc-breadcrumbs breadcrumbsContainer_Z_bl" aria-label="Breadcrumbs"><ul class="breadcrumbs"><li class="breadcrumbs__item"><a aria-label="Home page" class="breadcrumbs__link" href="/LLMs-metrics-catalog/"><svg viewBox="0 0 24 24" class="breadcrumbHomeIcon_YNFT"><path d="M10 19v-5h4v5c0 .55.45 1 1 1h3c.55 0 1-.45 1-1v-7h1.7c.46 0 .68-.57.33-.87L12.67 3.6c-.38-.34-.96-.34-1.34 0l-8.36 7.53c-.34.3-.13.87.33.87H5v7c0 .55.45 1 1 1h3c.55 0 1-.45 1-1z" fill="currentColor"></path></svg></a></li><li class="breadcrumbs__item"><span class="breadcrumbs__link">Code Quality &amp; Structural Metrics</span></li><li class="breadcrumbs__item breadcrumbs__item--active"><span class="breadcrumbs__link">CodeJudge</span></li></ul></nav><div class="tocCollapsible_ETCw theme-doc-toc-mobile tocMobile_ITEo"><button type="button" class="clean-btn tocCollapsibleButton_TO0P">On this page</button></div><div class="theme-doc-markdown markdown"><header><h1>CodeJudge</h1></header><h2 class="anchor anchorWithStickyNavbar_LWe7" id="introduction">Introduction<a href="#introduction" class="hash-link" aria-label="Direct link to Introduction" title="Direct link to Introduction" translate="no">​</a></h2>
<p>CodeJudge is an LLM-based evaluation framework designed to assess the semantic correctness of machine-generated code without relying on test cases. Proposed by Tong &amp; Zhang (2024), CodeJudge introduces a “slow thinking” process that enables large language models to reason through code step by step, improving alignment with human judgment in code evaluation tasks.
Traditional test-based metrics like Pass@k depend on unit tests, while token-based metrics (e.g., BLEU, ROUGE-L, CodeBLEU) fail to capture semantic equivalence when code differs syntactically but behaves correctly. CodeJudge addresses these limitations by using structured reasoning prompts and error taxonomies to judge correctness and quality, even in the absence of reference implementations.</p>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="formula-and-scoring-mechanism">Formula and Scoring Mechanism<a href="#formula-and-scoring-mechanism" class="hash-link" aria-label="Direct link to Formula and Scoring Mechanism" title="Direct link to Formula and Scoring Mechanism" translate="no">​</a></h2>
<p>CodeJudge introduces two main evaluation procedures:</p>
<ol>
<li><em>Analyze-Then-Summarize (A.S.)</em> – for binary correctness</li>
<li><em>Taxonomy-Guided Fault Localization (F.L.)</em> – for graded correctness</li>
</ol>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="1-analyze-then-summarize">1. Analyze-Then-Summarize<a href="#1-analyze-then-summarize" class="hash-link" aria-label="Direct link to 1. Analyze-Then-Summarize" title="Direct link to 1. Analyze-Then-Summarize" translate="no">​</a></h3>
<p>This method decomposes code evaluation into two subtasks:</p>
<ul>
<li><em>Analysis</em>: The LLM identifies the required functionalities from the task description, inspects the code logic, and lists any missing elements.</li>
<li><em>Summarization</em>: Based on this analysis, the model decides whether the code is correct (1) or incorrect (0).</li>
</ul>
<p>The binary decision <span class="katex"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>f</mi><mo stretchy="false">(</mo><mi>c</mi><mo separator="true">,</mo><mi>t</mi><mo stretchy="false">)</mo><mo>∈</mo><mo stretchy="false">{</mo><mn>0</mn><mo separator="true">,</mo><mn>1</mn><mo stretchy="false">}</mo></mrow><annotation encoding="application/x-tex">f(c, t) \in \{0, 1\}</annotation></semantics></math></span> depends on whether all task requirements are satisfied by the code snippet <span class="katex"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>c</mi></mrow><annotation encoding="application/x-tex">c</annotation></semantics></math></span> given the description <span class="katex"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>t</mi></mrow><annotation encoding="application/x-tex">t</annotation></semantics></math></span>.</p>
<p>Formally:</p>
<span class="katex"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><mi>f</mi><mo stretchy="false">(</mo><mi>c</mi><mo separator="true">,</mo><mi>t</mi><mo stretchy="false">)</mo><mo>=</mo><mrow><mo fence="true">{</mo><mtable rowspacing="0.36em" columnalign="left left" columnspacing="1em"><mtr><mtd><mstyle scriptlevel="0" displaystyle="false"><mrow><mn>1</mn><mo separator="true">,</mo></mrow></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="false"><mtext>if all required functionalities are correctly implemented,</mtext></mstyle></mtd></mtr><mtr><mtd><mstyle scriptlevel="0" displaystyle="false"><mrow><mn>0</mn><mo separator="true">,</mo></mrow></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="false"><mtext>otherwise.</mtext></mstyle></mtd></mtr></mtable></mrow></mrow><annotation encoding="application/x-tex">f(c, t) =
\begin{cases}
1, &amp; \text{if all required functionalities are correctly implemented,} \\
0, &amp; \text{otherwise.}
\end{cases}</annotation></semantics></math></span>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="2-taxonomy-guided-fault-localization">2. Taxonomy-Guided Fault Localization<a href="#2-taxonomy-guided-fault-localization" class="hash-link" aria-label="Direct link to 2. Taxonomy-Guided Fault Localization" title="Direct link to 2. Taxonomy-Guided Fault Localization" translate="no">​</a></h3>
<p>For tasks requiring graded correctness (partial or incomplete code), CodeJudge provides a taxonomy of inconsistencies with corresponding severities:</p>
<table><thead><tr><th>Severity</th><th>Type of Inconsistency</th><th>Description</th></tr></thead><tbody><tr><td>Negligible</td><td>Missing imports, no error handling</td><td>Minor, does not affect core functionality</td></tr><tr><td>Small</td><td>Input handling or edge case omission</td><td>Slight deviation from ideal behavior</td></tr><tr><td>Major</td><td>Logical errors</td><td>Directly affect semantic correctness</td></tr><tr><td>Fatal</td><td>Undefined variables, incomplete code</td><td>Cause crashes or total failure</td></tr></tbody></table>
<p>Each detected inconsistency contributes a penalty based on severity weights:</p>
<span class="katex"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><mi>S</mi><mo>=</mo><mi>N</mi><mi>u</mi><msub><mi>m</mi><mrow><mi>s</mi><mi>m</mi><mi>a</mi><mi>l</mi><mi>l</mi></mrow></msub><mo>×</mo><mn>5</mn><mspace linebreak="newline"></mspace><mi>M</mi><mo>=</mo><mi>N</mi><mi>u</mi><msub><mi>m</mi><mrow><mi>m</mi><mi>a</mi><mi>j</mi><mi>o</mi><mi>r</mi></mrow></msub><mo>×</mo><mn>50</mn><mspace linebreak="newline"></mspace><mi>F</mi><mo>=</mo><mi>N</mi><mi>u</mi><msub><mi>m</mi><mrow><mi>f</mi><mi>a</mi><mi>t</mi><mi>a</mi><mi>l</mi></mrow></msub><mo>×</mo><mn>100</mn></mrow><annotation encoding="application/x-tex">S = Num_{small} \times 5 \\
M = Num_{major} \times 50 \\
F = Num_{fatal} \times 100</annotation></semantics></math></span>
<p>Then, the penalty and final CodeJudge Score are computed as:</p>
<span class="katex"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><mi>P</mi><mi>e</mi><mi>n</mi><mi>a</mi><mi>l</mi><mi>t</mi><mi>y</mi><mo>=</mo><mi>max</mi><mo>⁡</mo><mo stretchy="false">(</mo><mo>−</mo><mn>100</mn><mo separator="true">,</mo><mo>−</mo><mo stretchy="false">(</mo><mi>S</mi><mo>+</mo><mi>M</mi><mo>+</mo><mi>F</mi><mo stretchy="false">)</mo><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">Penalty = \max(-100, -(S + M + F))</annotation></semantics></math></span>
<span class="katex"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><mi>S</mi><mi>c</mi><mi>o</mi><mi>r</mi><mi>e</mi><mo>=</mo><mn>1</mn><mo>−</mo><mfrac><mrow><mi>P</mi><mi>e</mi><mi>n</mi><mi>a</mi><mi>l</mi><mi>t</mi><mi>y</mi></mrow><mn>100</mn></mfrac></mrow><annotation encoding="application/x-tex">Score = 1 - \frac{Penalty}{100}</annotation></semantics></math></span>
<p>The score ranges from 0 to 1, where 1 indicates a fully correct solution and values below 1 reflect increasing degrees of error severity.</p>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="variants">Variants<a href="#variants" class="hash-link" aria-label="Direct link to Variants" title="Direct link to Variants" translate="no">​</a></h2>
<table><thead><tr><th>Variant</th><th>Description</th><th>Application</th></tr></thead><tbody><tr><td><em>CodeJudge A.S.</em></td><td>Binary correctness evaluation using Analyze-Then-Summarize</td><td>HumanEval-X, APPS, BigCodeBench</td></tr><tr><td><em>CodeJudge F.L.</em></td><td>Graded correctness using Taxonomy-Guided Fault Localization</td><td>CoNaLa (Human-annotated code usefulness)</td></tr><tr><td><em>CodeJudge w/o REF</em></td><td>Reference-free version for scenarios without ground-truth code</td><td>Online evaluation, developer assistance tools</td></tr><tr><td><em>Few-Shot &amp; CoT Variants</em></td><td>Incorporate examples or chain-of-thought reasoning, but found less effective than A.S.</td><td>Research extensions</td></tr></tbody></table>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="evaluation-and-results">Evaluation and Results<a href="#evaluation-and-results" class="hash-link" aria-label="Direct link to Evaluation and Results" title="Direct link to Evaluation and Results" translate="no">​</a></h2>
<p>Across multiple benchmarks (HumanEval-X, CoNaLa, APPS, BigCodeBench), CodeJudge consistently outperformed existing methods such as ICE-Score, CodeBLEU, and CodeBERTScore, achieving higher correlation with human judgment.</p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="example-results-gpt-35-turbo-1106">Example Results (GPT-3.5-Turbo-1106)<a href="#example-results-gpt-35-turbo-1106" class="hash-link" aria-label="Direct link to Example Results (GPT-3.5-Turbo-1106)" title="Direct link to Example Results (GPT-3.5-Turbo-1106)" translate="no">​</a></h3>
<table><thead><tr><th>Dataset</th><th>Kendall’s τ</th><th>Spearman’s ρ</th><th>Accuracy (%)</th></tr></thead><tbody><tr><td>HumanEval-X</td><td>0.612</td><td>0.612</td><td>80.56</td></tr><tr><td>CoNaLa</td><td>0.478</td><td>0.562</td><td>—</td></tr><tr><td>APPS</td><td>0.354</td><td>0.354</td><td>68.33</td></tr><tr><td>BigCodeBench</td><td>0.392</td><td>0.392</td><td>74.56</td></tr></tbody></table>
<p>Even without reference code, CodeJudge maintained strong correlation (τ = 0.502) and 73% accuracy, demonstrating its ability to evaluate code semantically rather than syntactically.</p>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="interpretation">Interpretation<a href="#interpretation" class="hash-link" aria-label="Direct link to Interpretation" title="Direct link to Interpretation" translate="no">​</a></h2>
<p>CodeJudge redefines automated code evaluation by simulating human-like review reasoning.<br>
<!-- -->Instead of pass/fail based solely on execution, it evaluates how code meets or deviates from intended logic.</p>
<p>Key interpretative strengths:</p>
<ul>
<li><em>No test cases required:</em> Effective in open-ended tasks.</li>
<li><em>Supports partial correctness:</em> Differentiates between minor and severe issues.</li>
<li><em>Cross-language generalization:</em> Valid across Python, Java, C++, JavaScript, Go.</li>
<li><em>LLM adaptability:</em> Works with GPT-3.5, Llama-3 (8B, 70B), CodeLlama, etc.</li>
</ul>
<p>Limitations include occasional overemphasis on error handling and misinterpretation of complex logic in advanced benchmarks like APPS.</p>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="comparison-with-ice-score">Comparison with ICE-Score<a href="#comparison-with-ice-score" class="hash-link" aria-label="Direct link to Comparison with ICE-Score" title="Direct link to Comparison with ICE-Score" translate="no">​</a></h2>
<table><thead><tr><th>Feature</th><th>ICE-Score</th><th>CodeJudge</th></tr></thead><tbody><tr><td>Test-case independence</td><td>✓</td><td>✓</td></tr><tr><td>Partial correctness scoring</td><td>✗</td><td>✓</td></tr><tr><td>Reasoning process</td><td>Single-step</td><td>Slow thinking (multi-step)</td></tr><tr><td>Reference-free evaluation</td><td>Limited</td><td>Supported</td></tr><tr><td>Correlation with ground truth</td><td>Moderate</td><td>High (&gt;0.6)</td></tr></tbody></table>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="applications-in-software-engineering">Applications in Software Engineering<a href="#applications-in-software-engineering" class="hash-link" aria-label="Direct link to Applications in Software Engineering" title="Direct link to Applications in Software Engineering" translate="no">​</a></h2>
<ul>
<li><em>Code generation evaluation:</em> Measures semantic correctness across diverse programming tasks.</li>
<li><em>Developer feedback systems:</em> Enables automated quality feedback without tests.</li>
<li><em>Benchmarking frameworks:</em> Used in HumanEval-X, CoNaLa, APPS, BigCodeBench.</li>
<li><em>Code repair and debugging:</em> Identifies logic-level inconsistencies for refinement loops.</li>
</ul>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="limitations">Limitations<a href="#limitations" class="hash-link" aria-label="Direct link to Limitations" title="Direct link to Limitations" translate="no">​</a></h2>
<p>While CodeJudge shows strong correlation with human evaluation, challenges remain:</p>
<ul>
<li>Misjudgments in complex control flows or large functions.</li>
<li>Overestimation of “error-handling” needs.</li>
<li>Sensitivity to incomplete prompts in zero-shot settings.</li>
</ul>
<p>Future work involves integrating dynamic execution tracing and improving the weighting of minor vs. major inconsistencies.</p>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="references">References<a href="#references" class="hash-link" aria-label="Direct link to References" title="Direct link to References" translate="no">​</a></h2>
<ol>
<li>
<p><em>Tong, W., &amp; Zhang, T. (2024).</em> CodeJudge: Evaluating Code Generation with Large Language Models.<br>
<!-- -->arXiv:2410.02184 [cs.LG].<br>
<a href="https://arxiv.org/abs/2410.02184" target="_blank" rel="noopener noreferrer">https://arxiv.org/abs/2410.02184</a></p>
</li>
<li>
<p><em>Zhuo, T. Y. (2024).</em> ICE-Score: Instructing Large Language Models to Evaluate Code.<br>
<!-- -->Findings of the Association for Computational Linguistics: EACL 2024.<br>
<a href="https://aclanthology.org/2024.findings-eacl.148" target="_blank" rel="noopener noreferrer">https://aclanthology.org/2024.findings-eacl.148</a></p>
</li>
<li>
<p><em>Evtikhiev, M., Bogomolov, E., Sokolov, Y., &amp; Bryksin, T. (2023).</em> Out of the BLEU: How Should We Assess Quality of the Code Generation Models?<br>
<!-- -->Journal of Systems and Software, 203:111741.<br>
<a href="https://doi.org/10.1016/j.jss.2023.111741" target="_blank" rel="noopener noreferrer">https://doi.org/10.1016/j.jss.2023.111741</a></p>
</li>
</ol></div></article><nav class="docusaurus-mt-lg pagination-nav" aria-label="Docs pages"><a class="pagination-nav__link pagination-nav__link--prev" href="/LLMs-metrics-catalog/metrics/code-structural/bugs"><div class="pagination-nav__sublabel">Previous</div><div class="pagination-nav__label">Bug Metrics</div></a><a class="pagination-nav__link pagination-nav__link--next" href="/LLMs-metrics-catalog/metrics/code-structural/compilation"><div class="pagination-nav__sublabel">Next</div><div class="pagination-nav__label">Compilation Metrics</div></a></nav></div></div><div class="col col--3"><div class="tableOfContents_bqdL thin-scrollbar theme-doc-toc-desktop"><ul class="table-of-contents table-of-contents__left-border"><li><a href="#introduction" class="table-of-contents__link toc-highlight">Introduction</a></li><li><a href="#formula-and-scoring-mechanism" class="table-of-contents__link toc-highlight">Formula and Scoring Mechanism</a><ul><li><a href="#1-analyze-then-summarize" class="table-of-contents__link toc-highlight">1. Analyze-Then-Summarize</a></li><li><a href="#2-taxonomy-guided-fault-localization" class="table-of-contents__link toc-highlight">2. Taxonomy-Guided Fault Localization</a></li></ul></li><li><a href="#variants" class="table-of-contents__link toc-highlight">Variants</a></li><li><a href="#evaluation-and-results" class="table-of-contents__link toc-highlight">Evaluation and Results</a><ul><li><a href="#example-results-gpt-35-turbo-1106" class="table-of-contents__link toc-highlight">Example Results (GPT-3.5-Turbo-1106)</a></li></ul></li><li><a href="#interpretation" class="table-of-contents__link toc-highlight">Interpretation</a></li><li><a href="#comparison-with-ice-score" class="table-of-contents__link toc-highlight">Comparison with ICE-Score</a></li><li><a href="#applications-in-software-engineering" class="table-of-contents__link toc-highlight">Applications in Software Engineering</a></li><li><a href="#limitations" class="table-of-contents__link toc-highlight">Limitations</a></li><li><a href="#references" class="table-of-contents__link toc-highlight">References</a></li></ul></div></div></div></div></main></div></div></div></div>
</body>
</html>