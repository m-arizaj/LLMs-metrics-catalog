<!doctype html>
<html lang="en" dir="ltr" class="docs-wrapper plugin-docs plugin-id-default docs-version-current docs-doc-page docs-doc-id-references" data-has-hydrated="false">
<head>
<meta charset="UTF-8">
<meta name="generator" content="Docusaurus v3.9.1">
<title data-rh="true">References | LLM Metrics Catalog</title><meta data-rh="true" name="viewport" content="width=device-width,initial-scale=1"><meta data-rh="true" name="twitter:card" content="summary_large_image"><meta data-rh="true" property="og:url" content="https://m-arizaj.github.io/LLMs-metrics-catalog/references"><meta data-rh="true" property="og:locale" content="en"><meta data-rh="true" name="docusaurus_locale" content="en"><meta data-rh="true" name="docsearch:language" content="en"><meta data-rh="true" name="docusaurus_version" content="current"><meta data-rh="true" name="docusaurus_tag" content="docs-default-current"><meta data-rh="true" name="docsearch:version" content="current"><meta data-rh="true" name="docsearch:docusaurus_tag" content="docs-default-current"><meta data-rh="true" property="og:title" content="References | LLM Metrics Catalog"><meta data-rh="true" name="description" content="This page lists all source papers used in the LLMs Metrics Catalog. Click each ID to open the corresponding DOI link."><meta data-rh="true" property="og:description" content="This page lists all source papers used in the LLMs Metrics Catalog. Click each ID to open the corresponding DOI link."><link data-rh="true" rel="canonical" href="https://m-arizaj.github.io/LLMs-metrics-catalog/references"><link data-rh="true" rel="alternate" href="https://m-arizaj.github.io/LLMs-metrics-catalog/references" hreflang="en"><link data-rh="true" rel="alternate" href="https://m-arizaj.github.io/LLMs-metrics-catalog/references" hreflang="x-default"><script data-rh="true" type="application/ld+json">{"@context":"https://schema.org","@type":"BreadcrumbList","itemListElement":[{"@type":"ListItem","position":1,"name":"References","item":"https://m-arizaj.github.io/LLMs-metrics-catalog/references"}]}</script><link rel="stylesheet" href="/LLMs-metrics-catalog/assets/css/styles.422c2d42.css">
<script src="/LLMs-metrics-catalog/assets/js/runtime~main.e4eec439.js" defer="defer"></script>
<script src="/LLMs-metrics-catalog/assets/js/main.b6316d61.js" defer="defer"></script>
</head>
<body class="navigation-with-keyboard">
<svg style="display: none;"><defs>
<symbol id="theme-svg-external-link" viewBox="0 0 24 24"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"/></symbol>
</defs></svg>
<script>!function(){var t=function(){try{return new URLSearchParams(window.location.search).get("docusaurus-theme")}catch(t){}}()||function(){try{return window.localStorage.getItem("theme")}catch(t){}}();document.documentElement.setAttribute("data-theme",t||"light"),document.documentElement.setAttribute("data-theme-choice",t||"light")}(),function(){try{const c=new URLSearchParams(window.location.search).entries();for(var[t,e]of c)if(t.startsWith("docusaurus-data-")){var a=t.replace("docusaurus-data-","data-");document.documentElement.setAttribute(a,e)}}catch(t){}}()</script><div id="__docusaurus"><div role="region" aria-label="Skip to main content"><a class="skipToContent_fXgn" href="#__docusaurus_skipToContent_fallback">Skip to main content</a></div><nav aria-label="Main" class="theme-layout-navbar navbar navbar--fixed-top"><div class="navbar__inner"><div class="theme-layout-navbar-left navbar__items"><a class="navbar__brand" href="/LLMs-metrics-catalog/"></a></div><div class="theme-layout-navbar-right navbar__items navbar__items--right"><div class="toggle_vylO colorModeToggle_DEke"><button class="clean-btn toggleButton_gllP toggleButtonDisabled_aARS" type="button" disabled="" title="system mode" aria-label="Switch between dark and light mode (currently system mode)"><svg viewBox="0 0 24 24" width="24" height="24" aria-hidden="true" class="toggleIcon_g3eP lightToggleIcon_pyhR"><path fill="currentColor" d="M12,9c1.65,0,3,1.35,3,3s-1.35,3-3,3s-3-1.35-3-3S10.35,9,12,9 M12,7c-2.76,0-5,2.24-5,5s2.24,5,5,5s5-2.24,5-5 S14.76,7,12,7L12,7z M2,13l2,0c0.55,0,1-0.45,1-1s-0.45-1-1-1l-2,0c-0.55,0-1,0.45-1,1S1.45,13,2,13z M20,13l2,0c0.55,0,1-0.45,1-1 s-0.45-1-1-1l-2,0c-0.55,0-1,0.45-1,1S19.45,13,20,13z M11,2v2c0,0.55,0.45,1,1,1s1-0.45,1-1V2c0-0.55-0.45-1-1-1S11,1.45,11,2z M11,20v2c0,0.55,0.45,1,1,1s1-0.45,1-1v-2c0-0.55-0.45-1-1-1C11.45,19,11,19.45,11,20z M5.99,4.58c-0.39-0.39-1.03-0.39-1.41,0 c-0.39,0.39-0.39,1.03,0,1.41l1.06,1.06c0.39,0.39,1.03,0.39,1.41,0s0.39-1.03,0-1.41L5.99,4.58z M18.36,16.95 c-0.39-0.39-1.03-0.39-1.41,0c-0.39,0.39-0.39,1.03,0,1.41l1.06,1.06c0.39,0.39,1.03,0.39,1.41,0c0.39-0.39,0.39-1.03,0-1.41 L18.36,16.95z M19.42,5.99c0.39-0.39,0.39-1.03,0-1.41c-0.39-0.39-1.03-0.39-1.41,0l-1.06,1.06c-0.39,0.39-0.39,1.03,0,1.41 s1.03,0.39,1.41,0L19.42,5.99z M7.05,18.36c0.39-0.39,0.39-1.03,0-1.41c-0.39-0.39-1.03-0.39-1.41,0l-1.06,1.06 c-0.39,0.39-0.39,1.03,0,1.41s1.03,0.39,1.41,0L7.05,18.36z"></path></svg><svg viewBox="0 0 24 24" width="24" height="24" aria-hidden="true" class="toggleIcon_g3eP darkToggleIcon_wfgR"><path fill="currentColor" d="M9.37,5.51C9.19,6.15,9.1,6.82,9.1,7.5c0,4.08,3.32,7.4,7.4,7.4c0.68,0,1.35-0.09,1.99-0.27C17.45,17.19,14.93,19,12,19 c-3.86,0-7-3.14-7-7C5,9.07,6.81,6.55,9.37,5.51z M12,3c-4.97,0-9,4.03-9,9s4.03,9,9,9s9-4.03,9-9c0-0.46-0.04-0.92-0.1-1.36 c-0.98,1.37-2.58,2.26-4.4,2.26c-2.98,0-5.4-2.42-5.4-5.4c0-1.81,0.89-3.42,2.26-4.4C12.92,3.04,12.46,3,12,3L12,3z"></path></svg><svg viewBox="0 0 24 24" width="24" height="24" aria-hidden="true" class="toggleIcon_g3eP systemToggleIcon_QzmC"><path fill="currentColor" d="m12 21c4.971 0 9-4.029 9-9s-4.029-9-9-9-9 4.029-9 9 4.029 9 9 9zm4.95-13.95c1.313 1.313 2.05 3.093 2.05 4.95s-0.738 3.637-2.05 4.95c-1.313 1.313-3.093 2.05-4.95 2.05v-14c1.857 0 3.637 0.737 4.95 2.05z"></path></svg></button></div><div class="navbarSearchContainer_Bca1"><div class="navbar__search searchBarContainer_NW3z" dir="ltr"><input placeholder="Search" aria-label="Search" class="navbar__search-input searchInput_YFbd" value=""><div class="loadingRing_RJI3 searchBarLoadingRing_YnHq"><div></div><div></div><div></div><div></div></div></div></div></div></div><div role="presentation" class="navbar-sidebar__backdrop"></div></nav><div id="__docusaurus_skipToContent_fallback" class="theme-layout-main main-wrapper mainWrapper_z2l0"><div class="docsWrapper_hBAB"><button aria-label="Scroll back to top" class="clean-btn theme-back-to-top-button backToTopButton_sjWU" type="button"></button><div class="docRoot_UBD9"><aside class="theme-doc-sidebar-container docSidebarContainer_YfHR"><div class="sidebarViewport_aRkj"><div class="sidebar_njMd"><nav aria-label="Docs sidebar" class="menu thin-scrollbar menu_SIkG"><ul class="theme-doc-sidebar-menu menu__list"><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-1 menu__list-item"><a class="menu__link" href="/LLMs-metrics-catalog/intro"><span title="Introduction" class="linkLabel_WmDU">Introduction</span></a></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist menu__link--sublist-caret" role="button" aria-expanded="true" href="/LLMs-metrics-catalog/metrics/accuracy-overlap/bleu"><span title="Core Accuracy &amp; Overlap Metrics" class="categoryLinkLabel_W154">Core Accuracy &amp; Overlap Metrics</span></a></div><ul class="menu__list"><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/LLMs-metrics-catalog/metrics/accuracy-overlap/bleu"><span title="BLEU" class="linkLabel_WmDU">BLEU</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/LLMs-metrics-catalog/metrics/accuracy-overlap/accuracy"><span title="Accuracy" class="linkLabel_WmDU">Accuracy</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/LLMs-metrics-catalog/metrics/accuracy-overlap/pass-at-k"><span title="Pass@k" class="linkLabel_WmDU">Pass@k</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/LLMs-metrics-catalog/metrics/accuracy-overlap/f1-score"><span title="F1-Score" class="linkLabel_WmDU">F1-Score</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/LLMs-metrics-catalog/metrics/accuracy-overlap/exact-match"><span title="Exact Match" class="linkLabel_WmDU">Exact Match</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/LLMs-metrics-catalog/metrics/accuracy-overlap/rouge"><span title="ROUGE" class="linkLabel_WmDU">ROUGE</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/LLMs-metrics-catalog/metrics/accuracy-overlap/recall"><span title="Recall" class="linkLabel_WmDU">Recall</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/LLMs-metrics-catalog/metrics/accuracy-overlap/precision"><span title="Precision" class="linkLabel_WmDU">Precision</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/LLMs-metrics-catalog/metrics/accuracy-overlap/meteor"><span title="Meteor" class="linkLabel_WmDU">Meteor</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/LLMs-metrics-catalog/metrics/accuracy-overlap/edit-distance"><span title="Edit Distance" class="linkLabel_WmDU">Edit Distance</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/LLMs-metrics-catalog/metrics/accuracy-overlap/mrr"><span title="Mean Reciprocal Rank" class="linkLabel_WmDU">Mean Reciprocal Rank</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/LLMs-metrics-catalog/metrics/accuracy-overlap/swe"><span title="SE-Jury Score" class="linkLabel_WmDU">SE-Jury Score</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/LLMs-metrics-catalog/metrics/accuracy-overlap/bertscore"><span title="BERTScore" class="linkLabel_WmDU">BERTScore</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/LLMs-metrics-catalog/metrics/accuracy-overlap/coverage"><span title="Coverage" class="linkLabel_WmDU">Coverage</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/LLMs-metrics-catalog/metrics/accuracy-overlap/chrf"><span title="chrF" class="linkLabel_WmDU">chrF</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/LLMs-metrics-catalog/metrics/accuracy-overlap/codescore"><span title="CodeScore" class="linkLabel_WmDU">CodeScore</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/LLMs-metrics-catalog/metrics/accuracy-overlap/moverscore"><span title="MoverScore" class="linkLabel_WmDU">MoverScore</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/LLMs-metrics-catalog/metrics/accuracy-overlap/comet"><span title="COMET" class="linkLabel_WmDU">COMET</span></a></li></ul></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist menu__link--sublist-caret" role="button" aria-expanded="true" href="/LLMs-metrics-catalog/metrics/statistical/ice-score"><span title="Statistical &amp; Correlation Metrics" class="categoryLinkLabel_W154">Statistical &amp; Correlation Metrics</span></a></div><ul class="menu__list"><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/LLMs-metrics-catalog/metrics/statistical/ice-score"><span title="ICE-Score" class="linkLabel_WmDU">ICE-Score</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/LLMs-metrics-catalog/metrics/statistical/kendall"><span title="Kendall’s τ" class="linkLabel_WmDU">Kendall’s τ</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/LLMs-metrics-catalog/metrics/statistical/spearman"><span title="Spearman’s ρ" class="linkLabel_WmDU">Spearman’s ρ</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/LLMs-metrics-catalog/metrics/statistical/pearson"><span title="Pearson’s r" class="linkLabel_WmDU">Pearson’s r</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/LLMs-metrics-catalog/metrics/statistical/cohen"><span title="Cohen&#x27;s Score" class="linkLabel_WmDU">Cohen&#x27;s Score</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/LLMs-metrics-catalog/metrics/statistical/smape"><span title="Smape" class="linkLabel_WmDU">Smape</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/LLMs-metrics-catalog/metrics/statistical/rate"><span title="Rate Metrics" class="linkLabel_WmDU">Rate Metrics</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/LLMs-metrics-catalog/metrics/statistical/average"><span title="Average Metrics" class="linkLabel_WmDU">Average Metrics</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/LLMs-metrics-catalog/metrics/statistical/fault-localization-rank"><span title="FL Rank Metrics" class="linkLabel_WmDU">FL Rank Metrics</span></a></li></ul></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist menu__link--sublist-caret" role="button" aria-expanded="true" href="/LLMs-metrics-catalog/metrics/code-structural/ast-metrics"><span title="Code Quality &amp; Structural Metrics" class="categoryLinkLabel_W154">Code Quality &amp; Structural Metrics</span></a></div><ul class="menu__list"><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/LLMs-metrics-catalog/metrics/code-structural/ast-metrics"><span title="AST Metrics" class="linkLabel_WmDU">AST Metrics</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/LLMs-metrics-catalog/metrics/code-structural/edition-metrics"><span title="Edition Metrics" class="linkLabel_WmDU">Edition Metrics</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/LLMs-metrics-catalog/metrics/code-structural/bugs"><span title="Bug Metrics" class="linkLabel_WmDU">Bug Metrics</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/LLMs-metrics-catalog/metrics/code-structural/codejudge"><span title="CodeJudge" class="linkLabel_WmDU">CodeJudge</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/LLMs-metrics-catalog/metrics/code-structural/compilation"><span title="Compilation Metrics" class="linkLabel_WmDU">Compilation Metrics</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/LLMs-metrics-catalog/metrics/code-structural/complexity"><span title="Complexity Metrics" class="linkLabel_WmDU">Complexity Metrics</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/LLMs-metrics-catalog/metrics/code-structural/code-style"><span title="Code Style Adherence" class="linkLabel_WmDU">Code Style Adherence</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/LLMs-metrics-catalog/metrics/code-structural/cohesion"><span title="Cohesion and Decoupling" class="linkLabel_WmDU">Cohesion and Decoupling</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/LLMs-metrics-catalog/metrics/code-structural/correctness"><span title="Correctness" class="linkLabel_WmDU">Correctness</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/LLMs-metrics-catalog/metrics/code-structural/count"><span title="Count Metrics" class="linkLabel_WmDU">Count Metrics</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/LLMs-metrics-catalog/metrics/code-structural/build"><span title="Build Metrics" class="linkLabel_WmDU">Build Metrics</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/LLMs-metrics-catalog/metrics/code-structural/ranked-retrieval"><span title="Ranked Retrieval" class="linkLabel_WmDU">Ranked Retrieval</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/LLMs-metrics-catalog/metrics/code-structural/dataflow"><span title="Data-Flow Match" class="linkLabel_WmDU">Data-Flow Match</span></a></li></ul></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist menu__link--sublist-caret" role="button" aria-expanded="true" href="/LLMs-metrics-catalog/metrics/functional-test/error"><span title="Functional &amp; Test-based Evaluation" class="categoryLinkLabel_W154">Functional &amp; Test-based Evaluation</span></a></div><ul class="menu__list"><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/LLMs-metrics-catalog/metrics/functional-test/error"><span title="Error Metrics" class="linkLabel_WmDU">Error Metrics</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/LLMs-metrics-catalog/metrics/functional-test/percentage"><span title="Percentage Metrics" class="linkLabel_WmDU">Percentage Metrics</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/LLMs-metrics-catalog/metrics/functional-test/number"><span title="Number Metrics" class="linkLabel_WmDU">Number Metrics</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/LLMs-metrics-catalog/metrics/functional-test/test"><span title="Test Metrics" class="linkLabel_WmDU">Test Metrics</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/LLMs-metrics-catalog/metrics/functional-test/mutant-killings"><span title="Mutant Killings" class="linkLabel_WmDU">Mutant Killings</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/LLMs-metrics-catalog/metrics/functional-test/solution-metrics"><span title="Solution-Based Metrics" class="linkLabel_WmDU">Solution-Based Metrics</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/LLMs-metrics-catalog/metrics/functional-test/reasoning-depth"><span title="Reasoning Depth" class="linkLabel_WmDU">Reasoning Depth</span></a></li></ul></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist menu__link--sublist-caret" role="button" aria-expanded="false" href="/LLMs-metrics-catalog/metrics/human"><span title="Human &amp; Subjective Evaluation" class="categoryLinkLabel_W154">Human &amp; Subjective Evaluation</span></a></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist menu__link--sublist-caret" role="button" aria-expanded="false" href="/LLMs-metrics-catalog/metrics/generative/amber-score"><span title="Generative &amp; Distribution Metrics" class="categoryLinkLabel_W154">Generative &amp; Distribution Metrics</span></a></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist menu__link--sublist-caret" role="button" aria-expanded="false" href="/LLMs-metrics-catalog/metrics/logical/difference-automata"><span title="Logical Reasoning &amp; Verification" class="categoryLinkLabel_W154">Logical Reasoning &amp; Verification</span></a></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist menu__link--sublist-caret" role="button" aria-expanded="false" href="/LLMs-metrics-catalog/metrics/robustness/ct-score"><span title="Robustness, Security &amp; Reliability" class="categoryLinkLabel_W154">Robustness, Security &amp; Reliability</span></a></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist menu__link--sublist-caret" role="button" aria-expanded="false" href="/LLMs-metrics-catalog/metrics/efficiency/time"><span title="Efficiency &amp; Resource Usage" class="categoryLinkLabel_W154">Efficiency &amp; Resource Usage</span></a></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist menu__link--sublist-caret" role="button" aria-expanded="false" href="/LLMs-metrics-catalog/metrics/architectural/composite"><span title="Architectural &amp; System-level Metrics" class="categoryLinkLabel_W154">Architectural &amp; System-level Metrics</span></a></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist menu__link--sublist-caret" role="button" aria-expanded="false" href="/LLMs-metrics-catalog/metrics/creativity/dialogue-similarities"><span title="Creativity, Diversity &amp; Novelty" class="categoryLinkLabel_W154">Creativity, Diversity &amp; Novelty</span></a></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist menu__link--sublist-caret" role="button" aria-expanded="false" href="/LLMs-metrics-catalog/metrics/ranking/elo-score"><span title="Ranking, Reward &amp; Optimization" class="categoryLinkLabel_W154">Ranking, Reward &amp; Optimization</span></a></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist menu__link--sublist-caret" role="button" aria-expanded="false" href="/LLMs-metrics-catalog/metrics/semantic/hallucination"><span title="Semantic, Coherence &amp; Hallucination" class="categoryLinkLabel_W154">Semantic, Coherence &amp; Hallucination</span></a></div></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-1 menu__list-item"><a class="menu__link menu__link--active" aria-current="page" href="/LLMs-metrics-catalog/references"><span title="References" class="linkLabel_WmDU">References</span></a></li></ul></nav></div></div></aside><main class="docMainContainer_TBSr"><div class="container padding-top--md padding-bottom--lg"><div class="row"><div class="col docItemCol_VOVn"><div class="docItemContainer_Djhp"><article><nav class="theme-doc-breadcrumbs breadcrumbsContainer_Z_bl" aria-label="Breadcrumbs"><ul class="breadcrumbs"><li class="breadcrumbs__item"><a aria-label="Home page" class="breadcrumbs__link" href="/LLMs-metrics-catalog/"><svg viewBox="0 0 24 24" class="breadcrumbHomeIcon_YNFT"><path d="M10 19v-5h4v5c0 .55.45 1 1 1h3c.55 0 1-.45 1-1v-7h1.7c.46 0 .68-.57.33-.87L12.67 3.6c-.38-.34-.96-.34-1.34 0l-8.36 7.53c-.34.3-.13.87.33.87H5v7c0 .55.45 1 1 1h3c.55 0 1-.45 1-1z" fill="currentColor"></path></svg></a></li><li class="breadcrumbs__item breadcrumbs__item--active"><span class="breadcrumbs__link">References</span></li></ul></nav><div class="theme-doc-markdown markdown"><header><h1>References</h1></header><p>This page lists all source papers used in the LLMs Metrics Catalog. Click each ID to open the corresponding DOI link.</p>
<ul>
<li><a href="https://doi.org/10.1109/SWC62898.2024.00231" target="_blank" rel="noopener noreferrer"><strong>1</strong></a> — L. Lin, D. Zhu and J. Shang, &quot;Overview of the Comprehensive Evaluation of Large Language Models,&quot; 2024 IEEE Smart World Congress (SWC), Nadi, Fiji, 2024, pp. 1504-1512</li>
<li><a href="https://doi.org/10.48550/arXiv.2404.09135" target="_blank" rel="noopener noreferrer"><strong>2</strong></a> — Hu, T., &amp; Zhou, X.-H. (2024). Unveiling LLM Evaluation Focused on Metrics: Challenges and Solutions (Version 1). arXiv.</li>
<li><a href="https://elib.dlr.de/217570/1/Bektas_Ali_MA.pdf" target="_blank" rel="noopener noreferrer"><strong>3</strong></a> — A. Bektas (2025). Large Language Models in Software Engineering: A Critical Review of Evaluation Strategies. Freie Universität Berlin</li>
<li><a href="https://doi.org/10.48550/arXiv.2211.09110" target="_blank" rel="noopener noreferrer"><strong>4</strong></a> — Liang, P., Bommasani, R., Lee, T., Tsipras, D., Soylu, D., Yasunaga, M., Zhang, Y., Narayanan, D., Wu, Y., Kumar, A., Newman, B., Yuan, B., Yan, B., Zhang, C., Cosgrove, C., Manning, C. D., Ré, C., Acosta-Navas, D., Hudson, D. A., … Koreeda, Y. (2022). Holistic Evaluation of Language Models. arXiv.</li>
<li><a href="https://doi.org/10.48550/arXiv.2310.19736" target="_blank" rel="noopener noreferrer"><strong>5</strong></a> — Guo, Z., Jin, R., Liu, C., Huang, Y., Shi, D., Supryadi, Yu, L., Liu, Y., Li, J., Xiong, B., &amp; Xiong, D. (2023). Evaluating Large Language Models: A Comprehensive Survey (Version 3). arXiv.</li>
<li><a href="https://doi.org/10.48550/arXiv.2308.10620" target="_blank" rel="noopener noreferrer"><strong>6</strong></a> — Hou, X., Zhao, Y., Liu, Y., Yang, Z., Wang, K., Li, L., Luo, X., Lo, D., Grundy, J., &amp; Wang, H. (2023). Large Language Models for Software Engineering: A Systematic Literature Review (Version 6). arXiv.</li>
<li><a href="https://doi.org/10.48550/arXiv.2505.08903" target="_blank" rel="noopener noreferrer"><strong>7</strong></a> — Hu, X., Niu, F., Chen, J., Zhou, X., Zhang, J., He, J., Xia, X., &amp; Lo, D. (2025). Assessing and Advancing Benchmarks for Evaluating Large Language Models in Software Engineering Tasks (Version 4). arXiv.</li>
<li><a href="https://doi.org/10.48550/arXiv.2311.07397" target="_blank" rel="noopener noreferrer"><strong>8</strong></a> — Wang, J., Wang, Y., Xu, G., Zhang, J., Gu, Y., Jia, H., Wang, J., Xu, H., Yan, M., Zhang, J., &amp; Sang, J. (2023). AMBER: An LLM-free Multi-dimensional Benchmark for MLLMs Hallucination Evaluation (Version 2). arXiv.</li>
<li><a href="https://doi.org/10.48550/arXiv.2307.03109" target="_blank" rel="noopener noreferrer"><strong>9</strong></a> — Chang, Y., Wang, X., Wang, J., Wu, Y., Yang, L., Zhu, K., Chen, H., Yi, X., Wang, C., Wang, Y., Ye, W., Zhang, Y., Chang, Y., Yu, P. S., Yang, Q., &amp; Xie, X. (2023). A Survey on Evaluation of Large Language Models (Version 9). arXiv.</li>
<li><a href="https://doi.org/10.48550/arXiv.2408.16498" target="_blank" rel="noopener noreferrer"><strong>10</strong></a> — Chen, L., Guo, Q., Jia, H., Zeng, Z., Wang, X., Xu, Y., Wu, J., Wang, Y., Gao, Q., Wang, J., Ye, W., &amp; Zhang, S. (2024). A Survey on Evaluating Large Language Models in Code Generation Tasks (Version 2). arXiv.</li>
<li><a href="https://doi.org/10.48550/arXiv.2505.20854" target="_blank" rel="noopener noreferrer"><strong>11</strong></a> — Zhou, X., Kim, K., Zhang, T., Weyssow, M., Gomes, L. F., Yang, G., Liu, K., Xia, X., &amp; Lo, D. (2025). An LLM-as-Judge Metric for Bridging the Gap with Human Evaluation in SE Tasks (Version 2). arXiv.</li>
<li><a href="https://doi.org/10.48550/arXiv.2304.14317" target="_blank" rel="noopener noreferrer"><strong>12</strong></a> — Zhuo, T. Y. (2023). ICE-Score: Instructing Large Language Models to Evaluate Code (Version 2). arXiv.</li>
<li><a href="https://doi.org/10.48550/arXiv.2403.08604" target="_blank" rel="noopener noreferrer"><strong>13</strong></a> — Li, B., Wu, W., Tang, Z., Shi, L., Yang, J., Li, J., Yao, S., Qian, C., Hui, B., Zhang, Q., Yu, Z., Du, H., Yang, P., Lin, D., Peng, C., &amp; Chen, K. (2024). Prompting Large Language Models to Tackle the Full Software Development Lifecycle: A Case Study (Version 3). arXiv.</li>
<li><a href="https://doi.org/10.48550/arXiv.2310.06770" target="_blank" rel="noopener noreferrer"><strong>14</strong></a> — Jimenez, C. E., Yang, J., Wettig, A., Yao, S., Pei, K., Press, O., &amp; Narasimhan, K. (2023). SWE-bench: Can Language Models Resolve Real-World GitHub Issues? (Version 3). arXiv.</li>
<li><a href="https://doi.org/10.48550/arXiv.2206.04615" target="_blank" rel="noopener noreferrer"><strong>15</strong></a> — Srivastava, A., Rastogi, A., Rao, A., Shoeb, A. A. M., Abid, A., Fisch, A., Brown, A. R., Santoro, A., Gupta, A., Garriga-Alonso, A., Kluska, A., Lewkowycz, A., Agarwal, A., Power, A., Ray, A., Warstadt, A., Kocurek, A. W., Safaya, A., Tazarv, A., … Wu, Z. (2022). Beyond the Imitation Game: Quantifying and extrapolating the capabilities of language models. arXiv.</li>
<li><a href="https://doi.org/10.1162/coli_a_00524" target="_blank" rel="noopener noreferrer"><strong>16</strong></a> — Gallegos, I. O., Rossi, R. A., Barrow, J., Tanjim, M. M., Kim, S., Dernoncourt, F., Yu, T., Zhang, R., &amp; Ahmed, N. K. (2024). Bias and Fairness in Large Language Models: A Survey. Computational Linguistics, 50(3), 1097–1179.</li>
<li><a href="https://doi.org/10.56038/oprd.v4i1.444" target="_blank" rel="noopener noreferrer"><strong>17</strong></a> — Ersoy, P., &amp; Erşahin, M. (2024). Benchmarking Llama 3 70B for Code Generation: A Comprehensive Evaluation. Orclever Proceedings of Research and Development, 4(1), 52–58.</li>
<li><a href="https://doi.org/10.56155/978-81-955020-9-7-24" target="_blank" rel="noopener noreferrer"><strong>18</strong></a> — Anand, A., Chopra, S., &amp; Arora, M. (2024). Analysis of LLM Code Synthesis in Software Productivity. In Applied Intelligence and Computing (pp. 247–259). Soft Computing Research Society.</li>
<li><a href="https://doi.org/10.48550/arXiv.2406.12655" target="_blank" rel="noopener noreferrer"><strong>19</strong></a> — Paul, D. G., Zhu, H., &amp; Bayley, I. (2024). Benchmarks and Metrics for Evaluations of Code Generation: A Critical Review (Version 1). arXiv.</li>
<li><a href="https://doi.org/10.48550/arXiv.2305.01210" target="_blank" rel="noopener noreferrer"><strong>20</strong></a> — Liu, J., Xia, C. S., Wang, Y., &amp; Zhang, L. (2023). Is Your Code Generated by ChatGPT Really Correct? Rigorous Evaluation of Large Language Models for Code Generation (Version 3). arXiv.</li>
<li><a href="https://doi.org/10.4218/etrij.2023-0357" target="_blank" rel="noopener noreferrer"><strong>21</strong></a> — Yeo, S., Ma, Y., Kim, S. C., Jun, H., &amp; Kim, T. (2024). Framework for evaluating code generation ability of large language models. ETRI Journal, 46(1), 106–117.</li>
<li><a href="https://doi.org/10.48550/arXiv.2401.06401" target="_blank" rel="noopener noreferrer"><strong>22</strong></a> — Li, J., Li, G., Zhao, Y., Li, Y., Jin, Z., Zhu, H., Liu, H., Liu, K., Wang, L., Fang, Z., Wang, L., Ding, J., Zhang, X., Dong, Y., Zhu, Y., Gu, B., &amp; Yang, M. (2024). DevEval: Evaluating Code Generation in Practical Software Projects (Version 4). arXiv.</li>
<li><a href="https://doi.org/10.48550/arXiv.2212.10264" target="_blank" rel="noopener noreferrer"><strong>23</strong></a> — Wang, S., Li, Z., Qian, H., Yang, C., Wang, Z., Shang, M., Kumar, V., Tan, S., Ray, B., Bhatia, P., Nallapati, R., Ramanathan, M. K., Roth, D., &amp; Xiang, B. (2022). ReCode: Robustness Evaluation of Code Generation Models (Version 1). arXiv.</li>
<li><a href="https://doi.org/10.48550/arXiv.2302.05527" target="_blank" rel="noopener noreferrer"><strong>24</strong></a> — Zhou, S., Alon, U., Agarwal, S., &amp; Neubig, G. (2023). CodeBERTScore: Evaluating Code Generation with Pretrained Models of Code (Version 2). arXiv.</li>
<li><a href="https://doi.org/10.1016/j.jss.2023.111741" target="_blank" rel="noopener noreferrer"><strong>25</strong></a> — Evtikhiev, M., Bogomolov, E., Sokolov, Y., &amp; Bryksin, T. (2023). Out of the BLEU: How should we assess quality of the Code Generation models? Journal of Systems and Software, 203, 111741.</li>
<li><a href="https://doi.org/10.48550/arXiv.2406.06902" target="_blank" rel="noopener noreferrer"><strong>26</strong></a> — Yang, G., Zhou, Y., Chen, X., &amp; Zhang, X. (2024). CodeScore-R: An Automated Robustness Metric for Assessing the FunctionalCorrectness of Code Synthesis (Version 1). arXiv.</li>
<li><a href="https://doi.org/10.18653/v1/2024.findings-emnlp.303" target="_blank" rel="noopener noreferrer"><strong>27</strong></a> — Zhang, Y., Wang, S., Qian, H., Wang, Z., Shang, M., Liu, L., Gouda, S. K., Ray, B., Ramanathan, M. K., Ma, X., &amp; Deoras, A. (2024). CodeFort: Robust Training for Code Generation Models. In Findings of the Association for Computational Linguistics: EMNLP 2024 (pp. 5262–5277). Findings of the Association for Computational Linguistics: EMNLP 2024. Association for Computational Linguistics.</li>
<li><a href="https://doi.org/10.1007/s42979-025-04241-5" target="_blank" rel="noopener noreferrer"><strong>28</strong></a> — Bistarelli, S., Fiore, M., Mercanti, I., &amp; Mongiello, M. (2025). Usage of Large Language Model for Code Generation Tasks: A Review. SN Computer Science, 6(6).</li>
<li><a href="https://doi.org/10.1007/s10009-025-00798-x" target="_blank" rel="noopener noreferrer"><strong>29</strong></a> — Busch, D., Bainczyk, A., Smyth, S., &amp; Steffen, B. (2025). LLM-based code generation and system migration in language-driven engineering. International Journal on Software Tools for Technology Transfer, 27(1), 137–147.</li>
<li><a href="https://doi.org/10.1007/s10710-024-09494-2" target="_blank" rel="noopener noreferrer"><strong>30</strong></a> — Hemberg, E., Moskal, S., &amp; O’Reilly, U.-M. (2024). Evolving code with a large language model. Genetic Programming and Evolvable Machines, 25(2).</li>
<li><a href="https://doi.org/10.48550/arXiv.2107.03374" target="_blank" rel="noopener noreferrer"><strong>31</strong></a> — Chen, M., Tworek, J., Jun, H., Yuan, Q., Pinto, H. P. de O., Kaplan, J., Edwards, H., Burda, Y., Joseph, N., Brockman, G., Ray, A., Puri, R., Krueger, G., Petrov, M., Khlaaf, H., Sastry, G., Mishkin, P., Chan, B., Gray, S., … Zaremba, W. (2021). Evaluating Large Language Models Trained on Code (Version 2). arXiv.</li>
<li><a href="https://doi.org/10.48550/arXiv.2102.04664" target="_blank" rel="noopener noreferrer"><strong>32</strong></a> — Lu, S., Guo, D., Ren, S., Huang, J., Svyatkovskiy, A., Blanco, A., Clement, C., Drain, D., Jiang, D., Tang, D., Li, G., Zhou, L., Shou, L., Zhou, L., Tufano, M., Gong, M., Zhou, M., Duan, N., Sundaresan, N., … Liu, S. (2021). CodeXGLUE: A Machine Learning Benchmark Dataset for Code Understanding and Generation (Version 2). arXiv.</li>
<li><a href="https://doi.org/10.48550/arXiv.2410.12381" target="_blank" rel="noopener noreferrer"><strong>33</strong></a> — Zhang, F., Wu, L., Bai, H., Lin, G., Li, X., Yu, X., Wang, Y., Chen, B., &amp; Keung, J. (2024). HumanEval-V: Benchmarking High-Level Visual Reasoning with Complex Diagrams in Coding Tasks (Version 3). arXiv.</li>
<li><a href="https://doi.org/10.48550/arXiv.2108.07732" target="_blank" rel="noopener noreferrer"><strong>34</strong></a> — Austin, J., Odena, A., Nye, M., Bosma, M., Michalewski, H., Dohan, D., Jiang, E., Cai, C., Terry, M., Le, Q., &amp; Sutton, C. (2021). Program Synthesis with Large Language Models (Version 1). arXiv.</li>
<li><a href="https://doi.org/10.48550/arXiv.2208.08227" target="_blank" rel="noopener noreferrer"><strong>35</strong></a> — Cassano, F., Gouwar, J., Nguyen, D., Nguyen, S., Phipps-Costin, L., Pinckney, D., Yee, M.-H., Zi, Y., Anderson, C. J., Feldman, M. Q., Guha, A., Greenberg, M., &amp; Jangda, A. (2022). MultiPL-E: A Scalable and Extensible Approach to Benchmarking Neural Code Generation (Version 4). arXiv.</li>
<li><a href="https://doi.org/10.48550/arXiv.2404.00599" target="_blank" rel="noopener noreferrer"><strong>36</strong></a> — Li, J., Li, G., Zhang, X., Dong, Y., &amp; Jin, Z. (2024). EvoCodeBench: An Evolving Code Generation Benchmark Aligned with Real-World Code Repositories (Version 1). arXiv.</li>
<li><a href="https://doi.org/10.48550/arXiv.2301.09043" target="_blank" rel="noopener noreferrer"><strong>37</strong></a> — Dong, Y., Ding, J., Jiang, X., Li, G., Li, Z., &amp; Jin, Z. (2023). CodeScore: Evaluating Code Generation by Learning Code Execution (Version 4). arXiv.</li>
<li><a href="https://doi.org/10.1145/3650105.3652295" target="_blank" rel="noopener noreferrer"><strong>38</strong></a> — Niu, C., Zhang, T., Li, C., Luo, B., &amp; Ng, V. (2024). On Evaluating the Efficiency of Source Code Generated by LLMs. In Proceedings of the 2024 IEEE/ACM First International Conference on AI Foundation Models and Software Engineering (pp. 103–107). FORGE ’24: 2024 IEEE/ACM First International Conference on AI Foundation Models and Software Engineering. ACM.</li>
<li><a href="https://doi.org/10.3390/digital4010005" target="_blank" rel="noopener noreferrer"><strong>39</strong></a> — Coello, C. E. A., Alimam, M. N., &amp; Kouatly, R. (2024). Effectiveness of ChatGPT in Coding: A Comparative Analysis of Popular Large Language Models. Digital, 4(1), 114–125.</li>
<li><a href="https://doi.org/10.18653/v1/2024.emnlp-main.1118" target="_blank" rel="noopener noreferrer"><strong>40</strong></a> — Tong, W., &amp; Zhang, T. (2024). CodeJudge: Evaluating Code Generation with Large Language Models. In Proceedings of the 2024 Conference on Empirical Methods in Natural Language Processing (pp. 20032–20051). Proceedings of the 2024 Conference on Empirical Methods in Natural Language Processing. Association for Computational Linguistics.</li>
<li><a href="https://doi.org/10.48550/arXiv.2408.06450" target="_blank" rel="noopener noreferrer"><strong>41</strong></a> — Liu, J., Xie, S., Wang, J., Wei, Y., Ding, Y., &amp; Zhang, L. (2024). Evaluating Language Models for Efficient Code Generation (Version 1). arXiv.</li>
<li><a href="https://doi.org/10.48550/arXiv.2411.11908" target="_blank" rel="noopener noreferrer"><strong>42</strong></a> — Nascimento, N., Guimaraes, E., Chintakunta, S. S., &amp; Boominathan, S. A. (2024). LLM4DS: Evaluating Large Language Models for Data Science Code Generation (Version 1). arXiv.</li>
<li><a href="https://doi.org/10.18653/v1/2021.emnlp-main.685" target="_blank" rel="noopener noreferrer"><strong>43</strong></a> — Wang, Y., Wang, W., Joty, S., &amp; Hoi, S. C. H. (2021). CodeT5: Identifier-aware Unified Pre-trained Encoder-Decoder Models for Code Understanding and Generation. In Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing (pp. 8696–8708). Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing. Association for Computational Linguistics.</li>
<li><a href="https://doi.org/10.48550/arXiv.2207.11280" target="_blank" rel="noopener noreferrer"><strong>44</strong></a> — Christopoulou, F., Lampouras, G., Gritta, M., Zhang, G., Guo, Y., Li, Z., Zhang, Q., Xiao, M., Shen, B., Li, L., Yu, H., Yan, L., Zhou, P., Wang, X., Ma, Y., Iacobacci, I., Wang, Y., Liang, G., Wei, J., … Liu, Q. (2022). PanGu-Coder: Program Synthesis with Function-Level Language Modeling (Version 1). arXiv.</li>
<li><a href="https://doi.org/10.48550/arXiv.2301.03988" target="_blank" rel="noopener noreferrer"><strong>45</strong></a> — Allal, L. B., Li, R., Kocetkov, D., Mou, C., Akiki, C., Ferrandis, C. M., Muennighoff, N., Mishra, M., Gu, A., Dey, M., Umapathi, L. K., Anderson, C. J., Zi, Y., Poirier, J. L., Schoelkopf, H., Troshin, S., Abulkhanov, D., Romero, M., Lappert, M., … von Werra, L. (2023). SantaCoder: don’t reach for the stars! (Version 2). arXiv.</li>
<li><a href="https://doi.org/10.48550/arXiv.2303.17568" target="_blank" rel="noopener noreferrer"><strong>46</strong></a> — Zheng, Q., Xia, X., Zou, X., Dong, Y., Wang, S., Xue, Y., Wang, Z., Shen, L., Wang, A., Li, Y., Su, T., Yang, Z., &amp; Tang, J. (2023). CodeGeeX: A Pre-Trained Model for Code Generation with Multilingual Benchmarking on HumanEval-X (Version 2). arXiv.</li>
<li><a href="https://doi.org/10.48550/arXiv.2206.08474" target="_blank" rel="noopener noreferrer"><strong>47</strong></a> — Zhu, M., Jain, A., Suresh, K., Ravindran, R., Tipirneni, S., &amp; Reddy, C. K. (2022). XLCoST: A Benchmark Dataset for Cross-lingual Code Intelligence (Version 1). arXiv.</li>
<li><a href="https://doi.org/10.1007/s41019-025-00296-9" target="_blank" rel="noopener noreferrer"><strong>48</strong></a> — Xu, W., Huang, C., Gao, S., &amp; Shang, S. (2025). LLM-Based Agents for Tool Learning: A Survey. Data Science and Engineering.</li>
<li><a href="https://doi.org/10.1007/s11704-024-40231-1" target="_blank" rel="noopener noreferrer"><strong>49</strong></a> — Wang, L., Ma, C., Feng, X., Zhang, Z., Yang, H., Zhang, J., Chen, Z., Tang, J., Chen, X., Lin, Y., Zhao, W. X., Wei, Z., &amp; Wen, J. (2024). A survey on large language model based autonomous agents. Frontiers of Computer Science, 18(6).</li>
<li><a href="https://doi.org/10.1007/s11432-023-4127-5" target="_blank" rel="noopener noreferrer"><strong>50</strong></a> — Chen, X., Hu, X., Huang, Y., Jiang, H., Ji, W., Jiang, Y., Jiang, Y., Liu, B., Liu, H., Li, X., Lian, X., Meng, G., Peng, X., Sun, H., Shi, L., Wang, B., Wang, C., Wang, J., Wang, T., … Zhang, L. (2024). Deep learning-based software engineering: progress, challenges, and opportunities. Science China Information Sciences, 68(1).</li>
<li><a href="https://doi.org/10.1007/s44443-025-00074-7" target="_blank" rel="noopener noreferrer"><strong>51</strong></a> — Rong, Y., Du, T., Li, R., &amp; Bao, W. (2025). Integrating LLM-based code optimization with human-like exclusionary reasoning for computational education. Journal of King Saud University Computer and Information Sciences, 37(5).</li>
<li><a href="https://doi.org/10.1007/s10515-024-00451-y" target="_blank" rel="noopener noreferrer"><strong>52</strong></a> — Le, K. T., &amp; Andrzejak, A. (2024). Rethinking AI code generation: a one-shot correction approach based on user feedback. Automated Software Engineering, 31(2).</li>
<li><a href="https://doi.org/10.1007/s10462-024-10888-y" target="_blank" rel="noopener noreferrer"><strong>53</strong></a> — Kumar, P. (2024). Large language models (LLMs): survey, technical frameworks, and future challenges. Artificial Intelligence Review, 57(10).</li>
<li><a href="https://doi.org/10.48550/arXiv.2509.09614" target="_blank" rel="noopener noreferrer"><strong>54</strong></a> — Qiu, J., Liu, Z., Liu, Z., Murthy, R., Zhang, J., Chen, H., Wang, S., Zhu, M., Yang, L., Tan, J., Cen, Z., Qian, C., Heinecke, S., Yao, W., Savarese, S., Xiong, C., &amp; Wang, H. (2025). LoCoBench: A Benchmark for Long-Context Large Language Models in Complex Software Engineering (Version 1). arXiv.</li>
<li><a href="https://doi.org/10.48550/arXiv.2506.10833" target="_blank" rel="noopener noreferrer"><strong>55</strong></a> — Peña, F. C., &amp; Herbold, S. (2025). Evaluating Large Language Models on Non-Code Software Engineering Tasks (Version 1). arXiv.</li>
<li><a href="https://doi.org/10.1007/s43681-025-00721-9" target="_blank" rel="noopener noreferrer"><strong>56</strong></a> — Afreen, J., Mohaghegh, M., &amp; Doborjeh, M. (2025). Systematic literature review on bias mitigation in generative AI. AI and Ethics, 5(5), 4789–4841.</li>
<li><a href="https://doi.org/10.1109/ACCESS.2024.3482107" target="_blank" rel="noopener noreferrer"><strong>57</strong></a> — Shao, M., Basit, A., Karri, R., &amp; Shafique, M. (2024). Survey of Different Large Language Model Architectures: Trends, Benchmarks, and Challenges. IEEE Access, 12, 188664–188706.</li>
<li><a href="https://doi.org/10.1109/ACCESS.2024.3403858" target="_blank" rel="noopener noreferrer"><strong>58</strong></a> — Ságodi, Z., Siket, I., &amp; Ferenc, R. (2024). Methodology for Code Synthesis Evaluation of LLMs Presented by a Case Study of ChatGPT and Copilot. IEEE Access, 12, 72303–72316.</li>
<li><a href="https://doi.org/10.1109/ACCESS.2024.3484947" target="_blank" rel="noopener noreferrer"><strong>59</strong></a> — Black, G., Mathew Vaidyan, V., &amp; Comert, G. (2024). Evaluating Large Language Models for Enhanced Fuzzing: An Analysis Framework for LLM-Driven Seed Generation. IEEE Access, 12, 156065–156081.</li>
<li><a href="https://doi.org/10.1109/ACCESS.2025.3553870" target="_blank" rel="noopener noreferrer"><strong>60</strong></a> — Ko, E., &amp; Kang, P. (2025). Evaluating Coding Proficiency of Large Language Models: An Investigation Through Machine Learning Problems. IEEE Access, 13, 52925–52938.</li>
<li><a href="https://doi.org/10.1109/ACCESS.2025.3601206" target="_blank" rel="noopener noreferrer"><strong>61</strong></a> — Woesle, C., Fischer-Brandies, L., &amp; Buettner, R. (2025). A Systematic Literature Review of Hallucinations in Large Language Models. IEEE Access, 13, 148231–148253.</li>
<li><a href="https://doi.org/10.1016/j.csi.2024.103942" target="_blank" rel="noopener noreferrer"><strong>62</strong></a> — Li, Y., Liu, P., Wang, H., Chu, J., &amp; Wong, W. E. (2025). Evaluating large language models for software testing. Computer Standards &amp; amp; Interfaces, 93, 103942.</li>
<li><a href="https://doi.org/10.1145/3597503.3639219" target="_blank" rel="noopener noreferrer"><strong>63</strong></a> — Du, X., Liu, M., Wang, K., Wang, H., Liu, J., Chen, Y., Feng, J., Sha, C., Peng, X., &amp; Lou, Y. (2024). Evaluating Large Language Models in Class-Level Code Generation. In Proceedings of the IEEE/ACM 46th International Conference on Software Engineering (pp. 1–13). ICSE ’24: IEEE/ACM 46th International Conference on Software Engineering. ACM.</li>
<li><a href="https://doi.org/10.1109/TSE.2023.3334955" target="_blank" rel="noopener noreferrer"><strong>64</strong></a> — Schäfer, M., Nadi, S., Eghbali, A., &amp; Tip, F. (2024). An Empirical Evaluation of Using Large Language Models for Automated Unit Test Generation. IEEE Transactions on Software Engineering, 50(1), 85–105.</li>
<li><a href="https://doi.org/10.1007/s10664-025-10687-1" target="_blank" rel="noopener noreferrer"><strong>65</strong></a> — Alhanahnah, M., Rashedul Hasan, M., Xu, L., &amp; Bagheri, H. (2025). An empirical evaluation of pre-trained large language models for repairing declarative formal specifications. Empirical Software Engineering, 30(5).</li>
<li><a href="https://doi.org/10.48550/arXiv.2506.01793" target="_blank" rel="noopener noreferrer"><strong>66</strong></a> — Guo, Y., Ji, K., Zhu, X., Wang, J., Wen, F., Li, C., Zhang, Z., &amp; Zhai, G. (2025). Human-Centric Evaluation for Foundation Models (Version 1). arXiv.</li>
<li><a href="https://doi.org/10.48550/arXiv.2306.04675" target="_blank" rel="noopener noreferrer"><strong>67</strong></a> — Stein, G., Cresswell, J. C., Hosseinzadeh, R., Sui, Y., Ross, B. L., Villecroze, V., Liu, Z., Caterini, A. L., Taylor, J. E. T., &amp; Loaiza-Ganem, G. (2023). Exposing flaws of generative model evaluation metrics and their unfair treatment of diffusion models. arXiv.</li>
<li><a href="https://doi.org/10.48550/arXiv.2509.12395" target="_blank" rel="noopener noreferrer"><strong>68</strong></a> — Mundhra, Y., Valk, M., &amp; Izadi, M. (2025). Evaluating Large Language Models for Functional and Maintainable Code in Industrial Settings: A Case Study at ASML (Version 1). arXiv.</li>
</ul></div></article><nav class="docusaurus-mt-lg pagination-nav" aria-label="Docs pages"><a class="pagination-nav__link pagination-nav__link--prev" href="/LLMs-metrics-catalog/metrics/semantic/surface-form-constraints"><div class="pagination-nav__sublabel">Previous</div><div class="pagination-nav__label">Surface-Form Constraints</div></a></nav></div></div></div></div></main></div></div></div></div>
</body>
</html>