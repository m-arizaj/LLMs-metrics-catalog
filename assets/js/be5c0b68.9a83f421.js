"use strict";(self.webpackChunkll_ms_metrics_catalog=self.webpackChunkll_ms_metrics_catalog||[]).push([[6076],{956:(e,t,i)=>{i.r(t),i.d(t,{assets:()=>a,contentTitle:()=>r,default:()=>h,frontMatter:()=>l,metadata:()=>s,toc:()=>c});const s=JSON.parse('{"id":"metrics/efficiency/cost-metrics","title":"Cost Metrics","description":"Introduction","source":"@site/docs/metrics/efficiency/cost-metrics.md","sourceDirName":"metrics/efficiency","slug":"/metrics/efficiency/cost-metrics","permalink":"/LLMs-metrics-catalog/metrics/efficiency/cost-metrics","draft":false,"unlisted":false,"tags":[],"version":"current","frontMatter":{"id":"cost-metrics","title":"Cost Metrics","sidebar_label":"Cost Metrics"},"sidebar":"docsSidebar","previous":{"title":"Time Metrics","permalink":"/LLMs-metrics-catalog/metrics/efficiency/time"},"next":{"title":"Memory Metrics","permalink":"/LLMs-metrics-catalog/metrics/efficiency/memory"}}');var n=i(4848),o=i(8453);const l={id:"cost-metrics",title:"Cost Metrics",sidebar_label:"Cost Metrics"},r=void 0,a={},c=[{value:"Introduction",id:"introduction",level:2},{value:"1. Monetary Cost",id:"1-monetary-cost",level:2},{value:"Definition",id:"definition",level:3},{value:"Purpose",id:"purpose",level:3},{value:"Applications",id:"applications",level:3},{value:"2. Development Cost",id:"2-development-cost",level:2},{value:"Definition",id:"definition-1",level:3},{value:"Purpose",id:"purpose-1",level:3},{value:"Applications",id:"applications-1",level:3},{value:"3. Total Cost",id:"3-total-cost",level:2},{value:"Definition",id:"definition-2",level:3},{value:"Purpose",id:"purpose-2",level:3},{value:"Applications",id:"applications-2",level:3},{value:"4. Comparative Summary",id:"4-comparative-summary",level:2},{value:"References",id:"references",level:2},{value:"Additional References",id:"additional-references",level:2}];function d(e){const t={a:"a",code:"code",em:"em",h2:"h2",h3:"h3",li:"li",ol:"ol",p:"p",strong:"strong",table:"table",tbody:"tbody",td:"td",th:"th",thead:"thead",tr:"tr",ul:"ul",...(0,o.R)(),...e.components};return(0,n.jsxs)(n.Fragment,{children:[(0,n.jsx)(t.h2,{id:"introduction",children:"Introduction"}),"\n",(0,n.jsx)(t.p,{children:'In the evaluation of Large Language Models (LLMs) for software engineering tasks, "cost" is a crucial metric category that goes beyond simple functional correctness. It is not a single metric, but a set of efficiency metrics that quantify the resources consumed during code development, execution, or repair.'}),"\n",(0,n.jsxs)(t.p,{children:["These costs are generally divided into ",(0,n.jsx)(t.strong,{children:"time cost"})," (how long the process takes) and ",(0,n.jsx)(t.strong,{children:"resource cost"})," (financial or computational). Specific metrics like ",(0,n.jsx)(t.strong,{children:"Monetary Cost"}),", ",(0,n.jsx)(t.strong,{children:"Development Cost"}),", and ",(0,n.jsx)(t.strong,{children:"Total Cost"})," are used to measure the financial and efficiency implications of using LLMs in domains like automatic program repair (APR), code evolution, and autonomous agents."]}),"\n",(0,n.jsx)(t.h2,{id:"1-monetary-cost",children:"1. Monetary Cost"}),"\n",(0,n.jsx)(t.h3,{id:"definition",children:"Definition"}),"\n",(0,n.jsx)(t.p,{children:'"Monetary Cost" is defined as the "monetary expenses associated with token consumption, based on OpenAI\'s pricing" It is considered one of two "primary cost factors" for assessing pipelines that use LLMs.'}),"\n",(0,n.jsx)(t.h3,{id:"purpose",children:"Purpose"}),"\n",(0,n.jsx)(t.p,{children:"The primary purpose is to assess the financial implications of utilizing an LLM pipeline for a specific task."}),"\n",(0,n.jsx)(t.h3,{id:"applications",children:"Applications"}),"\n",(0,n.jsxs)(t.ul,{children:["\n",(0,n.jsxs)(t.li,{children:["It is used to measure the cost of ",(0,n.jsx)(t.strong,{children:"Automatic Program Repair (APR)"})," pipelines for declarative specifications, such as Alloy."]}),"\n",(0,n.jsx)(t.li,{children:'It is analyzed by comparing different agent setups (e.g., single-agent vs. dual-agent), where dual-agent setups exhibit "marginally higher costs".'}),"\n",(0,n.jsx)(t.li,{children:"It is used to compare the cost of different models (e.g., GPT-3.5-Turbo vs. the GPT-4 family), noting that GPT-3.5-Turbo has the lowest costs due to cheaper tokens."}),"\n",(0,n.jsx)(t.li,{children:'It is measured for both successful ("fixed") and unsuccessful ("unfixed") repair attempts.'}),"\n"]}),"\n",(0,n.jsx)(t.h2,{id:"2-development-cost",children:"2. Development Cost"}),"\n",(0,n.jsx)(t.h3,{id:"definition-1",children:"Definition"}),"\n",(0,n.jsx)(t.p,{children:'"Development Cost" is identified as an "efficiency metric". The paper that mentions it (a survey on autonomous agents) lists it as a key efficiency indicator but does not provide an explicit calculation formula, citing (ChatDev) as its origin.'}),"\n",(0,n.jsx)(t.h3,{id:"purpose-1",children:"Purpose"}),"\n",(0,n.jsx)(t.p,{children:'The purpose is to "assess the efficiency" of an LLM-based autonomous agent.'}),"\n",(0,n.jsx)(t.h3,{id:"applications-1",children:"Applications"}),"\n",(0,n.jsxs)(t.ul,{children:["\n",(0,n.jsxs)(t.li,{children:["It is used in the context of evaluating ",(0,n.jsx)(t.strong,{children:"LLM-based autonomous agents"}),"."]}),"\n",(0,n.jsxs)(t.li,{children:["It is specifically associated with ",(0,n.jsx)(t.strong,{children:"software engineering"})," tasks, where agents simulate a software development lifecycle ."]}),"\n"]}),"\n",(0,n.jsx)(t.h2,{id:"3-total-cost",children:"3. Total Cost"}),"\n",(0,n.jsx)(t.h3,{id:"definition-2",children:"Definition"}),"\n",(0,n.jsx)(t.p,{children:'In the context of evolutionary algorithms using LLMs (like LLM_GP), "Total Cost" is a "run-time cost" metric that encompasses multiple facets of LLM API usage:'}),"\n",(0,n.jsxs)(t.ol,{children:["\n",(0,n.jsxs)(t.li,{children:[(0,n.jsx)(t.strong,{children:"Time Cost:"})," The duration associated with sending ",(0,n.jsx)(t.em,{children:"prompts"})," and waiting for API responses."]}),"\n",(0,n.jsxs)(t.li,{children:[(0,n.jsx)(t.strong,{children:"Monetary Cost:"})," The direct financial expense of API calls."]}),"\n",(0,n.jsxs)(t.li,{children:[(0,n.jsx)(t.strong,{children:"Indirect Cost:"}),' The paper also notes a "hidden, but significant cost" of the LLM\'s pre-training, which is an indirect but fundamental cost of using the technology.']}),"\n"]}),"\n",(0,n.jsx)(t.h3,{id:"purpose-2",children:"Purpose"}),"\n",(0,n.jsx)(t.p,{children:'"Total Cost" is used to measure the computational and financial cost of employing an LLM to execute evolutionary operators (like initialization, crossover, and mutation).'}),"\n",(0,n.jsx)(t.h3,{id:"applications-2",children:"Applications"}),"\n",(0,n.jsxs)(t.ul,{children:["\n",(0,n.jsxs)(t.li,{children:["It is used to evaluate and compare evolutionary algorithm variants (e.g., ",(0,n.jsx)(t.code,{children:"LLM_GP"})," vs. ",(0,n.jsx)(t.code,{children:"LLM_GP_Mu_XO"}),") in ",(0,n.jsx)(t.strong,{children:"code evolution"})," tasks like Symbolic Regression."]}),"\n",(0,n.jsx)(t.li,{children:"It is also used to compare how cost changes when the API provider updates the model version (e.g., F23 vs. S24)."}),"\n"]}),"\n",(0,n.jsx)(t.h2,{id:"4-comparative-summary",children:"4. Comparative Summary"}),"\n",(0,n.jsxs)(t.table,{children:[(0,n.jsx)(t.thead,{children:(0,n.jsxs)(t.tr,{children:[(0,n.jsx)(t.th,{style:{textAlign:"left"},children:"Metric"}),(0,n.jsx)(t.th,{style:{textAlign:"left"},children:"Application Domain (per paper)"}),(0,n.jsx)(t.th,{style:{textAlign:"left"},children:"Cost Focus"}),(0,n.jsx)(t.th,{style:{textAlign:"left"},children:"Measured Components"})]})}),(0,n.jsxs)(t.tbody,{children:[(0,n.jsxs)(t.tr,{children:[(0,n.jsx)(t.td,{style:{textAlign:"left"},children:(0,n.jsx)(t.strong,{children:"Monetary Cost"})}),(0,n.jsx)(t.td,{style:{textAlign:"left"},children:"Specification Repair (Alloy)"}),(0,n.jsx)(t.td,{style:{textAlign:"left"},children:"Financial"}),(0,n.jsx)(t.td,{style:{textAlign:"left"},children:"API token consumption"})]}),(0,n.jsxs)(t.tr,{children:[(0,n.jsx)(t.td,{style:{textAlign:"left"},children:(0,n.jsx)(t.strong,{children:"Development Cost"})}),(0,n.jsx)(t.td,{style:{textAlign:"left"},children:"Autonomous Agents (Survey)"}),(0,n.jsx)(t.td,{style:{textAlign:"left"},children:"Efficiency"}),(0,n.jsx)(t.td,{style:{textAlign:"left"},children:"Cost associated with development (time/resources)"})]}),(0,n.jsxs)(t.tr,{children:[(0,n.jsx)(t.td,{style:{textAlign:"left"},children:(0,n.jsx)(t.strong,{children:"Total Cost"})}),(0,n.jsx)(t.td,{style:{textAlign:"left"},children:"Code Evolution (LLM_GP)"}),(0,n.jsx)(t.td,{style:{textAlign:"left"},children:"Financial & Temporal"}),(0,n.jsx)(t.td,{style:{textAlign:"left"},children:"API wait time, API cost, and (hidden) pre-training cost"})]})]})]}),"\n",(0,n.jsx)(t.h2,{id:"references",children:"References"}),"\n",(0,n.jsxs)(t.ul,{children:["\n",(0,n.jsxs)(t.li,{children:["Alhanahnah, M., Rashedul Hasan, M., Xu, L. et al. An empirical evaluation of pre-trained large language models for repairing declarative formal specifications. Empir Software Eng 30, 149 (2025). ",(0,n.jsx)(t.a,{href:"https://doi.org/10.1007/s10664-025-10687-1",children:"https://doi.org/10.1007/s10664-025-10687-1"})]}),"\n",(0,n.jsxs)(t.li,{children:["Hemberg, E., Moskal, S. & O\u2019Reilly, UM. Evolving code with a large language model. Genet Program Evolvable Mach 25, 21 (2024). ",(0,n.jsx)(t.a,{href:"https://doi.org/10.1007/s10710-024-09494-2",children:"https://doi.org/10.1007/s10710-024-09494-2"})]}),"\n",(0,n.jsxs)(t.li,{children:["Wang, L., Ma, C., Feng, X. et al. A survey on large language model based autonomous agents. Front. Comput. Sci. 18, 186345 (2024). ",(0,n.jsx)(t.a,{href:"https://doi.org/10.1007/s11704-024-40231-1",children:"https://doi.org/10.1007/s11704-024-40231-1"})]}),"\n"]}),"\n",(0,n.jsx)(t.h2,{id:"additional-references",children:"Additional References"}),"\n",(0,n.jsxs)(t.ul,{children:["\n",(0,n.jsx)(t.li,{children:"49, 65, 30"}),"\n"]})]})}function h(e={}){const{wrapper:t}={...(0,o.R)(),...e.components};return t?(0,n.jsx)(t,{...e,children:(0,n.jsx)(d,{...e})}):d(e)}},8453:(e,t,i)=>{i.d(t,{R:()=>l,x:()=>r});var s=i(6540);const n={},o=s.createContext(n);function l(e){const t=s.useContext(o);return s.useMemo(function(){return"function"==typeof e?e(t):{...t,...e}},[t,e])}function r(e){let t;return t=e.disableParentContext?"function"==typeof e.components?e.components(n):e.components||n:l(e.components),s.createElement(o.Provider,{value:t},e.children)}}}]);