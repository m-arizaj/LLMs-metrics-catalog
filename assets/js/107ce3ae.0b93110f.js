"use strict";(self.webpackChunkll_ms_metrics_catalog=self.webpackChunkll_ms_metrics_catalog||[]).push([[160],{7349:(e,i,n)=>{n.r(i),n.d(i,{assets:()=>c,contentTitle:()=>a,default:()=>h,frontMatter:()=>l,metadata:()=>s,toc:()=>o});const s=JSON.parse('{"id":"metrics/clasicas-ml/recall","title":"Recall","description":"Definition","source":"@site/docs/metrics/clasicas-ml/recall.md","sourceDirName":"metrics/clasicas-ml","slug":"/metrics/clasicas-ml/recall","permalink":"/LLMs-metrics-catalog/metrics/clasicas-ml/recall","draft":false,"unlisted":false,"tags":[],"version":"current","frontMatter":{"id":"recall","title":"Recall","sidebar_label":"Recall"},"sidebar":"docsSidebar","previous":{"title":"Precision","permalink":"/LLMs-metrics-catalog/metrics/clasicas-ml/precision"},"next":{"title":"ROUGE","permalink":"/LLMs-metrics-catalog/metrics/nlg/rouge"}}');var t=n(4848),r=n(8453);const l={id:"recall",title:"Recall",sidebar_label:"Recall"},a=void 0,c={},o=[{value:"Definition",id:"definition",level:2},{value:"Formula (General Idea)",id:"formula-general-idea",level:2},{value:"Purpose",id:"purpose",level:2},{value:"Domains",id:"domains",level:2},{value:"Benchmarks",id:"benchmarks",level:2},{value:"Advantages",id:"advantages",level:2},{value:"Limitations",id:"limitations",level:2},{value:"Key References",id:"key-references",level:2}];function d(e){const i={annotation:"annotation",em:"em",h2:"h2",hr:"hr",li:"li",math:"math",mfrac:"mfrac",mo:"mo",mrow:"mrow",mtext:"mtext",p:"p",semantics:"semantics",span:"span",strong:"strong",ul:"ul",...(0,r.R)(),...e.components};return(0,t.jsxs)(t.Fragment,{children:[(0,t.jsx)(i.h2,{id:"definition",children:"Definition"}),"\n",(0,t.jsxs)(i.p,{children:["Recall, also known as ",(0,t.jsx)(i.strong,{children:"sensitivity"})," or ",(0,t.jsx)(i.strong,{children:"true positive rate"}),", is a fundamental metric used in various machine learning tasks, including classification, information retrieval, and the evaluation of generative models. In the context of generative models for images or text/code, it is often adapted to measure ",(0,t.jsx)(i.strong,{children:"diversity"})," or ",(0,t.jsx)(i.strong,{children:"coverage"}),"\u2014how well the generated samples capture the breadth and variety present in the real data distribution or reference set [cite: 2998-2999, 3333]. For tasks like bug detection/repair, it measures the proportion of actual bugs that were correctly identified or fixed."]}),"\n",(0,t.jsx)(i.hr,{}),"\n",(0,t.jsx)(i.h2,{id:"formula-general-idea",children:"Formula (General Idea)"}),"\n",(0,t.jsx)(i.p,{children:"The standard formula for recall in classification/detection is:"}),"\n",(0,t.jsx)(i.span,{className:"katex",children:(0,t.jsx)(i.math,{xmlns:"http://www.w3.org/1998/Math/MathML",display:"block",children:(0,t.jsxs)(i.semantics,{children:[(0,t.jsxs)(i.mrow,{children:[(0,t.jsx)(i.mtext,{children:"Recall"}),(0,t.jsx)(i.mo,{children:"="}),(0,t.jsxs)(i.mfrac,{children:[(0,t.jsx)(i.mtext,{children:"True\xa0Positives\xa0(TP)"}),(0,t.jsxs)(i.mrow,{children:[(0,t.jsx)(i.mtext,{children:"True\xa0Positives\xa0(TP)"}),(0,t.jsx)(i.mo,{children:"+"}),(0,t.jsx)(i.mtext,{children:"False\xa0Negatives\xa0(FN)"})]})]})]}),(0,t.jsx)(i.annotation,{encoding:"application/x-tex",children:"\\text{Recall} = \\frac{\\text{True Positives (TP)}}{\\text{True Positives (TP)} + \\text{False Negatives (FN)}}"})]})})}),"\n",(0,t.jsxs)(i.ul,{children:["\n",(0,t.jsxs)(i.li,{children:[(0,t.jsx)(i.strong,{children:"TP:"})," Items correctly identified as positive (e.g., actual bugs found, relevant documents retrieved)."]}),"\n",(0,t.jsxs)(i.li,{children:[(0,t.jsx)(i.strong,{children:"FN:"})," Items incorrectly identified as negative (e.g., actual bugs missed, relevant documents not retrieved)."]}),"\n"]}),"\n",(0,t.jsx)(i.p,{children:"In the context of generative model evaluation (e.g., using the Precision and Recall metric framework for distributions):"}),"\n",(0,t.jsxs)(i.ul,{children:["\n",(0,t.jsxs)(i.li,{children:["It measures the fraction of the ",(0,t.jsx)(i.em,{children:"real"})," data distribution that is covered by the ",(0,t.jsx)(i.em,{children:"generated"})," distribution, often estimated using nearest-neighbor methods in a feature space."]}),"\n"]}),"\n",(0,t.jsx)(i.hr,{}),"\n",(0,t.jsx)(i.h2,{id:"purpose",children:"Purpose"}),"\n",(0,t.jsxs)(i.ul,{children:["\n",(0,t.jsxs)(i.li,{children:[(0,t.jsx)(i.strong,{children:"Classification/Detection:"})," To measure the model's ability to find all relevant positive instances (e.g., find all bugs, identify all patients with a disease)."]}),"\n",(0,t.jsxs)(i.li,{children:[(0,t.jsx)(i.strong,{children:"Generative Models:"})," To evaluate the ",(0,t.jsx)(i.strong,{children:"diversity"})," or ",(0,t.jsx)(i.strong,{children:"coverage"})," of the generated samples compared to the real data distribution. [cite_start]A high recall suggests the model can generate varied outputs covering most modes of the true distribution [cite: 2998-2999, 3333]."]}),"\n"]}),"\n",(0,t.jsx)(i.hr,{}),"\n",(0,t.jsx)(i.h2,{id:"domains",children:"Domains"}),"\n",(0,t.jsxs)(i.ul,{children:["\n",(0,t.jsx)(i.li,{children:"Classification (General ML)"}),"\n",(0,t.jsx)(i.li,{children:"Information Retrieval"}),"\n",(0,t.jsx)(i.li,{children:"[cite_start]Generative Models (Image/Text/Code Generation - Diversity Evaluation) [cite: 2998-2999, 3333]"}),"\n",(0,t.jsx)(i.li,{children:"Bug Fixing / Bug Detection"}),"\n",(0,t.jsx)(i.li,{children:"Biomedical NLP"}),"\n",(0,t.jsx)(i.li,{children:"Security Evaluation (Code Generation)"}),"\n"]}),"\n",(0,t.jsx)(i.hr,{}),"\n",(0,t.jsx)(i.h2,{id:"benchmarks",children:"Benchmarks"}),"\n",(0,t.jsxs)(i.ul,{children:["\n",(0,t.jsx)(i.li,{children:"Defects4J, QuixBugs"}),"\n",(0,t.jsx)(i.li,{children:"CodeSearchNet"}),"\n",(0,t.jsx)(i.li,{children:"BC5CDR, NCBI Disease, MedNLI, CHEMPROT"}),"\n",(0,t.jsx)(i.li,{children:"CIFAR10, ImageNet1k, FFHQ, LSUN-Bedroom (for generative model evaluation)"}),"\n",(0,t.jsx)(i.li,{children:"AMBER (for Multimodal LLMs)"}),"\n",(0,t.jsx)(i.li,{children:"CYBERSECEVAL"}),"\n",(0,t.jsx)(i.li,{children:"(Various classification/IR benchmarks)"}),"\n"]}),"\n",(0,t.jsx)(i.hr,{}),"\n",(0,t.jsx)(i.h2,{id:"advantages",children:"Advantages"}),"\n",(0,t.jsxs)(i.ul,{children:["\n",(0,t.jsx)(i.li,{children:"Directly measures how well a model captures all positive/relevant instances or the diversity of a target distribution."}),"\n",(0,t.jsx)(i.li,{children:"Crucial in applications where missing positives is costly (e.g., medical diagnosis, bug detection)."}),"\n",(0,t.jsx)(i.li,{children:"When used alongside Precision for generative models, helps disentangle fidelity (Precision) from diversity (Recall)."}),"\n"]}),"\n",(0,t.jsx)(i.hr,{}),"\n",(0,t.jsx)(i.h2,{id:"limitations",children:"Limitations"}),"\n",(0,t.jsxs)(i.ul,{children:["\n",(0,t.jsx)(i.li,{children:"Does not account for False Positives (measured by Precision). A model can achieve high recall by simply classifying/generating everything as positive, leading to low precision."}),"\n",(0,t.jsx)(i.li,{children:"The implementation for generative models (based on feature space overlaps) can be sensitive to the choice of feature extractor (encoder) and hyperparameters (like k in k-NN)."}),"\n",(0,t.jsx)(i.li,{children:"High recall in generation doesn't guarantee high fidelity (realism/correctness) of individual samples."}),"\n"]}),"\n",(0,t.jsx)(i.hr,{}),"\n",(0,t.jsx)(i.h2,{id:"key-references",children:"Key References"}),"\n",(0,t.jsxs)(i.ul,{children:["\n",(0,t.jsx)(i.li,{children:"[cite_start]Sajjadi et al., 2018 (Precision and Recall for Generative Models paper) [cite: 3122-3123]"}),"\n",(0,t.jsx)(i.li,{children:"[cite_start]Kynk\xe4\xe4nniemi et al., 2019 (Improved Precision and Recall metric) [cite: 3063-3064]"}),"\n",(0,t.jsx)(i.li,{children:"[cite_start]File: exposing flaws.pdf [cite: 2998-2999, 3333, 3340]"}),"\n",(0,t.jsx)(i.li,{children:"(Excel Data: Papers 2, 3, 6, 7, 8, 18, 48, 67)"}),"\n"]})]})}function h(e={}){const{wrapper:i}={...(0,r.R)(),...e.components};return i?(0,t.jsx)(i,{...e,children:(0,t.jsx)(d,{...e})}):d(e)}},8453:(e,i,n)=>{n.d(i,{R:()=>l,x:()=>a});var s=n(6540);const t={},r=s.createContext(t);function l(e){const i=s.useContext(r);return s.useMemo(function(){return"function"==typeof e?e(i):{...i,...e}},[i,e])}function a(e){let i;return i=e.disableParentContext?"function"==typeof e.components?e.components(t):e.components||t:l(e.components),s.createElement(r.Provider,{value:i},e.children)}}}]);