"use strict";(self.webpackChunkll_ms_metrics_catalog=self.webpackChunkll_ms_metrics_catalog||[]).push([[2883],{8453:(e,n,i)=>{i.d(n,{R:()=>l,x:()=>r});var s=i(6540);const t={},a=s.createContext(t);function l(e){const n=s.useContext(a);return s.useMemo(function(){return"function"==typeof e?e(n):{...n,...e}},[n,e])}function r(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(t):e.components||t:l(e.components),s.createElement(a.Provider,{value:n},e.children)}},8724:(e,n,i)=>{i.r(n),i.d(n,{assets:()=>c,contentTitle:()=>r,default:()=>h,frontMatter:()=>l,metadata:()=>s,toc:()=>o});const s=JSON.parse('{"id":"metrics/semantic/factuality","title":"Factuality","description":"Definition","source":"@site/docs/metrics/semantic/factuality.md","sourceDirName":"metrics/semantic","slug":"/metrics/semantic/factuality","permalink":"/LLMs-metrics-catalog/metrics/semantic/factuality","draft":false,"unlisted":false,"tags":[],"version":"current","frontMatter":{"id":"factuality","title":"Factuality","sidebar_label":"Factuality"},"sidebar":"docsSidebar","previous":{"title":"Distinguishability (d)","permalink":"/LLMs-metrics-catalog/metrics/semantic/distinguishability"},"next":{"title":"Faithfulness","permalink":"/LLMs-metrics-catalog/metrics/semantic/faithfulness"}}');var t=i(4848),a=i(8453);const l={id:"factuality",title:"Factuality",sidebar_label:"Factuality"},r=void 0,c={},o=[{value:"Definition",id:"definition",level:2},{value:"Purpose",id:"purpose",level:2},{value:"Domains",id:"domains",level:2},{value:"Benchmarks",id:"benchmarks",level:2},{value:"Advantages",id:"advantages",level:2},{value:"Limitations",id:"limitations",level:2},{value:"Key References",id:"key-references",level:2}];function d(e){const n={a:"a",em:"em",h2:"h2",hr:"hr",li:"li",p:"p",strong:"strong",ul:"ul",...(0,a.R)(),...e.components};return(0,t.jsxs)(t.Fragment,{children:[(0,t.jsx)(n.h2,{id:"definition",children:"Definition"}),"\n",(0,t.jsxs)(n.p,{children:[(0,t.jsx)(n.strong,{children:"Factuality"})," in the context of Large Language Models (LLMs) refers to the extent to which the information or answers provided by the model align with ",(0,t.jsx)(n.strong,{children:"real-world truths and verifiable facts"}),"."]}),"\n",(0,t.jsx)(n.p,{children:"Evaluating factuality is a critical component of LLM assessment. It measures the model's ability to:"}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsx)(n.li,{children:"Maintain consistency with known facts."}),"\n",(0,t.jsxs)(n.li,{children:["Avoid generating misleading or false information, a phenomenon known as ",(0,t.jsx)(n.strong,{children:'"factual hallucination"'}),"."]}),"\n",(0,t.jsx)(n.li,{children:"Effectively learn and recall factual knowledge."}),"\n"]}),"\n",(0,t.jsx)(n.hr,{}),"\n",(0,t.jsx)(n.h2,{id:"purpose",children:"Purpose"}),"\n",(0,t.jsxs)(n.p,{children:["The primary purpose of evaluating factuality is to ",(0,t.jsx)(n.strong,{children:"ensure trust and enable the efficient use of LLMs"}),"."]}),"\n",(0,t.jsx)(n.p,{children:"Factuality significantly impacts the reliability of downstream applications. Inconsistent or incorrect information can lead to substantial misunderstandings, making this metric crucial for tasks like:"}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsx)(n.li,{children:"Question Answering (QA) systems"}),"\n",(0,t.jsx)(n.li,{children:"Information extraction"}),"\n",(0,t.jsx)(n.li,{children:"Text summarization"}),"\n",(0,t.jsx)(n.li,{children:"Dialogue systems"}),"\n",(0,t.jsx)(n.li,{children:"Automated fact-checking"}),"\n"]}),"\n",(0,t.jsx)(n.hr,{}),"\n",(0,t.jsx)(n.h2,{id:"domains",children:"Domains"}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsx)(n.li,{children:"General LLM Evaluation"}),"\n",(0,t.jsx)(n.li,{children:"Knowledge Accuracy"}),"\n",(0,t.jsx)(n.li,{children:"Question Answering"}),"\n",(0,t.jsx)(n.li,{children:"Text Summarization (Factual Consistency)"}),"\n",(0,t.jsx)(n.li,{children:"Fact-Checking"}),"\n"]}),"\n",(0,t.jsx)(n.hr,{}),"\n",(0,t.jsx)(n.h2,{id:"benchmarks",children:"Benchmarks"}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"HELM"})," (Holistic Evaluation of Language Models) [User provided data]"]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"TruthfulQA:"})," A dataset specifically designed to cause models to make mistakes and test truthfulness."]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Natural Questions:"})," Used to assess internal knowledge capabilities."]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"TriviaQA:"})," Used to assess internal knowledge capabilities."]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"FActScore:"}),' A metric/benchmark that breaks down generated text into individual "atomic" facts which are then evaluated for correctness.']}),"\n"]}),"\n",(0,t.jsx)(n.hr,{}),"\n",(0,t.jsx)(n.h2,{id:"advantages",children:"Advantages"}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Builds Trust:"})," Directly measures the reliability and truthfulness of a model, which is essential for user trust."]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Critical for Applications:"})," Serves as a gate for deploying LLMs in information-sensitive fields like medicine, finance, and education."]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Targets Hallucination:"}),' Provides a direct way to quantify and track a model\'s tendency to "hallucinate" or fabricate information.']}),"\n"]}),"\n",(0,t.jsx)(n.hr,{}),"\n",(0,t.jsx)(n.h2,{id:"limitations",children:"Limitations"}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"No Unified Framework:"})," There is an absence of a unified comparison framework for factual consistency, and some scores have limited value compared to simple binary labels."]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Scaling Isn't a Silver Bullet:"})," Simply scaling up model sizes does not necessarily improve their truthfulness."]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Estimator Performance:"}),' Current estimators designed to measure factuality (like FActScore) still "have some way to go" in effectively addressing the task.']}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Hallucination Risk:"})," Models are capable of generating coherent-sounding text that includes factual inaccuracies or statements ungrounded in reality."]}),"\n"]}),"\n",(0,t.jsx)(n.hr,{}),"\n",(0,t.jsx)(n.h2,{id:"key-references",children:"Key References"}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsxs)(n.li,{children:["Chang, Y., Wang, X., Wang, J., et al. (2023). ",(0,t.jsx)(n.em,{children:"A Survey on Evaluation of Large Language Models"}),". ",(0,t.jsx)(n.a,{href:"https://doi.org/10.48550/arXiv.2307.03109",children:"https://doi.org/10.48550/arXiv.2307.03109"})]}),"\n",(0,t.jsxs)(n.li,{children:["Lin, S., Hilton, J., & Evans, O. (2021). ",(0,t.jsx)(n.em,{children:"Truthfulqa: Measuring how models mimic human falsehoods"}),"."]}),"\n",(0,t.jsxs)(n.li,{children:["Wang, C., Cheng, S., Xu, Z., et al. (2023). ",(0,t.jsx)(n.em,{children:"Evaluating open question answering evaluation"}),"."]}),"\n",(0,t.jsxs)(n.li,{children:["Min, S., Krishna, K., Lyu, X., et al. (2023). ",(0,t.jsx)(n.em,{children:"FActScore: Fine-grained Atomic Evaluation of Factual Precision in Long Form Text Generation"}),"."]}),"\n",(0,t.jsxs)(n.li,{children:["Honovich, O., Aharoni, R., Herzig, J., et al. (2022). ",(0,t.jsx)(n.em,{children:"TRUE: Re-evaluating factual consistency evaluation"}),"."]}),"\n",(0,t.jsxs)(n.li,{children:["Gekhman, Z., Herzig, J., Aharoni, R., et al. (2023). ",(0,t.jsx)(n.em,{children:"Trueteacher: Learning factual consistency evaluation with large language models"}),"."]}),"\n",(0,t.jsxs)(n.li,{children:["Manakul, P., Liusie, A., & Gales, M. (2023). ",(0,t.jsx)(n.em,{children:"Selfcheckgpt: Zero-resource black-box hallucination detection for generative large language models"}),"."]}),"\n",(0,t.jsx)(n.li,{children:"(Excel Data: Paper 9)"}),"\n"]})]})}function h(e={}){const{wrapper:n}={...(0,a.R)(),...e.components};return n?(0,t.jsx)(n,{...e,children:(0,t.jsx)(d,{...e})}):d(e)}}}]);