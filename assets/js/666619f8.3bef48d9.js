"use strict";(self.webpackChunkll_ms_metrics_catalog=self.webpackChunkll_ms_metrics_catalog||[]).push([[1451],{3080:(e,n,i)=>{i.r(n),i.d(n,{assets:()=>a,contentTitle:()=>o,default:()=>f,frontMatter:()=>l,metadata:()=>t,toc:()=>c});const t=JSON.parse('{"id":"metrics/robustness/performance","title":"Performance (Functional & Efficiency)","description":"Introduction","source":"@site/docs/metrics/robustness/performance.md","sourceDirName":"metrics/robustness","slug":"/metrics/robustness/performance","permalink":"/LLMs-metrics-catalog/metrics/robustness/performance","draft":false,"unlisted":false,"tags":[],"version":"current","frontMatter":{"id":"performance","title":"Performance (Functional & Efficiency)","sidebar_label":"Performance"},"sidebar":"docsSidebar","previous":{"title":"Fitness Function","permalink":"/LLMs-metrics-catalog/metrics/robustness/fitness"},"next":{"title":"Reliability","permalink":"/LLMs-metrics-catalog/metrics/robustness/reliability"}}');var r=i(4848),s=i(8453);const l={id:"performance",title:"Performance (Functional & Efficiency)",sidebar_label:"Performance"},o=void 0,a={},c=[{value:"Introduction",id:"introduction",level:2},{value:"1. Functional Performance (General)",id:"1-functional-performance-general",level:2},{value:"Definition",id:"definition",level:3},{value:"Applications",id:"applications",level:3},{value:"2. Unit Test Performance",id:"2-unit-test-performance",level:2},{value:"Definition",id:"definition-1",level:3},{value:"Applications",id:"applications-1",level:3},{value:"3. Integration Test Performance",id:"3-integration-test-performance",level:2},{value:"Definition",id:"definition-2",level:3},{value:"Applications",id:"applications-2",level:3},{value:"4. Differential Performance Score",id:"4-differential-performance-score",level:2},{value:"Definition",id:"definition-3",level:3},{value:"Applications",id:"applications-3",level:3},{value:"5. Normalized Differential Performance Score",id:"5-normalized-differential-performance-score",level:2},{value:"Definition",id:"definition-4",level:3},{value:"Applications",id:"applications-4",level:3},{value:"6. Comparative Summary",id:"6-comparative-summary",level:2},{value:"References",id:"references",level:2}];function d(e){const n={a:"a",em:"em",h2:"h2",h3:"h3",li:"li",ol:"ol",p:"p",strong:"strong",table:"table",tbody:"tbody",td:"td",th:"th",thead:"thead",tr:"tr",ul:"ul",...(0,s.R)(),...e.components};return(0,r.jsxs)(r.Fragment,{children:[(0,r.jsx)(n.h2,{id:"introduction",children:"Introduction"}),"\n",(0,r.jsxs)(n.p,{children:["In the evaluation of Large Language Models, particularly in code generation and software engineering domains, ",(0,r.jsx)(n.strong,{children:"Performance"})," is a broad category of metrics. It is used to quantify the model's success in two key areas:"]}),"\n",(0,r.jsxs)(n.ol,{children:["\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Functional Performance / Correctness:"})," Does the code generated by the model work as intended? This is typically measured by executing the code against a set of test cases."]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Efficiency Evaluation:"})," How efficient is the model in its code generation process, especially when measured against a baseline?"]}),"\n"]}),"\n",(0,r.jsx)(n.p,{children:"This category includes several specific metrics, such as scores based on unit and integration test pass rates, as well as differential scores that compare a model's performance to a standard."}),"\n",(0,r.jsx)(n.h2,{id:"1-functional-performance-general",children:"1. Functional Performance (General)"}),"\n",(0,r.jsx)(n.h3,{id:"definition",children:"Definition"}),"\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"Functional Performance"})," is a general metric used to evaluate the ",(0,r.jsx)(n.strong,{children:"Functional Correctness"})," of generated code. It assesses whether the model's output (e.g., a function, a class, or a patch) behaves according to the requirements, which is often validated by executing it."]}),"\n",(0,r.jsx)(n.h3,{id:"applications",children:"Applications"}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["Used in benchmarks like ",(0,r.jsx)(n.strong,{children:"DevQualityEval"})," to assess the quality and correctness of code generated by LLMs."]}),"\n",(0,r.jsx)(n.li,{children:"Domain: Software Engineering / Code Generation."}),"\n"]}),"\n",(0,r.jsx)(n.h2,{id:"2-unit-test-performance",children:"2. Unit Test Performance"}),"\n",(0,r.jsx)(n.h3,{id:"definition-1",children:"Definition"}),"\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"Unit Test Performance"})," is a specific measure of ",(0,r.jsx)(n.strong,{children:"Functional Correctness"})," that evaluates whether the code generated by an LLM passes a predefined set of unit tests. Unit tests are fine-grained tests that check the correctness of individual components (e.g., a single function or method) in isolation."]}),"\n",(0,r.jsx)(n.h3,{id:"applications-1",children:"Applications"}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["Used in benchmarks like ",(0,r.jsx)(n.strong,{children:"LoCoBench"})," to evaluate the functional correctness of models in long-context software engineering tasks."]}),"\n"]}),"\n",(0,r.jsx)(n.h2,{id:"3-integration-test-performance",children:"3. Integration Test Performance"}),"\n",(0,r.jsx)(n.h3,{id:"definition-2",children:"Definition"}),"\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"Integration Test Performance"})," is another measure of ",(0,r.jsx)(n.strong,{children:"Functional Correctness"}),". Unlike unit tests, integration tests evaluate the model's ability to generate code that functions correctly when combined with other parts of a larger system. It checks the interactions between different modules or components."]}),"\n",(0,r.jsx)(n.h3,{id:"applications-2",children:"Applications"}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["Used in benchmarks like ",(0,r.jsx)(n.strong,{children:"LoCoBench"})," to assess if a model's generated code integrates properly within a broader software context."]}),"\n"]}),"\n",(0,r.jsx)(n.h2,{id:"4-differential-performance-score",children:"4. Differential Performance Score"}),"\n",(0,r.jsx)(n.h3,{id:"definition-3",children:"Definition"}),"\n",(0,r.jsxs)(n.p,{children:["The ",(0,r.jsx)(n.strong,{children:"Differential Performance Score"})," is a metric used for ",(0,r.jsx)(n.strong,{children:"Efficiency Evaluation"})," in code generation. It is designed to measure the ",(0,r.jsx)(n.em,{children:"difference"})," in performance (such as execution speed or resource usage) between the code generated by an LLM and a baseline or reference implementation."]}),"\n",(0,r.jsx)(n.h3,{id:"applications-3",children:"Applications"}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["Used in the ",(0,r.jsx)(n.strong,{children:"EVALPERF"})," benchmark to evaluate the efficiency of LLM-generated code."]}),"\n"]}),"\n",(0,r.jsx)(n.h2,{id:"5-normalized-differential-performance-score",children:"5. Normalized Differential Performance Score"}),"\n",(0,r.jsx)(n.h3,{id:"definition-4",children:"Definition"}),"\n",(0,r.jsxs)(n.p,{children:["The ",(0,r.jsx)(n.strong,{children:"Normalized Differential Performance Score"})," is a variant of the Differential Performance Score, also used for ",(0,r.jsx)(n.strong,{children:"Efficiency Evaluation"}),". By normalizing the score, it allows for a more standardized comparison of performance differences across different tasks or models, which might have different scales of performance."]}),"\n",(0,r.jsx)(n.h3,{id:"applications-4",children:"Applications"}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["Also used within the ",(0,r.jsx)(n.strong,{children:"EVALPERF"})," benchmark to provide a standardized metric for code generation efficiency."]}),"\n"]}),"\n",(0,r.jsx)(n.h2,{id:"6-comparative-summary",children:"6. Comparative Summary"}),"\n",(0,r.jsxs)(n.table,{children:[(0,r.jsx)(n.thead,{children:(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.th,{style:{textAlign:"left"},children:"Metric"}),(0,r.jsx)(n.th,{style:{textAlign:"left"},children:"Category"}),(0,r.jsx)(n.th,{style:{textAlign:"left"},children:"Benchmark"}),(0,r.jsx)(n.th,{style:{textAlign:"left"},children:"Purpose"})]})}),(0,r.jsxs)(n.tbody,{children:[(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{style:{textAlign:"left"},children:(0,r.jsx)(n.strong,{children:"Functional Performance"})}),(0,r.jsx)(n.td,{style:{textAlign:"left"},children:"Functional Correctness"}),(0,r.jsx)(n.td,{style:{textAlign:"left"},children:"DevQualityEval"}),(0,r.jsx)(n.td,{style:{textAlign:"left"},children:"Assesses if generated code works as intended."})]}),(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{style:{textAlign:"left"},children:(0,r.jsx)(n.strong,{children:"Unit Test Performance"})}),(0,r.jsx)(n.td,{style:{textAlign:"left"},children:"Functional Correctness"}),(0,r.jsx)(n.td,{style:{textAlign:"left"},children:"LoCoBench"}),(0,r.jsx)(n.td,{style:{textAlign:"left"},children:"Assesses correctness at the individual function/method level."})]}),(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{style:{textAlign:"left"},children:(0,r.jsx)(n.strong,{children:"Integration Test Perf."})}),(0,r.jsx)(n.td,{style:{textAlign:"left"},children:"Functional Correctness"}),(0,r.jsx)(n.td,{style:{textAlign:"left"},children:"LoCoBench"}),(0,r.jsx)(n.td,{style:{textAlign:"left"},children:"Assesses correctness of interactions between code components."})]}),(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{style:{textAlign:"left"},children:(0,r.jsx)(n.strong,{children:"Diff. Performance Score"})}),(0,r.jsx)(n.td,{style:{textAlign:"left"},children:"Efficiency Evaluation"}),(0,r.jsx)(n.td,{style:{textAlign:"left"},children:"EVALPERF"}),(0,r.jsxs)(n.td,{style:{textAlign:"left"},children:["Measures the performance ",(0,r.jsx)(n.em,{children:"difference"})," against a baseline."]})]}),(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{style:{textAlign:"left"},children:(0,r.jsx)(n.strong,{children:"Normalized Diff. Perf. Score"})}),(0,r.jsx)(n.td,{style:{textAlign:"left"},children:"Efficiency Evaluation"}),(0,r.jsx)(n.td,{style:{textAlign:"left"},children:"EVALPERF"}),(0,r.jsxs)(n.td,{style:{textAlign:"left"},children:["Provides a ",(0,r.jsx)(n.em,{children:"standardized"})," score for performance differences."]})]})]})]}),"\n",(0,r.jsx)(n.h2,{id:"references",children:"References"}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["Bistarelli, S., Fiore, M., Mercanti, I. et al. Usage of Large Language Model for Code Generation Tasks: A Review. SN COMPUT. SCI. 6, 673 (2025). ",(0,r.jsx)(n.a,{href:"https://doi-org.ezproxy.uniandes.edu.co/10.1007/s42979-025-04241-5",children:"https://doi-org.ezproxy.uniandes.edu.co/10.1007/s42979-025-04241-5"})]}),"\n",(0,r.jsxs)(n.li,{children:["Liu, J., Xie, S., Wang, J., Wei, Y., Ding, Y., & Zhang, L. (2024). Evaluating language models for efficient code generation (arXiv:2408.06450). arXiv. ",(0,r.jsx)(n.a,{href:"https://doi.org/10.48550/arXiv.2408.06450",children:"https://doi.org/10.48550/arXiv.2408.06450"})]}),"\n",(0,r.jsxs)(n.li,{children:["Qiu, J., Liu, Z., Liu, Z., Murthy, R., Zhang, J., Chen, H., Wang, S., Zhu, M., Yang, L., Tan, J., Cen, Z., Qian, C., Heinecke, S., Yao, W., Savarese, S., Xiong, C., & Wang, H. (2025). LoCoBench: A benchmark for long-context large language models in complex software engineering (arXiv:2509.09614). arXiv. ",(0,r.jsx)(n.a,{href:"https://doi.org/10.48550/arXiv.2509.09614",children:"https://doi.org/10.48550/arXiv.2509.09614"})]}),"\n",(0,r.jsx)(n.li,{children:"(Excel Data: Papers 28, 41, 54)"}),"\n"]})]})}function f(e={}){const{wrapper:n}={...(0,s.R)(),...e.components};return n?(0,r.jsx)(n,{...e,children:(0,r.jsx)(d,{...e})}):d(e)}},8453:(e,n,i)=>{i.d(n,{R:()=>l,x:()=>o});var t=i(6540);const r={},s=t.createContext(r);function l(e){const n=t.useContext(s);return t.useMemo(function(){return"function"==typeof e?e(n):{...n,...e}},[n,e])}function o(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(r):e.components||r:l(e.components),t.createElement(s.Provider,{value:n},e.children)}}}]);