"use strict";(self.webpackChunkll_ms_metrics_catalog=self.webpackChunkll_ms_metrics_catalog||[]).push([[9651],{8453:(e,t,i)=>{i.d(t,{R:()=>r,x:()=>a});var n=i(6540);const s={},l=n.createContext(s);function r(e){const t=n.useContext(l);return n.useMemo(function(){return"function"==typeof e?e(t):{...t,...e}},[t,e])}function a(e){let t;return t=e.disableParentContext?"function"==typeof e.components?e.components(s):e.components||s:r(e.components),n.createElement(l.Provider,{value:t},e.children)}},8476:(e,t,i)=>{i.r(t),i.d(t,{assets:()=>o,contentTitle:()=>a,default:()=>h,frontMatter:()=>r,metadata:()=>n,toc:()=>d});const n=JSON.parse('{"id":"metrics/generative/fls","title":"FLS (Feature Likelihood Score)","description":"Introduction","source":"@site/docs/metrics/generative/fls.md","sourceDirName":"metrics/generative","slug":"/metrics/generative/fls","permalink":"/LLMs-metrics-catalog/metrics/generative/fls","draft":false,"unlisted":false,"tags":[],"version":"current","frontMatter":{"id":"fls","title":"FLS (Feature Likelihood Score)","sidebar_label":"FLS (Feature Likelihood Score)"},"sidebar":"docsSidebar","previous":{"title":"FD (Fr\xe9chet Distance)","permalink":"/LLMs-metrics-catalog/metrics/generative/fd"},"next":{"title":"Inception Score (IS)","permalink":"/LLMs-metrics-catalog/metrics/generative/inception"}}');var s=i(4848),l=i(8453);const r={id:"fls",title:"FLS (Feature Likelihood Score)",sidebar_label:"FLS (Feature Likelihood Score)"},a=void 0,o={},d=[{value:"Introduction",id:"introduction",level:2},{value:"1. FLS (Feature Likelihood Score)",id:"1-fls-feature-likelihood-score",level:2},{value:"Definition",id:"definition",level:3},{value:"Purpose",id:"purpose",level:3},{value:"Applications",id:"applications",level:3},{value:"Benchmarks",id:"benchmarks",level:3},{value:"Limitations",id:"limitations",level:3},{value:"2. FLS-POG (Percentage of Overfit Gaussians)",id:"2-fls-pog-percentage-of-overfit-gaussians",level:2},{value:"Definition",id:"definition-1",level:3},{value:"Purpose",id:"purpose-1",level:3},{value:"Limitations",id:"limitations-1",level:3},{value:"3. Comparative Summary",id:"3-comparative-summary",level:2},{value:"4. References",id:"4-references",level:2}];function c(e){const t={a:"a",annotation:"annotation",em:"em",h2:"h2",h3:"h3",li:"li",math:"math",mi:"mi",mrow:"mrow",msub:"msub",p:"p",semantics:"semantics",span:"span",strong:"strong",table:"table",tbody:"tbody",td:"td",th:"th",thead:"thead",tr:"tr",ul:"ul",...(0,l.R)(),...e.components};return(0,s.jsxs)(s.Fragment,{children:[(0,s.jsx)(t.h2,{id:"introduction",children:"Introduction"}),"\n",(0,s.jsxs)(t.p,{children:[(0,s.jsx)(t.strong,{children:"FLS (Feature Likelihood Score)"})," is a density estimation metric designed to evaluate the generalization performance of generative models. Introduced by Jiralerspong et al. (2023), its primary goal is to approximate a likelihood evaluation, even for models where a likelihood value is not readily available."]}),"\n",(0,s.jsxs)(t.p,{children:["The method works by fitting a Kernel Density Estimate (KDE) to the feature representations (e.g., from an Inception-V3 encoder) of the ",(0,s.jsx)(t.strong,{children:"generated"})," samples. The bandwidth for this KDE is optimized to maximize the log-likelihood of the ",(0,s.jsx)(t.strong,{children:"training"})," data. The final FLS score is then derived from the log-likelihood of the ",(0,s.jsx)(t.strong,{children:"test"})," data under this fitted KDE."]}),"\n",(0,s.jsxs)(t.p,{children:["FLS is used as a metric for ranking the overall quality of models [User provided data], but it also produces a diagnostic sub-metric, ",(0,s.jsx)(t.strong,{children:"FLS-POG"}),", which is specifically designed to measure memorization."]}),"\n",(0,s.jsx)(t.h2,{id:"1-fls-feature-likelihood-score",children:"1. FLS (Feature Likelihood Score)"}),"\n",(0,s.jsx)(t.h3,{id:"definition",children:"Definition"}),"\n",(0,s.jsxs)(t.p,{children:["FLS is a density estimation method that requires access to training, test, and generated samples. It fits a Kernel Density Estimate (KDE) to the encoded features of the generated samples. The KDE's bandwidths are chosen by maximizing the log-likelihood of the ",(0,s.jsx)(t.em,{children:"training data"}),". The final FLS score is an affine transformation of the log-likelihood of the ",(0,s.jsx)(t.em,{children:"test data"})," under this KDE."]}),"\n",(0,s.jsx)(t.h3,{id:"purpose",children:"Purpose"}),"\n",(0,s.jsx)(t.p,{children:'To provide a "Ranking / Overall Quality" score for generative models by approximating the likelihood of real test data under the model\'s generated distribution.'}),"\n",(0,s.jsx)(t.h3,{id:"applications",children:"Applications"}),"\n",(0,s.jsxs)(t.ul,{children:["\n",(0,s.jsx)(t.li,{children:"Generative Models / Image Generation [User provided data]"}),"\n",(0,s.jsx)(t.li,{children:"Ranking generative models"}),"\n"]}),"\n",(0,s.jsx)(t.h3,{id:"benchmarks",children:"Benchmarks"}),"\n",(0,s.jsxs)(t.ul,{children:["\n",(0,s.jsx)(t.li,{children:"CIFAR10"}),"\n",(0,s.jsx)(t.li,{children:"ImageNet1k"}),"\n",(0,s.jsx)(t.li,{children:"FFHQ"}),"\n",(0,s.jsx)(t.li,{children:"LSUN-Bedroom"}),"\n"]}),"\n",(0,s.jsx)(t.h3,{id:"limitations",children:"Limitations"}),"\n",(0,s.jsxs)(t.ul,{children:["\n",(0,s.jsx)(t.li,{children:"FLS is not strongly correlated with human evaluations of image realism, particularly on complex datasets."}),"\n",(0,s.jsx)(t.li,{children:"The metric can be sensitive to the choice of encoder used for feature extraction."}),"\n"]}),"\n",(0,s.jsx)(t.h2,{id:"2-fls-pog-percentage-of-overfit-gaussians",children:"2. FLS-POG (Percentage of Overfit Gaussians)"}),"\n",(0,s.jsx)(t.h3,{id:"definition-1",children:"Definition"}),"\n",(0,s.jsxs)(t.p,{children:["FLS-POG is a metric derived from the FLS calculation, designed specifically to measure ",(0,s.jsx)(t.strong,{children:"memorization"}),'. It is defined as the "percentage of generated samples that had a higher log-likelihood under the training set than the test set". A high FLS-POG score suggests that the generated samples are more "typical" of the training set than the test set, indicating overfitting or memorization.']}),"\n",(0,s.jsx)(t.h3,{id:"purpose-1",children:"Purpose"}),"\n",(0,s.jsx)(t.p,{children:"To automatically detect memorization in generative models, claiming to isolate it from other phenomena like mode collapse."}),"\n",(0,s.jsx)(t.h3,{id:"limitations-1",children:"Limitations"}),"\n",(0,s.jsx)(t.p,{children:"FLS-POG has been shown to be an unreliable metric for memorization."}),"\n",(0,s.jsxs)(t.ul,{children:["\n",(0,s.jsxs)(t.li,{children:["It ",(0,s.jsx)(t.strong,{children:"correlates poorly"})," with the actual, measured percentage of memorized samples."]}),"\n",(0,s.jsxs)(t.li,{children:["In controlled experiments, it was found to be the ",(0,s.jsx)(t.strong,{children:"weakest detector of memorization"})," compared to other metrics like AuthPct and ",(0,s.jsx)(t.span,{className:"katex",children:(0,s.jsx)(t.math,{xmlns:"http://www.w3.org/1998/Math/MathML",children:(0,s.jsxs)(t.semantics,{children:[(0,s.jsx)(t.mrow,{children:(0,s.jsxs)(t.msub,{children:[(0,s.jsx)(t.mi,{children:"C"}),(0,s.jsx)(t.mi,{children:"T"})]})}),(0,s.jsx)(t.annotation,{encoding:"application/x-tex",children:"C_{T}"})]})})}),"."]}),"\n",(0,s.jsxs)(t.li,{children:["It also ",(0,s.jsx)(t.strong,{children:"fails to flag mode shrinkage"})," correctly."]}),"\n"]}),"\n",(0,s.jsx)(t.h2,{id:"3-comparative-summary",children:"3. Comparative Summary"}),"\n",(0,s.jsxs)(t.table,{children:[(0,s.jsx)(t.thead,{children:(0,s.jsxs)(t.tr,{children:[(0,s.jsx)(t.th,{style:{textAlign:"left"},children:"Metric"}),(0,s.jsx)(t.th,{style:{textAlign:"left"},children:"Based on"}),(0,s.jsx)(t.th,{style:{textAlign:"left"},children:"Extension Goal"}),(0,s.jsx)(t.th,{style:{textAlign:"left"},children:"Key Feature(s)"}),(0,s.jsx)(t.th,{style:{textAlign:"left"},children:"Typical Domain"})]})}),(0,s.jsxs)(t.tbody,{children:[(0,s.jsxs)(t.tr,{children:[(0,s.jsx)(t.td,{style:{textAlign:"left"},children:(0,s.jsx)(t.strong,{children:"FLS"})}),(0,s.jsx)(t.td,{style:{textAlign:"left"},children:"KDE"}),(0,s.jsx)(t.td,{style:{textAlign:"left"},children:"Rank models based on density estimation."}),(0,s.jsx)(t.td,{style:{textAlign:"left"},children:"Fits a KDE to generated data; evaluates log-likelihood on test data."}),(0,s.jsx)(t.td,{style:{textAlign:"left"},children:"Image Generation (Overall Quality)"})]}),(0,s.jsxs)(t.tr,{children:[(0,s.jsx)(t.td,{style:{textAlign:"left"},children:(0,s.jsx)(t.strong,{children:"FLS-POG"})}),(0,s.jsx)(t.td,{style:{textAlign:"left"},children:"FLS"}),(0,s.jsx)(t.td,{style:{textAlign:"left"},children:"Detect memorization / overfitting."}),(0,s.jsx)(t.td,{style:{textAlign:"left"},children:"Compares train vs. test log-likelihood for each generated sample."}),(0,s.jsx)(t.td,{style:{textAlign:"left"},children:"Image Generation (Memorization)"})]})]})]}),"\n",(0,s.jsx)(t.h2,{id:"4-references",children:"4. References"}),"\n",(0,s.jsxs)(t.ul,{children:["\n",(0,s.jsxs)(t.li,{children:["\n",(0,s.jsxs)(t.p,{children:["Stein, G., Cresswell, J. C., Hosseinzadeh, R., et al. (2023). ",(0,s.jsx)(t.em,{children:"Exposing flaws of generative model evaluation metrics and their unfair treatment of diffusion models"}),". ",(0,s.jsx)(t.a,{href:"https://doi.org/10.48550/arXiv.2306.04675",children:"https://doi.org/10.48550/arXiv.2306.04675"})]}),"\n"]}),"\n",(0,s.jsxs)(t.li,{children:["\n",(0,s.jsxs)(t.p,{children:["Jiralerspong, M., Bose, A. J., & Gidel, G. (2023). ",(0,s.jsx)(t.em,{children:"Feature likelihood score: Evaluating generalization of generative models using samples"}),"."]}),"\n"]}),"\n",(0,s.jsxs)(t.li,{children:["\n",(0,s.jsx)(t.p,{children:"(Excel Data: Paper 67)"}),"\n"]}),"\n"]})]})}function h(e={}){const{wrapper:t}={...(0,l.R)(),...e.components};return t?(0,s.jsx)(t,{...e,children:(0,s.jsx)(c,{...e})}):c(e)}}}]);