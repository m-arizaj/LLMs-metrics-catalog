"use strict";(self.webpackChunkll_ms_metrics_catalog=self.webpackChunkll_ms_metrics_catalog||[]).push([[6411],{6610:(e,n,i)=>{i.r(n),i.d(n,{assets:()=>c,contentTitle:()=>r,default:()=>h,frontMatter:()=>l,metadata:()=>t,toc:()=>o});const t=JSON.parse('{"id":"metrics/semantic/hallucination","title":"Hallucination","description":"Introduction","source":"@site/docs/metrics/semantic/hallucination.md","sourceDirName":"metrics/semantic","slug":"/metrics/semantic/hallucination","permalink":"/LLMs-metrics-catalog/metrics/semantic/hallucination","draft":false,"unlisted":false,"tags":[],"version":"current","frontMatter":{"id":"hallucination","title":"Hallucination","sidebar_label":"Hallucination"},"sidebar":"docsSidebar","previous":{"title":"Reward Score","permalink":"/LLMs-metrics-catalog/metrics/ranking/reward-score"},"next":{"title":"Distinguishability (d)","permalink":"/LLMs-metrics-catalog/metrics/semantic/distinguishability"}}');var a=i(4848),s=i(8453);const l={id:"hallucination",title:"Hallucination",sidebar_label:"Hallucination"},r=void 0,c={},o=[{value:"Introduction",id:"introduction",level:2},{value:"Formula and Structure",id:"formula-and-structure",level:2},{value:"Variants and Implementations",id:"variants-and-implementations",level:2},{value:"1. Hallucination Rate",id:"1-hallucination-rate",level:3},{value:"2. Hallucination Ratio (Hal)",id:"2-hallucination-ratio-hal",level:3},{value:"3. General Hallucination Metric",id:"3-general-hallucination-metric",level:3},{value:"4. FEWL-based Factualness",id:"4-fewl-based-factualness",level:3},{value:"Interpretation",id:"interpretation",level:2},{value:"References",id:"references",level:2},{value:"Additional References in Dataset",id:"additional-references-in-dataset",level:3}];function d(e){const n={a:"a",annotation:"annotation",br:"br",em:"em",h2:"h2",h3:"h3",li:"li",math:"math",mfrac:"mfrac",mi:"mi",mo:"mo",mrow:"mrow",msub:"msub",mtext:"mtext",ol:"ol",p:"p",semantics:"semantics",span:"span",ul:"ul",...(0,s.R)(),...e.components};return(0,a.jsxs)(a.Fragment,{children:[(0,a.jsx)(n.h2,{id:"introduction",children:"Introduction"}),"\n",(0,a.jsxs)(n.p,{children:["The Hallucination metric evaluates the degree to which a model generates content that is factually incorrect, irrelevant, or self-contradictory with respect to the input or known ground truth.",(0,a.jsx)(n.br,{}),"\n","In large language models and software engineering contexts, hallucination refers to statements, code, or outputs that appear syntactically valid but are semantically false or unverifiable."]}),"\n",(0,a.jsx)(n.p,{children:"This metric is crucial for assessing model reliability, truthfulness, and robustness in tasks such as code documentation, automated debugging, or generation of factual technical explanations."}),"\n",(0,a.jsx)(n.h2,{id:"formula-and-structure",children:"Formula and Structure"}),"\n",(0,a.jsx)(n.p,{children:"Although hallucination is typically measured via discrete rates rather than continuous scores, a general quantitative definition can be given as:"}),"\n",(0,a.jsx)(n.span,{className:"katex",children:(0,a.jsx)(n.math,{xmlns:"http://www.w3.org/1998/Math/MathML",display:"block",children:(0,a.jsxs)(n.semantics,{children:[(0,a.jsxs)(n.mrow,{children:[(0,a.jsxs)(n.msub,{children:[(0,a.jsx)(n.mi,{children:"H"}),(0,a.jsxs)(n.mrow,{children:[(0,a.jsx)(n.mi,{children:"r"}),(0,a.jsx)(n.mi,{children:"a"}),(0,a.jsx)(n.mi,{children:"t"}),(0,a.jsx)(n.mi,{children:"e"})]})]}),(0,a.jsx)(n.mo,{children:"="}),(0,a.jsxs)(n.mfrac,{children:[(0,a.jsxs)(n.msub,{children:[(0,a.jsx)(n.mi,{children:"N"}),(0,a.jsxs)(n.mrow,{children:[(0,a.jsx)(n.mi,{children:"h"}),(0,a.jsx)(n.mi,{children:"a"}),(0,a.jsx)(n.mi,{children:"l"}),(0,a.jsx)(n.mi,{children:"l"}),(0,a.jsx)(n.mi,{children:"u"}),(0,a.jsx)(n.mi,{children:"c"}),(0,a.jsx)(n.mi,{children:"i"}),(0,a.jsx)(n.mi,{children:"n"}),(0,a.jsx)(n.mi,{children:"a"}),(0,a.jsx)(n.mi,{children:"t"}),(0,a.jsx)(n.mi,{children:"e"}),(0,a.jsx)(n.mi,{children:"d"})]})]}),(0,a.jsxs)(n.msub,{children:[(0,a.jsx)(n.mi,{children:"N"}),(0,a.jsxs)(n.mrow,{children:[(0,a.jsx)(n.mi,{children:"t"}),(0,a.jsx)(n.mi,{children:"o"}),(0,a.jsx)(n.mi,{children:"t"}),(0,a.jsx)(n.mi,{children:"a"}),(0,a.jsx)(n.mi,{children:"l"})]})]})]})]}),(0,a.jsx)(n.annotation,{encoding:"application/x-tex",children:"H_{rate} = \\frac{N_{hallucinated}}{N_{total}}"})]})})}),"\n",(0,a.jsx)(n.p,{children:"where:"}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsxs)(n.li,{children:[(0,a.jsx)(n.span,{className:"katex",children:(0,a.jsx)(n.math,{xmlns:"http://www.w3.org/1998/Math/MathML",children:(0,a.jsxs)(n.semantics,{children:[(0,a.jsx)(n.mrow,{children:(0,a.jsxs)(n.msub,{children:[(0,a.jsx)(n.mi,{children:"N"}),(0,a.jsxs)(n.mrow,{children:[(0,a.jsx)(n.mi,{children:"h"}),(0,a.jsx)(n.mi,{children:"a"}),(0,a.jsx)(n.mi,{children:"l"}),(0,a.jsx)(n.mi,{children:"l"}),(0,a.jsx)(n.mi,{children:"u"}),(0,a.jsx)(n.mi,{children:"c"}),(0,a.jsx)(n.mi,{children:"i"}),(0,a.jsx)(n.mi,{children:"n"}),(0,a.jsx)(n.mi,{children:"a"}),(0,a.jsx)(n.mi,{children:"t"}),(0,a.jsx)(n.mi,{children:"e"}),(0,a.jsx)(n.mi,{children:"d"})]})]})}),(0,a.jsx)(n.annotation,{encoding:"application/x-tex",children:"N_{hallucinated}"})]})})})," is the number of responses containing factual or logical hallucinations,"]}),"\n",(0,a.jsxs)(n.li,{children:[(0,a.jsx)(n.span,{className:"katex",children:(0,a.jsx)(n.math,{xmlns:"http://www.w3.org/1998/Math/MathML",children:(0,a.jsxs)(n.semantics,{children:[(0,a.jsx)(n.mrow,{children:(0,a.jsxs)(n.msub,{children:[(0,a.jsx)(n.mi,{children:"N"}),(0,a.jsxs)(n.mrow,{children:[(0,a.jsx)(n.mi,{children:"t"}),(0,a.jsx)(n.mi,{children:"o"}),(0,a.jsx)(n.mi,{children:"t"}),(0,a.jsx)(n.mi,{children:"a"}),(0,a.jsx)(n.mi,{children:"l"})]})]})}),(0,a.jsx)(n.annotation,{encoding:"application/x-tex",children:"N_{total}"})]})})})," is the total number of evaluated responses."]}),"\n"]}),"\n",(0,a.jsx)(n.p,{children:"Some studies instead define the Hallucination Ratio (Hal) as a normalized measure between 0 and 1 to capture the proportion of hallucinated content relative to the total generated text length or segments."}),"\n",(0,a.jsx)(n.span,{className:"katex",children:(0,a.jsx)(n.math,{xmlns:"http://www.w3.org/1998/Math/MathML",display:"block",children:(0,a.jsxs)(n.semantics,{children:[(0,a.jsxs)(n.mrow,{children:[(0,a.jsx)(n.mi,{children:"H"}),(0,a.jsx)(n.mi,{children:"a"}),(0,a.jsx)(n.mi,{children:"l"}),(0,a.jsx)(n.mo,{children:"="}),(0,a.jsxs)(n.mfrac,{children:[(0,a.jsx)(n.mtext,{children:"Length\xa0of\xa0hallucinated\xa0content"}),(0,a.jsx)(n.mtext,{children:"Total\xa0output\xa0length"})]})]}),(0,a.jsx)(n.annotation,{encoding:"application/x-tex",children:"Hal = \\frac{\\text{Length of hallucinated content}}{\\text{Total output length}}"})]})})}),"\n",(0,a.jsx)(n.p,{children:"These formulations can be adapted to measure hallucination in code generation by replacing textual segments with code statements or functions."}),"\n",(0,a.jsx)(n.h2,{id:"variants-and-implementations",children:"Variants and Implementations"}),"\n",(0,a.jsx)(n.h3,{id:"1-hallucination-rate",children:"1. Hallucination Rate"}),"\n",(0,a.jsxs)(n.p,{children:["Used in HELM (2024), this variant measures the proportion of hallucinated outputs across multiple tasks.",(0,a.jsx)(n.br,{}),"\n","It focuses on truthfulness and error handling robustness, identifying when the model produces plausible but factually incorrect information."]}),"\n",(0,a.jsx)(n.h3,{id:"2-hallucination-ratio-hal",children:"2. Hallucination Ratio (Hal)"}),"\n",(0,a.jsx)(n.p,{children:"Adopted in AMBER (2024) for generative multimodal tasks, this variant quantifies hallucination as a fraction of generated elements that deviate from factual or logical grounding."}),"\n",(0,a.jsx)(n.h3,{id:"3-general-hallucination-metric",children:"3. General Hallucination Metric"}),"\n",(0,a.jsx)(n.p,{children:"Applied in Software Testing benchmarks for detecting hallucinated or misleading responses in automatically generated documentation or logs. This measure emphasizes reliability within technical code evaluations."}),"\n",(0,a.jsx)(n.h3,{id:"4-fewl-based-factualness",children:"4. FEWL-based Factualness"}),"\n",(0,a.jsx)(n.p,{children:"From Wei et al. (2024), the FEWL (Factualness Evaluations via Weighting LLMs) framework proposes a model-based approach to hallucination detection without gold-standard answers. It aggregates judgments from several trusted models to compute a factualness score, penalizing superficial or inconsistent responses."}),"\n",(0,a.jsx)(n.h2,{id:"interpretation",children:"Interpretation"}),"\n",(0,a.jsxs)(n.p,{children:["Hallucination metrics reflect the factual integrity and trustworthiness of a model\u2019s output.",(0,a.jsx)(n.br,{}),"\n","A lower hallucination rate indicates higher reliability and alignment with reference data or logical correctness.",(0,a.jsx)(n.br,{}),"\n","In software engineering, hallucination manifests as:"]}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsx)(n.li,{children:"Non-existent API calls,"}),"\n",(0,a.jsx)(n.li,{children:"Incorrect library imports,"}),"\n",(0,a.jsx)(n.li,{children:"Fabricated function arguments or values."}),"\n"]}),"\n",(0,a.jsx)(n.p,{children:"Reducing hallucination improves debuggability, code maintainability, and developer trust in LLM-assisted programming."}),"\n",(0,a.jsx)(n.h2,{id:"references",children:"References"}),"\n",(0,a.jsxs)(n.ol,{children:["\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.em,{children:"Ji, Z., Lee, N., Frieske, R., Yu, T., Su, D., Xu, Y., Ishii, E., Bang, Y., Madotto, A., & Fung, P. (2023)."}),(0,a.jsx)(n.br,{}),"\n","A Survey on Hallucination in Large Language Models.",(0,a.jsx)(n.br,{}),"\n",(0,a.jsx)(n.a,{href:"https://arxiv.org/abs/2311.05232",children:"https://arxiv.org/abs/2311.05232"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.em,{children:"Wei, J., Chen, D., Xie, Y., Huang, S., & Xiong, C. (2024)."}),(0,a.jsx)(n.br,{}),"\n","Measuring and Reducing LLM Hallucination without Gold-Standard Answers.",(0,a.jsx)(n.br,{}),"\n",(0,a.jsx)(n.a,{href:"https://arxiv.org/abs/2402.10412",children:"https://arxiv.org/abs/2402.10412"})]}),"\n"]}),"\n"]}),"\n",(0,a.jsx)(n.h3,{id:"additional-references-in-dataset",children:"Additional References in Dataset"}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsx)(n.li,{children:"8, 9,\xa048,\xa062"}),"\n"]})]})}function h(e={}){const{wrapper:n}={...(0,s.R)(),...e.components};return n?(0,a.jsx)(n,{...e,children:(0,a.jsx)(d,{...e})}):d(e)}},8453:(e,n,i)=>{i.d(n,{R:()=>l,x:()=>r});var t=i(6540);const a={},s=t.createContext(a);function l(e){const n=t.useContext(s);return t.useMemo(function(){return"function"==typeof e?e(n):{...n,...e}},[n,e])}function r(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(a):e.components||a:l(e.components),t.createElement(s.Provider,{value:n},e.children)}}}]);