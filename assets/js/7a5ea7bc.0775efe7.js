"use strict";(self.webpackChunkll_ms_metrics_catalog=self.webpackChunkll_ms_metrics_catalog||[]).push([[5628],{7545:(e,n,s)=>{s.r(n),s.d(n,{assets:()=>c,contentTitle:()=>l,default:()=>h,frontMatter:()=>r,metadata:()=>i,toc:()=>o});const i=JSON.parse('{"id":"metrics/ranking/language-model-score","title":"Language Model Score (lms)","description":"Definition","source":"@site/docs/metrics/ranking/Language-model-score.md","sourceDirName":"metrics/ranking","slug":"/metrics/ranking/language-model-score","permalink":"/LLMs-metrics-catalog/metrics/ranking/language-model-score","draft":false,"unlisted":false,"tags":[],"version":"current","frontMatter":{"id":"language-model-score","title":"Language Model Score (lms)","sidebar_label":"Language Model Score"},"sidebar":"docsSidebar","previous":{"title":"LLM-as-Judge / Killings","permalink":"/LLMs-metrics-catalog/metrics/ranking/llm-evaluation-metrics"},"next":{"title":"LoCoBench Score","permalink":"/LLMs-metrics-catalog/metrics/ranking/locobench-score"}}');var t=s(4848),a=s(8453);const r={id:"language-model-score",title:"Language Model Score (lms)",sidebar_label:"Language Model Score"},l=void 0,c={},o=[{value:"Definition",id:"definition",level:2},{value:"Formula (General Idea)",id:"formula-general-idea",level:2},{value:"Purpose",id:"purpose",level:2},{value:"Domains",id:"domains",level:2},{value:"Benchmarks",id:"benchmarks",level:2},{value:"Advantages",id:"advantages",level:2},{value:"Limitations",id:"limitations",level:2},{value:"Key References",id:"key-references",level:2}];function d(e){const n={a:"a",annotation:"annotation",code:"code",em:"em",h2:"h2",hr:"hr",li:"li",math:"math",mfrac:"mfrac",mi:"mi",mn:"mn",mo:"mo",mrow:"mrow",msub:"msub",mtext:"mtext",munder:"munder",p:"p",semantics:"semantics",span:"span",strong:"strong",ul:"ul",...(0,a.R)(),...e.components};return(0,t.jsxs)(t.Fragment,{children:[(0,t.jsx)(n.h2,{id:"definition",children:"Definition"}),"\n",(0,t.jsxs)(n.p,{children:["The ",(0,t.jsx)(n.strong,{children:"Language Model Score (lms)"})," is a metric used within the evaluation framework of the ",(0,t.jsx)(n.strong,{children:"StereoSet"})," benchmark. It is not a direct measure of social bias itself, but rather a measure of a model's basic language understanding and coherence."]}),"\n",(0,t.jsxs)(n.p,{children:["It specifically calculates the ",(0,t.jsx)(n.strong,{children:"percentage of instances where a model prefers a meaningful sentence option over a meaningless (unrelated) one"}),". This score is then used as a component to calculate the ",(0,t.jsx)(n.strong,{children:"Idealized CAT (iCAT) Score"}),", which balances the model's language capability (",(0,t.jsx)(n.code,{children:"lms"}),") against its stereotyping tendencies (",(0,t.jsx)(n.code,{children:"ss"}),", or stereotype score)."]}),"\n",(0,t.jsx)(n.hr,{}),"\n",(0,t.jsx)(n.h2,{id:"formula-general-idea",children:"Formula (General Idea)"}),"\n",(0,t.jsxs)(n.p,{children:["The StereoSet dataset provides examples with three options: a stereotype, an anti-stereotype, and a meaningless option. To calculate the ",(0,t.jsx)(n.code,{children:"lms"}),", only the meaningful (stereotype or anti-stereotype) and meaningless options are compared."]}),"\n",(0,t.jsxs)(n.p,{children:["The ",(0,t.jsx)(n.code,{children:"lms"})," is the percentage of times the model assigns a higher probability (e.g., via pseudo-log-likelihood) to a meaningful sentence than to the meaningless one."]}),"\n",(0,t.jsx)(n.span,{className:"katex",children:(0,t.jsx)(n.math,{xmlns:"http://www.w3.org/1998/Math/MathML",display:"block",children:(0,t.jsxs)(n.semantics,{children:[(0,t.jsxs)(n.mrow,{children:[(0,t.jsx)(n.mtext,{children:"lms"}),(0,t.jsx)(n.mo,{children:"="}),(0,t.jsxs)(n.mfrac,{children:[(0,t.jsx)(n.mn,{children:"1"}),(0,t.jsxs)(n.mrow,{children:[(0,t.jsx)(n.mi,{mathvariant:"normal",children:"\u2223"}),(0,t.jsx)(n.mi,{mathvariant:"script",children:"S"}),(0,t.jsx)(n.mi,{mathvariant:"normal",children:"\u2223"})]})]}),(0,t.jsxs)(n.munder,{children:[(0,t.jsx)(n.mo,{children:"\u2211"}),(0,t.jsxs)(n.mrow,{children:[(0,t.jsx)(n.mi,{children:"i"}),(0,t.jsx)(n.mo,{children:"\u2208"}),(0,t.jsx)(n.mi,{mathvariant:"script",children:"S"})]})]}),(0,t.jsx)(n.mi,{mathvariant:"double-struck",children:"I"}),(0,t.jsx)(n.mo,{stretchy:"false",children:"("}),(0,t.jsx)(n.mtext,{children:"model_score"}),(0,t.jsx)(n.mo,{stretchy:"false",children:"("}),(0,t.jsxs)(n.msub,{children:[(0,t.jsx)(n.mi,{children:"S"}),(0,t.jsxs)(n.mrow,{children:[(0,t.jsx)(n.mtext,{children:"meaningful"}),(0,t.jsx)(n.mo,{separator:"true",children:","}),(0,t.jsx)(n.mi,{children:"i"})]})]}),(0,t.jsx)(n.mo,{stretchy:"false",children:")"}),(0,t.jsx)(n.mo,{children:">"}),(0,t.jsx)(n.mtext,{children:"model_score"}),(0,t.jsx)(n.mo,{stretchy:"false",children:"("}),(0,t.jsxs)(n.msub,{children:[(0,t.jsx)(n.mi,{children:"S"}),(0,t.jsxs)(n.mrow,{children:[(0,t.jsx)(n.mtext,{children:"meaningless"}),(0,t.jsx)(n.mo,{separator:"true",children:","}),(0,t.jsx)(n.mi,{children:"i"})]})]}),(0,t.jsx)(n.mo,{stretchy:"false",children:")"}),(0,t.jsx)(n.mo,{stretchy:"false",children:")"}),(0,t.jsx)(n.mo,{children:"\xd7"}),(0,t.jsx)(n.mn,{children:"100"})]}),(0,t.jsx)(n.annotation,{encoding:"application/x-tex",children:"\\text{lms} = \\frac{1}{|\\mathcal{S}|} \\sum_{i \\in \\mathcal{S}} \\mathbb{I}(\\text{model\\_score}(S_{\\text{meaningful}, i}) > \\text{model\\_score}(S_{\\text{meaningless}, i})) \\times 100"})]})})}),"\n",(0,t.jsx)(n.p,{children:"Where:"}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.span,{className:"katex",children:(0,t.jsx)(n.math,{xmlns:"http://www.w3.org/1998/Math/MathML",children:(0,t.jsxs)(n.semantics,{children:[(0,t.jsx)(n.mrow,{children:(0,t.jsx)(n.mi,{mathvariant:"script",children:"S"})}),(0,t.jsx)(n.annotation,{encoding:"application/x-tex",children:"\\mathcal{S}"})]})})})," is the set of examples in the dataset."]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.span,{className:"katex",children:(0,t.jsx)(n.math,{xmlns:"http://www.w3.org/1998/Math/MathML",children:(0,t.jsxs)(n.semantics,{children:[(0,t.jsx)(n.mrow,{children:(0,t.jsx)(n.mi,{mathvariant:"double-struck",children:"I"})}),(0,t.jsx)(n.annotation,{encoding:"application/x-tex",children:"\\mathbb{I}"})]})})})," is the indicator function."]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.span,{className:"katex",children:(0,t.jsx)(n.math,{xmlns:"http://www.w3.org/1998/Math/MathML",children:(0,t.jsxs)(n.semantics,{children:[(0,t.jsx)(n.mrow,{children:(0,t.jsxs)(n.msub,{children:[(0,t.jsx)(n.mi,{children:"S"}),(0,t.jsx)(n.mtext,{children:"meaningful"})]})}),(0,t.jsx)(n.annotation,{encoding:"application/x-tex",children:"S_{\\text{meaningful}}"})]})})})," is either the stereotype or anti-stereotype option."]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.span,{className:"katex",children:(0,t.jsx)(n.math,{xmlns:"http://www.w3.org/1998/Math/MathML",children:(0,t.jsxs)(n.semantics,{children:[(0,t.jsx)(n.mrow,{children:(0,t.jsxs)(n.msub,{children:[(0,t.jsx)(n.mi,{children:"S"}),(0,t.jsx)(n.mtext,{children:"meaningless"})]})}),(0,t.jsx)(n.annotation,{encoding:"application/x-tex",children:"S_{\\text{meaningless}}"})]})})})," is the unrelated, nonsensical option."]}),"\n"]}),"\n",(0,t.jsx)(n.hr,{}),"\n",(0,t.jsx)(n.h2,{id:"purpose",children:"Purpose"}),"\n",(0,t.jsxs)(n.p,{children:["The primary purpose of the ",(0,t.jsx)(n.code,{children:"lms"})," is to ",(0,t.jsx)(n.strong,{children:"evaluate a model's fundamental language modeling capability"})," (i.e., its ability to distinguish coherent text from nonsense) before evaluating its social bias."]}),"\n",(0,t.jsxs)(n.p,{children:['An "idealized language model" is defined as having an ',(0,t.jsx)(n.code,{children:"lms"})," of 100 (it always prefers the meaningful option) and a stereotype score of 50 (it chooses equally between stereotype and anti-stereotype options). The ",(0,t.jsx)(n.code,{children:"lms"}),' essentially acts as a "sanity check"; if a model\'s ',(0,t.jsx)(n.code,{children:"lms"})," is low (e.g., 50%), it is choosing randomly, and its stereotype score is therefore not a meaningful indicator of bias."]}),"\n",(0,t.jsx)(n.hr,{}),"\n",(0,t.jsx)(n.h2,{id:"domains",children:"Domains"}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsx)(n.li,{children:(0,t.jsx)(n.strong,{children:"Fairness / Bias Evaluation"})}),"\n",(0,t.jsx)(n.li,{children:"Stereotypical Bias Evaluation"}),"\n",(0,t.jsx)(n.li,{children:"Natural Language Understanding (NLU)"}),"\n"]}),"\n",(0,t.jsx)(n.hr,{}),"\n",(0,t.jsx)(n.h2,{id:"benchmarks",children:"Benchmarks"}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"StereoSet"}),": The ",(0,t.jsx)(n.code,{children:"lms"})," is a key component of the evaluation metric proposed with this benchmark."]}),"\n"]}),"\n",(0,t.jsx)(n.hr,{}),"\n",(0,t.jsx)(n.h2,{id:"advantages",children:"Advantages"}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Isolates Language Capability:"})," It separates the model's basic language understanding from its stereotyping tendency, allowing for a more nuanced interpretation of the bias score."]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Contextualizes Bias Scores:"})," It is a crucial component of the ",(0,t.jsx)(n.strong,{children:"iCAT Score"})," (",(0,t.jsx)(n.span,{className:"katex",children:(0,t.jsx)(n.math,{xmlns:"http://www.w3.org/1998/Math/MathML",children:(0,t.jsxs)(n.semantics,{children:[(0,t.jsxs)(n.mrow,{children:[(0,t.jsx)(n.mi,{children:"i"}),(0,t.jsx)(n.mi,{children:"C"}),(0,t.jsx)(n.mi,{children:"A"}),(0,t.jsx)(n.mi,{children:"T"}),(0,t.jsx)(n.mo,{children:"="}),(0,t.jsx)(n.mi,{children:"l"}),(0,t.jsx)(n.mi,{children:"m"}),(0,t.jsx)(n.mi,{children:"s"}),(0,t.jsx)(n.mo,{children:"\u22c5"}),(0,t.jsxs)(n.mfrac,{children:[(0,t.jsxs)(n.mrow,{children:[(0,t.jsx)(n.mi,{children:"m"}),(0,t.jsx)(n.mi,{children:"i"}),(0,t.jsx)(n.mi,{children:"n"}),(0,t.jsx)(n.mo,{stretchy:"false",children:"("}),(0,t.jsx)(n.mi,{children:"s"}),(0,t.jsx)(n.mi,{children:"s"}),(0,t.jsx)(n.mo,{separator:"true",children:","}),(0,t.jsx)(n.mn,{children:"100"}),(0,t.jsx)(n.mo,{children:"\u2212"}),(0,t.jsx)(n.mi,{children:"s"}),(0,t.jsx)(n.mi,{children:"s"}),(0,t.jsx)(n.mo,{stretchy:"false",children:")"})]}),(0,t.jsx)(n.mn,{children:"50"})]})]}),(0,t.jsx)(n.annotation,{encoding:"application/x-tex",children:"iCAT = lms \\cdot \\frac{min(ss, 100-ss)}{50}"})]})})}),"), which provides a single, combined score reflecting both model capability and fairness."]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Provides a Sanity Check:"})," A low ",(0,t.jsx)(n.code,{children:"lms"})," score immediately indicates that the model is failing at the basic task, rendering its bias-specific scores unreliable."]}),"\n"]}),"\n",(0,t.jsx)(n.hr,{}),"\n",(0,t.jsx)(n.h2,{id:"limitations",children:"Limitations"}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Benchmark Validity:"})," The ",(0,t.jsx)(n.code,{children:"lms"}),' is intrinsically tied to the StereoSet benchmark. This benchmark, along with others, has faced criticism for "severe shortcomings".']}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Ambiguity:"}),' The dataset instances may contain "ambiguities about what stereotypes they capture". This ambiguity could potentially affect the clear distinction between "meaningful" and "meaningless" options in some cases, thus impacting the ',(0,t.jsx)(n.code,{children:"lms"})," score."]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Oversimplification:"})," The task of choosing between pre-defined sentence options may not fully capture a model's real-world behavior or its propensity to ",(0,t.jsx)(n.em,{children:"generate"})," biased text on its own."]}),"\n"]}),"\n",(0,t.jsx)(n.hr,{}),"\n",(0,t.jsx)(n.h2,{id:"key-references",children:"Key References"}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsxs)(n.li,{children:["Nadeem, M., Bethke, A., & Reddy, S. (2021). StereoSet: Measuring stereotypical bias in pretrained language models. ",(0,t.jsx)(n.em,{children:"Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics (ACL)"}),"."]}),"\n",(0,t.jsxs)(n.li,{children:["Gallegos, I. O., Rossi, R. A., Barrow, J., Tanjim, M. M., Kim, S., Dernoncourt, F., Yu, T., Zhang, R., & Ahmed, N. K. (2024). Bias and fairness in large language models: A survey. Computational Linguistics, 50(3), 1097\u20131179. ",(0,t.jsx)(n.a,{href:"https://doi.org/10.1162/coli_a_00524",children:"https://doi.org/10.1162/coli_a_00524"})]}),"\n",(0,t.jsx)(n.li,{children:"(Excel Data: Paper 16)"}),"\n"]})]})}function h(e={}){const{wrapper:n}={...(0,a.R)(),...e.components};return n?(0,t.jsx)(n,{...e,children:(0,t.jsx)(d,{...e})}):d(e)}},8453:(e,n,s)=>{s.d(n,{R:()=>r,x:()=>l});var i=s(6540);const t={},a=i.createContext(t);function r(e){const n=i.useContext(a);return i.useMemo(function(){return"function"==typeof e?e(n):{...n,...e}},[n,e])}function l(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(t):e.components||t:r(e.components),i.createElement(a.Provider,{value:n},e.children)}}}]);