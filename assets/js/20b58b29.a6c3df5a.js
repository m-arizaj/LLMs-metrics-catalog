"use strict";(self.webpackChunkll_ms_metrics_catalog=self.webpackChunkll_ms_metrics_catalog||[]).push([[8703],{31:(e,i,n)=>{n.r(i),n.d(i,{assets:()=>h,contentTitle:()=>t,default:()=>d,frontMatter:()=>l,metadata:()=>s,toc:()=>a});const s=JSON.parse('{"id":"metrics/ranking/locobench-score","title":"LoCoBench Score (LCBS)","description":"Definition","source":"@site/docs/metrics/ranking/locobench-score.md","sourceDirName":"metrics/ranking","slug":"/metrics/ranking/locobench-score","permalink":"/LLMs-metrics-catalog/metrics/ranking/locobench-score","draft":false,"unlisted":false,"tags":[],"version":"current","frontMatter":{"id":"locobench-score","title":"LoCoBench Score (LCBS)","sidebar_label":"LoCoBench Score"},"sidebar":"docsSidebar","previous":{"title":"Language Model Score","permalink":"/LLMs-metrics-catalog/metrics/ranking/language-model-score"},"next":{"title":"Hallucination","permalink":"/LLMs-metrics-catalog/metrics/semantic/hallucination"}}');var r=n(4848),c=n(8453);const l={id:"locobench-score",title:"LoCoBench Score (LCBS)",sidebar_label:"LoCoBench Score"},t=void 0,h={},a=[{value:"Definition",id:"definition",level:2},{value:"Formula (General Idea)",id:"formula-general-idea",level:2},{value:"Purpose",id:"purpose",level:2},{value:"Domains",id:"domains",level:2},{value:"Benchmarks",id:"benchmarks",level:2},{value:"Advantages",id:"advantages",level:2},{value:"Limitations",id:"limitations",level:2},{value:"Key References",id:"key-references",level:2}];function o(e){const i={a:"a",annotation:"annotation",code:"code",h2:"h2",hr:"hr",li:"li",math:"math",mfrac:"mfrac",mi:"mi",mn:"mn",mo:"mo",mrow:"mrow",msub:"msub",msubsup:"msubsup",ol:"ol",p:"p",semantics:"semantics",span:"span",strong:"strong",ul:"ul",...(0,c.R)(),...e.components};return(0,r.jsxs)(r.Fragment,{children:[(0,r.jsx)(i.h2,{id:"definition",children:"Definition"}),"\n",(0,r.jsxs)(i.p,{children:["The ",(0,r.jsx)(i.strong,{children:"LoCoBench Score (LCBS)"})," is a unified, aggregated metric introduced in the ",(0,r.jsx)(i.strong,{children:"LoCoBench"})," benchmark. It is specifically designed to evaluate the performance of long-context Large Language Models (LLMs) in complex, realistic software engineering scenarios."]}),"\n",(0,r.jsx)(i.p,{children:'The LCBS functions as a "weighted aggregate function that maps the 17-dimensional metric space to a scalar evaluation score". This provides a single, comprehensive measure of a model\'s capabilities across four key dimensions of software development.'}),"\n",(0,r.jsx)(i.hr,{}),"\n",(0,r.jsx)(i.h2,{id:"formula-general-idea",children:"Formula (General Idea)"}),"\n",(0,r.jsx)(i.p,{children:"The LoCoBench Score is calculated as a weighted linear combination of four dimension scores, which is then scaled to a final value on a 0-5 scale."}),"\n",(0,r.jsx)(i.p,{children:"The four evaluation dimensions and their respective weights are:"}),"\n",(0,r.jsxs)(i.ol,{children:["\n",(0,r.jsxs)(i.li,{children:[(0,r.jsx)(i.strong,{children:"Software Engineering Excellence (SE):"})," 40% weight"]}),"\n",(0,r.jsxs)(i.li,{children:[(0,r.jsx)(i.strong,{children:"Functional Correctness (FC):"})," 30% weight"]}),"\n",(0,r.jsxs)(i.li,{children:[(0,r.jsx)(i.strong,{children:"Code Quality Assessment (CQ):"})," 20% weight"]}),"\n",(0,r.jsxs)(i.li,{children:[(0,r.jsx)(i.strong,{children:"Long-Context Utilization (LCU):"})," 10% weight"]}),"\n"]}),"\n",(0,r.jsx)(i.p,{children:"The calculation follows a multi-step process:"}),"\n",(0,r.jsxs)(i.ol,{children:["\n",(0,r.jsxs)(i.li,{children:["\n",(0,r.jsxs)(i.p,{children:[(0,r.jsx)(i.strong,{children:"Metric Normalization:"})," First, each of the 17 individual metrics (e.g., ",(0,r.jsx)(i.code,{children:"ACS"}),", ",(0,r.jsx)(i.code,{children:"DTA"}),", ",(0,r.jsx)(i.code,{children:"UTP"}),", ",(0,r.jsx)(i.code,{children:"ICU"}),", etc.) is normalized to a value ",(0,r.jsx)(i.span,{className:"katex",children:(0,r.jsx)(i.math,{xmlns:"http://www.w3.org/1998/Math/MathML",children:(0,r.jsxs)(i.semantics,{children:[(0,r.jsxs)(i.mrow,{children:[(0,r.jsx)(i.mi,{mathvariant:"script",children:"N"}),(0,r.jsx)(i.mo,{stretchy:"false",children:"("}),(0,r.jsxs)(i.msub,{children:[(0,r.jsx)(i.mi,{children:"m"}),(0,r.jsx)(i.mi,{children:"i"})]}),(0,r.jsx)(i.mo,{stretchy:"false",children:")"})]}),(0,r.jsx)(i.annotation,{encoding:"application/x-tex",children:"\\mathcal{N}(m_i)"})]})})})," in the unit interval [0, 1] using min-max scaling.\r\n",(0,r.jsx)(i.span,{className:"katex",children:(0,r.jsx)(i.math,{xmlns:"http://www.w3.org/1998/Math/MathML",children:(0,r.jsxs)(i.semantics,{children:[(0,r.jsxs)(i.mrow,{children:[(0,r.jsx)(i.mi,{mathvariant:"script",children:"N"}),(0,r.jsx)(i.mo,{stretchy:"false",children:"("}),(0,r.jsxs)(i.msub,{children:[(0,r.jsx)(i.mi,{children:"m"}),(0,r.jsx)(i.mi,{children:"i"})]}),(0,r.jsx)(i.mo,{stretchy:"false",children:")"}),(0,r.jsx)(i.mo,{children:"="}),(0,r.jsxs)(i.mfrac,{children:[(0,r.jsxs)(i.mrow,{children:[(0,r.jsxs)(i.msub,{children:[(0,r.jsx)(i.mi,{children:"m"}),(0,r.jsx)(i.mi,{children:"i"})]}),(0,r.jsx)(i.mo,{children:"\u2212"}),(0,r.jsx)(i.mi,{children:"m"}),(0,r.jsx)(i.mi,{children:"i"}),(0,r.jsx)(i.mi,{children:"n"}),(0,r.jsx)(i.mo,{stretchy:"false",children:"("}),(0,r.jsxs)(i.msub,{children:[(0,r.jsx)(i.mi,{children:"m"}),(0,r.jsx)(i.mi,{children:"i"})]}),(0,r.jsx)(i.mo,{stretchy:"false",children:")"})]}),(0,r.jsxs)(i.mrow,{children:[(0,r.jsx)(i.mi,{children:"m"}),(0,r.jsx)(i.mi,{children:"a"}),(0,r.jsx)(i.mi,{children:"x"}),(0,r.jsx)(i.mo,{stretchy:"false",children:"("}),(0,r.jsxs)(i.msub,{children:[(0,r.jsx)(i.mi,{children:"m"}),(0,r.jsx)(i.mi,{children:"i"})]}),(0,r.jsx)(i.mo,{stretchy:"false",children:")"}),(0,r.jsx)(i.mo,{children:"\u2212"}),(0,r.jsx)(i.mi,{children:"m"}),(0,r.jsx)(i.mi,{children:"i"}),(0,r.jsx)(i.mi,{children:"n"}),(0,r.jsx)(i.mo,{stretchy:"false",children:"("}),(0,r.jsxs)(i.msub,{children:[(0,r.jsx)(i.mi,{children:"m"}),(0,r.jsx)(i.mi,{children:"i"})]}),(0,r.jsx)(i.mo,{stretchy:"false",children:")"})]})]})]}),(0,r.jsx)(i.annotation,{encoding:"application/x-tex",children:"\\mathcal{N}(m_{i})=\\frac{m_{i}-min(m_{i})}{max(m_{i})-min(m_{i})}"})]})})})]}),"\n"]}),"\n",(0,r.jsxs)(i.li,{children:["\n",(0,r.jsxs)(i.p,{children:[(0,r.jsx)(i.strong,{children:"Dimension Aggregation:"})," The score for each of the four dimensions (SE, FC, CQ, LCU) is computed as the arithmetic mean of its constituent normalized metrics. For example, the SE score, which is derived from 8 metrics, is calculated as:\r\n",(0,r.jsx)(i.span,{className:"katex",children:(0,r.jsx)(i.math,{xmlns:"http://www.w3.org/1998/Math/MathML",children:(0,r.jsxs)(i.semantics,{children:[(0,r.jsxs)(i.mrow,{children:[(0,r.jsx)(i.mi,{children:"S"}),(0,r.jsx)(i.mi,{children:"E"}),(0,r.jsx)(i.mo,{children:"="}),(0,r.jsxs)(i.mfrac,{children:[(0,r.jsx)(i.mn,{children:"1"}),(0,r.jsxs)(i.mrow,{children:[(0,r.jsx)(i.mi,{mathvariant:"normal",children:"\u2223"}),(0,r.jsxs)(i.msub,{children:[(0,r.jsx)(i.mi,{mathvariant:"script",children:"M"}),(0,r.jsxs)(i.mrow,{children:[(0,r.jsx)(i.mi,{children:"S"}),(0,r.jsx)(i.mi,{children:"E"})]})]}),(0,r.jsx)(i.mi,{mathvariant:"normal",children:"\u2223"})]})]}),(0,r.jsxs)(i.msub,{children:[(0,r.jsx)(i.mo,{children:"\u2211"}),(0,r.jsxs)(i.mrow,{children:[(0,r.jsx)(i.mi,{children:"m"}),(0,r.jsx)(i.mo,{children:"\u2208"}),(0,r.jsxs)(i.msub,{children:[(0,r.jsx)(i.mi,{mathvariant:"script",children:"M"}),(0,r.jsxs)(i.mrow,{children:[(0,r.jsx)(i.mi,{children:"S"}),(0,r.jsx)(i.mi,{children:"E"})]})]})]})]}),(0,r.jsx)(i.mi,{mathvariant:"script",children:"N"}),(0,r.jsx)(i.mo,{stretchy:"false",children:"("}),(0,r.jsx)(i.mi,{children:"m"}),(0,r.jsx)(i.mo,{stretchy:"false",children:")"}),(0,r.jsx)(i.mo,{children:"="}),(0,r.jsxs)(i.mfrac,{children:[(0,r.jsx)(i.mn,{children:"1"}),(0,r.jsx)(i.mn,{children:"8"})]}),(0,r.jsxs)(i.msubsup,{children:[(0,r.jsx)(i.mo,{children:"\u2211"}),(0,r.jsxs)(i.mrow,{children:[(0,r.jsx)(i.mi,{children:"i"}),(0,r.jsx)(i.mo,{children:"="}),(0,r.jsx)(i.mn,{children:"1"})]}),(0,r.jsx)(i.mn,{children:"8"})]}),(0,r.jsx)(i.mi,{mathvariant:"script",children:"N"}),(0,r.jsx)(i.mo,{stretchy:"false",children:"("}),(0,r.jsxs)(i.msubsup,{children:[(0,r.jsx)(i.mi,{children:"m"}),(0,r.jsx)(i.mi,{children:"i"}),(0,r.jsxs)(i.mrow,{children:[(0,r.jsx)(i.mi,{children:"S"}),(0,r.jsx)(i.mi,{children:"E"})]})]}),(0,r.jsx)(i.mo,{stretchy:"false",children:")"})]}),(0,r.jsx)(i.annotation,{encoding:"application/x-tex",children:"SE = \\frac{1}{|\\mathcal{M}_{SE}|}\\sum_{m \\in \\mathcal{M}_{SE}} \\mathcal{N}(m) = \\frac{1}{8}\\sum_{i=1}^{8} \\mathcal{N}(m_{i}^{SE})"})]})})})]}),"\n"]}),"\n",(0,r.jsxs)(i.li,{children:["\n",(0,r.jsxs)(i.p,{children:[(0,r.jsx)(i.strong,{children:"Final Score:"})," The final LCBS is the weighted sum of the four dimension scores, scaled by 5 to produce the final 0-5 point score.\r\n",(0,r.jsx)(i.span,{className:"katex",children:(0,r.jsx)(i.math,{xmlns:"http://www.w3.org/1998/Math/MathML",children:(0,r.jsxs)(i.semantics,{children:[(0,r.jsxs)(i.mrow,{children:[(0,r.jsx)(i.mi,{children:"L"}),(0,r.jsx)(i.mi,{children:"C"}),(0,r.jsx)(i.mi,{children:"B"}),(0,r.jsx)(i.mi,{children:"S"}),(0,r.jsx)(i.mo,{children:"="}),(0,r.jsx)(i.mn,{children:"5"}),(0,r.jsx)(i.mo,{children:"\u22c5"}),(0,r.jsx)(i.mo,{stretchy:"false",children:"("}),(0,r.jsxs)(i.msub,{children:[(0,r.jsx)(i.mi,{children:"w"}),(0,r.jsxs)(i.mrow,{children:[(0,r.jsx)(i.mi,{children:"S"}),(0,r.jsx)(i.mi,{children:"E"})]})]}),(0,r.jsx)(i.mo,{children:"\u22c5"}),(0,r.jsx)(i.mi,{children:"S"}),(0,r.jsx)(i.mi,{children:"E"}),(0,r.jsx)(i.mo,{children:"+"}),(0,r.jsxs)(i.msub,{children:[(0,r.jsx)(i.mi,{children:"w"}),(0,r.jsxs)(i.mrow,{children:[(0,r.jsx)(i.mi,{children:"F"}),(0,r.jsx)(i.mi,{children:"C"})]})]}),(0,r.jsx)(i.mo,{children:"\u22c5"}),(0,r.jsx)(i.mi,{children:"F"}),(0,r.jsx)(i.mi,{children:"C"}),(0,r.jsx)(i.mo,{children:"+"}),(0,r.jsxs)(i.msub,{children:[(0,r.jsx)(i.mi,{children:"w"}),(0,r.jsxs)(i.mrow,{children:[(0,r.jsx)(i.mi,{children:"C"}),(0,r.jsx)(i.mi,{children:"Q"})]})]}),(0,r.jsx)(i.mo,{children:"\u22c5"}),(0,r.jsx)(i.mi,{children:"C"}),(0,r.jsx)(i.mi,{children:"Q"}),(0,r.jsx)(i.mo,{children:"+"}),(0,r.jsxs)(i.msub,{children:[(0,r.jsx)(i.mi,{children:"w"}),(0,r.jsxs)(i.mrow,{children:[(0,r.jsx)(i.mi,{children:"L"}),(0,r.jsx)(i.mi,{children:"C"}),(0,r.jsx)(i.mi,{children:"U"})]})]}),(0,r.jsx)(i.mo,{children:"\u22c5"}),(0,r.jsx)(i.mi,{children:"L"}),(0,r.jsx)(i.mi,{children:"C"}),(0,r.jsx)(i.mi,{children:"U"}),(0,r.jsx)(i.mo,{stretchy:"false",children:")"})]}),(0,r.jsx)(i.annotation,{encoding:"application/x-tex",children:"LCBS = 5 \\cdot (w_{SE} \\cdot SE + w_{FC} \\cdot FC + w_{CQ} \\cdot CQ + w_{LCU} \\cdot LCU)"})]})})}),"\r\nSubstituting the defined weights gives the final formula[cite: 3537]:\r\n",(0,r.jsx)(i.span,{className:"katex",children:(0,r.jsx)(i.math,{xmlns:"http://www.w3.org/1998/Math/MathML",children:(0,r.jsxs)(i.semantics,{children:[(0,r.jsxs)(i.mrow,{children:[(0,r.jsx)(i.mi,{children:"L"}),(0,r.jsx)(i.mi,{children:"C"}),(0,r.jsx)(i.mi,{children:"B"}),(0,r.jsx)(i.mi,{children:"S"}),(0,r.jsx)(i.mo,{children:"="}),(0,r.jsx)(i.mn,{children:"5"}),(0,r.jsx)(i.mo,{children:"\u22c5"}),(0,r.jsx)(i.mo,{stretchy:"false",children:"("}),(0,r.jsx)(i.mn,{children:"0.4"}),(0,r.jsx)(i.mo,{children:"\u22c5"}),(0,r.jsx)(i.mi,{children:"S"}),(0,r.jsx)(i.mi,{children:"E"}),(0,r.jsx)(i.mo,{children:"+"}),(0,r.jsx)(i.mn,{children:"0.3"}),(0,r.jsx)(i.mo,{children:"\u22c5"}),(0,r.jsx)(i.mi,{children:"F"}),(0,r.jsx)(i.mi,{children:"C"}),(0,r.jsx)(i.mo,{children:"+"}),(0,r.jsx)(i.mn,{children:"0.2"}),(0,r.jsx)(i.mo,{children:"\u22c5"}),(0,r.jsx)(i.mi,{children:"C"}),(0,r.jsx)(i.mi,{children:"Q"}),(0,r.jsx)(i.mo,{children:"+"}),(0,r.jsx)(i.mn,{children:"0.1"}),(0,r.jsx)(i.mo,{children:"\u22c5"}),(0,r.jsx)(i.mi,{children:"L"}),(0,r.jsx)(i.mi,{children:"C"}),(0,r.jsx)(i.mi,{children:"U"}),(0,r.jsx)(i.mo,{stretchy:"false",children:")"})]}),(0,r.jsx)(i.annotation,{encoding:"application/x-tex",children:"LCBS = 5 \\cdot (0.4 \\cdot SE + 0.3 \\cdot FC + 0.2 \\cdot CQ + 0.1 \\cdot LCU)"})]})})})]}),"\n"]}),"\n"]}),"\n",(0,r.jsx)(i.hr,{}),"\n",(0,r.jsx)(i.h2,{id:"purpose",children:"Purpose"}),"\n",(0,r.jsx)(i.p,{children:"The primary purpose of the LCBS is to provide a single, unified scalar score that summarizes a model's performance across 17 different metrics. This allows for a holistic and comprehensive comparison of models on complex, long-context software engineering tasks."}),"\n",(0,r.jsx)(i.hr,{}),"\n",(0,r.jsx)(i.h2,{id:"domains",children:"Domains"}),"\n",(0,r.jsxs)(i.ul,{children:["\n",(0,r.jsx)(i.li,{children:"Long-Context Evaluation"}),"\n",(0,r.jsx)(i.li,{children:"Software Engineering"}),"\n"]}),"\n",(0,r.jsx)(i.hr,{}),"\n",(0,r.jsx)(i.h2,{id:"benchmarks",children:"Benchmarks"}),"\n",(0,r.jsxs)(i.ul,{children:["\n",(0,r.jsx)(i.li,{children:(0,r.jsx)(i.strong,{children:"LoCoBench"})}),"\n"]}),"\n",(0,r.jsx)(i.hr,{}),"\n",(0,r.jsx)(i.h2,{id:"advantages",children:"Advantages"}),"\n",(0,r.jsxs)(i.ul,{children:["\n",(0,r.jsxs)(i.li,{children:[(0,r.jsx)(i.strong,{children:"Comprehensive:"})," It aggregates 17 distinct metrics across 4 fundamental dimensions of software development: Software Engineering Excellence, Functional Correctness, Code Quality, and Long-Context Utilization."]}),"\n",(0,r.jsxs)(i.li,{children:[(0,r.jsx)(i.strong,{children:"Unified Score:"})," It condenses a complex, 17-dimensional evaluation into a single, easy-to-compare scalar score."]}),"\n",(0,r.jsxs)(i.li,{children:[(0,r.jsx)(i.strong,{children:"Weighted:"}),' The weights (40%/30%/20%/10%) are "empirically determined to reflect the relative importance of each dimension", with Software Engineering Excellence receiving the highest priority.']}),"\n"]}),"\n",(0,r.jsx)(i.hr,{}),"\n",(0,r.jsx)(i.h2,{id:"limitations",children:"Limitations"}),"\n",(0,r.jsxs)(i.ul,{children:["\n",(0,r.jsxs)(i.li,{children:[(0,r.jsx)(i.strong,{children:"Aggregation Obscurity:"}),' As an aggregated score, it can hide significant performance variations in specific capabilities. The paper\'s analysis notes that "Models that appear similar in overall performance may exhibit substantial differences in specific capabilities".']}),"\n",(0,r.jsxs)(i.li,{children:[(0,r.jsx)(i.strong,{children:"Weight Subjectivity:"}),' The dimension weights are "empirically determined", meaning they are tied to the benchmark authors\' assessment of importance and could be debated.']}),"\n",(0,r.jsxs)(i.li,{children:[(0,r.jsx)(i.strong,{children:"Hides Trade-offs:"}),' A high overall LCBS does not guarantee top performance in all areas. The paper\'s results show that the model with the best overall LCBS was not the top performer in the specialized "Long-Context Utilization" dimension.']}),"\n"]}),"\n",(0,r.jsx)(i.hr,{}),"\n",(0,r.jsx)(i.h2,{id:"key-references",children:"Key References"}),"\n",(0,r.jsxs)(i.ul,{children:["\n",(0,r.jsxs)(i.li,{children:["Qiu, J., Liu, Z., Liu, Z., Murthy, R., Zhang, J., Chen, H., Wang, S., Zhu, M., Yang, L., Tan, J., Cen, Z., Qian, C., Heinecke, S., Yao, W., Savarese, S., Xiong, C., & Wang, H. (2025). LoCoBench: A benchmark for long-context large language models in complex software engineering (arXiv:2509.09614). arXiv. ",(0,r.jsx)(i.a,{href:"https://doi.org/10.48550/arXiv.2509.09614",children:"https://doi.org/10.48550/arXiv.2509.09614"})]}),"\n",(0,r.jsx)(i.li,{children:"(Excel Data: Paper 54)"}),"\n"]})]})}function d(e={}){const{wrapper:i}={...(0,c.R)(),...e.components};return i?(0,r.jsx)(i,{...e,children:(0,r.jsx)(o,{...e})}):o(e)}},8453:(e,i,n)=>{n.d(i,{R:()=>l,x:()=>t});var s=n(6540);const r={},c=s.createContext(r);function l(e){const i=s.useContext(c);return s.useMemo(function(){return"function"==typeof e?e(i):{...i,...e}},[i,e])}function t(e){let i;return i=e.disableParentContext?"function"==typeof e.components?e.components(r):e.components||r:l(e.components),s.createElement(c.Provider,{value:i},e.children)}}}]);