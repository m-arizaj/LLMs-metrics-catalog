"use strict";(self.webpackChunkll_ms_metrics_catalog=self.webpackChunkll_ms_metrics_catalog||[]).push([[6600],{8453:(e,i,n)=>{n.d(i,{R:()=>a,x:()=>l});var t=n(6540);const s={},r=t.createContext(s);function a(e){const i=t.useContext(r);return t.useMemo(function(){return"function"==typeof e?e(i):{...i,...e}},[i,e])}function l(e){let i;return i=e.disableParentContext?"function"==typeof e.components?e.components(s):e.components||s:a(e.components),t.createElement(r.Provider,{value:i},e.children)}},9160:(e,i,n)=>{n.r(i),n.d(i,{assets:()=>c,contentTitle:()=>l,default:()=>h,frontMatter:()=>a,metadata:()=>t,toc:()=>o});const t=JSON.parse('{"id":"metrics/semantic/similarity","title":"Similarity Metrics","description":"Introduction","source":"@site/docs/metrics/semantic/similarity.md","sourceDirName":"metrics/semantic","slug":"/metrics/semantic/similarity","permalink":"/LLMs-metrics-catalog/metrics/semantic/similarity","draft":false,"unlisted":false,"tags":[],"version":"current","frontMatter":{"id":"similarity","title":"Similarity Metrics","sidebar_label":"Similarity"},"sidebar":"docsSidebar","previous":{"title":"Sentiment Polarity","permalink":"/LLMs-metrics-catalog/metrics/semantic/sentiment-polarity-shift"},"next":{"title":"Surface-Form Constraints","permalink":"/LLMs-metrics-catalog/metrics/semantic/surface-form-constraints"}}');var s=n(4848),r=n(8453);const a={id:"similarity",title:"Similarity Metrics",sidebar_label:"Similarity"},l=void 0,c={},o=[{value:"Introduction",id:"introduction",level:2},{value:"1. Levenshtein Edit Similarity",id:"1-levenshtein-edit-similarity",level:2},{value:"Definition",id:"definition",level:3},{value:"Purpose",id:"purpose",level:3},{value:"Applications",id:"applications",level:3},{value:"Benchmarks",id:"benchmarks",level:3},{value:"2. Sentence Cosine Similarity",id:"2-sentence-cosine-similarity",level:2},{value:"Definition",id:"definition-1",level:3},{value:"Purpose",id:"purpose-1",level:3},{value:"Applications",id:"applications-1",level:3},{value:"Benchmarks",id:"benchmarks-1",level:3},{value:"3. Visualization Similarity Scores",id:"3-visualization-similarity-scores",level:2},{value:"Definition",id:"definition-2",level:3},{value:"Purpose",id:"purpose-2",level:3},{value:"Applications",id:"applications-2",level:3},{value:"4. Comparative Summary",id:"4-comparative-summary",level:2},{value:"References",id:"references",level:2}];function d(e){const i={a:"a",annotation:"annotation",code:"code",em:"em",h2:"h2",h3:"h3",li:"li",math:"math",mfrac:"mfrac",mi:"mi",mn:"mn",mo:"mo",mrow:"mrow",msub:"msub",mtext:"mtext",p:"p",semantics:"semantics",span:"span",strong:"strong",table:"table",tbody:"tbody",td:"td",th:"th",thead:"thead",tr:"tr",ul:"ul",...(0,r.R)(),...e.components};return(0,s.jsxs)(s.Fragment,{children:[(0,s.jsx)(i.h2,{id:"introduction",children:"Introduction"}),"\n",(0,s.jsxs)(i.p,{children:['In code generation and software engineering, "Similarity" is not a single metric but a broad category of evaluation techniques. Its purpose is to quantify how "close" a generated output is to a reference, especially when a simple ',(0,s.jsx)(i.strong,{children:"Exact Match"})," is too strict and fails to capture partially correct or semantically equivalent solutions."]}),"\n",(0,s.jsx)(i.p,{children:"Different tasks require different notions of similarity. For example:"}),"\n",(0,s.jsxs)(i.ul,{children:["\n",(0,s.jsxs)(i.li,{children:["In ",(0,s.jsx)(i.strong,{children:"code completion"}),", a suggestion should be ",(0,s.jsx)(i.em,{children:"syntactically"})," close to the desired code, minimizing the typing or editing effort required by the developer."]}),"\n",(0,s.jsxs)(i.li,{children:["In ",(0,s.jsx)(i.strong,{children:"docstring generation"})," or robustness checks, the output should be ",(0,s.jsx)(i.em,{children:"semantically"})," close, even if the exact wording differs."]}),"\n",(0,s.jsxs)(i.li,{children:["In ",(0,s.jsx)(i.strong,{children:"data visualization"}),", the generated ",(0,s.jsx)(i.em,{children:"image"})," must be visually similar to the target, a property the code itself cannot guarantee."]}),"\n"]}),"\n",(0,s.jsx)(i.p,{children:"This framework covers several key variants of similarity metrics used in evaluation."}),"\n",(0,s.jsx)(i.h2,{id:"1-levenshtein-edit-similarity",children:"1. Levenshtein Edit Similarity"}),"\n",(0,s.jsx)(i.h3,{id:"definition",children:"Definition"}),"\n",(0,s.jsxs)(i.p,{children:["Also known as ",(0,s.jsx)(i.strong,{children:"Edit Distance"}),', this metric measures the "edit effort" between two strings. It is defined as the minimum number of single-character edits (insertions, deletions, or substitutions) required to change the candidate string into the reference string. A lower distance means higher similarity.']}),"\n",(0,s.jsx)(i.span,{className:"katex",children:(0,s.jsx)(i.math,{xmlns:"http://www.w3.org/1998/Math/MathML",display:"block",children:(0,s.jsxs)(i.semantics,{children:[(0,s.jsxs)(i.mrow,{children:[(0,s.jsx)(i.mtext,{children:"Similarity"}),(0,s.jsx)(i.mo,{children:"="}),(0,s.jsx)(i.mn,{children:"1"}),(0,s.jsx)(i.mo,{children:"\u2212"}),(0,s.jsxs)(i.mfrac,{children:[(0,s.jsxs)(i.mrow,{children:[(0,s.jsx)(i.mtext,{children:"LevenshteinDistance"}),(0,s.jsx)(i.mo,{stretchy:"false",children:"("}),(0,s.jsxs)(i.msub,{children:[(0,s.jsx)(i.mtext,{children:"str"}),(0,s.jsx)(i.mn,{children:"1"})]}),(0,s.jsx)(i.mo,{separator:"true",children:","}),(0,s.jsxs)(i.msub,{children:[(0,s.jsx)(i.mtext,{children:"str"}),(0,s.jsx)(i.mn,{children:"2"})]}),(0,s.jsx)(i.mo,{stretchy:"false",children:")"})]}),(0,s.jsxs)(i.mrow,{children:[(0,s.jsx)(i.mi,{children:"max"}),(0,s.jsx)(i.mo,{children:"\u2061"}),(0,s.jsx)(i.mo,{stretchy:"false",children:"("}),(0,s.jsx)(i.mtext,{children:"len"}),(0,s.jsx)(i.mo,{stretchy:"false",children:"("}),(0,s.jsxs)(i.msub,{children:[(0,s.jsx)(i.mtext,{children:"str"}),(0,s.jsx)(i.mn,{children:"1"})]}),(0,s.jsx)(i.mo,{stretchy:"false",children:")"}),(0,s.jsx)(i.mo,{separator:"true",children:","}),(0,s.jsx)(i.mtext,{children:"len"}),(0,s.jsx)(i.mo,{stretchy:"false",children:"("}),(0,s.jsxs)(i.msub,{children:[(0,s.jsx)(i.mtext,{children:"str"}),(0,s.jsx)(i.mn,{children:"2"})]}),(0,s.jsx)(i.mo,{stretchy:"false",children:")"}),(0,s.jsx)(i.mo,{stretchy:"false",children:")"})]})]})]}),(0,s.jsx)(i.annotation,{encoding:"application/x-tex",children:"\\text{Similarity} = 1 - \\frac{\\text{LevenshteinDistance}(\\text{str}_1, \\text{str}_2)}{\\max(\\text{len}(\\text{str}_1), \\text{len}(\\text{str}_2))}"})]})})}),"\n",(0,s.jsx)(i.p,{children:(0,s.jsx)(i.em,{children:"(Note: The exact formula for similarity score based on edit distance can vary, but the core is the distance calculation.)"})}),"\n",(0,s.jsx)(i.h3,{id:"purpose",children:"Purpose"}),"\n",(0,s.jsx)(i.p,{children:'In code evaluation, it is used as a "critical evaluation metric"  because it directly measures how much effort a developer would need to manually correct a model\'s generated code to match the ground truth.'}),"\n",(0,s.jsx)(i.h3,{id:"applications",children:"Applications"}),"\n",(0,s.jsxs)(i.ul,{children:["\n",(0,s.jsxs)(i.li,{children:[(0,s.jsx)(i.strong,{children:"Code Completion:"})," Evaluating line-level  or token-level code suggestions."]}),"\n",(0,s.jsxs)(i.li,{children:[(0,s.jsx)(i.strong,{children:"Structural Distance:"})," Assessing syntactic closeness of code snippets."]}),"\n"]}),"\n",(0,s.jsx)(i.h3,{id:"benchmarks",children:"Benchmarks"}),"\n",(0,s.jsxs)(i.ul,{children:["\n",(0,s.jsx)(i.li,{children:"PY150"}),"\n",(0,s.jsx)(i.li,{children:"GitHub Java Corpus"}),"\n"]}),"\n",(0,s.jsx)(i.h2,{id:"2-sentence-cosine-similarity",children:"2. Sentence Cosine Similarity"}),"\n",(0,s.jsx)(i.h3,{id:"definition-1",children:"Definition"}),"\n",(0,s.jsxs)(i.p,{children:["This is a ",(0,s.jsx)(i.strong,{children:"semantic similarity"}),' metric that measures the cosine of the angle between two non-zero vectors in a multi-dimensional space. In NLP and code analysis, these vectors are typically "sentence embeddings" of docstrings or code, generated by models like Sentence Transformers (SBERT).\r\nA score of ',(0,s.jsx)(i.span,{className:"katex",children:(0,s.jsx)(i.math,{xmlns:"http://www.w3.org/1998/Math/MathML",children:(0,s.jsxs)(i.semantics,{children:[(0,s.jsx)(i.mrow,{children:(0,s.jsx)(i.mn,{children:"1.0"})}),(0,s.jsx)(i.annotation,{encoding:"application/x-tex",children:"1.0"})]})})})," means the vectors point in the same direction (semantically identical), while ",(0,s.jsx)(i.span,{className:"katex",children:(0,s.jsx)(i.math,{xmlns:"http://www.w3.org/1998/Math/MathML",children:(0,s.jsxs)(i.semantics,{children:[(0,s.jsx)(i.mrow,{children:(0,s.jsx)(i.mn,{children:"0.0"})}),(0,s.jsx)(i.annotation,{encoding:"application/x-tex",children:"0.0"})]})})})," means they are orthogonal (unrelated)."]}),"\n",(0,s.jsx)(i.h3,{id:"purpose-1",children:"Purpose"}),"\n",(0,s.jsxs)(i.p,{children:["To verify that a generated piece of text (like a docstring) or a code element (like a function name) preserves its original ",(0,s.jsx)(i.em,{children:"meaning"}),", even if the surface-level text (words, syntax) is different."]}),"\n",(0,s.jsx)(i.h3,{id:"applications-1",children:"Applications"}),"\n",(0,s.jsxs)(i.ul,{children:["\n",(0,s.jsxs)(i.li,{children:[(0,s.jsx)(i.strong,{children:"Semantic Similarity:"}),' Used in robustness benchmarks (like ReCode) to confirm that a "perturbed" docstring or function name is still semantically equivalent to the original.']}),"\n",(0,s.jsxs)(i.li,{children:[(0,s.jsx)(i.strong,{children:"Code Generation Evaluation:"})," Assessing the quality of generated docstrings or comments."]}),"\n"]}),"\n",(0,s.jsx)(i.h3,{id:"benchmarks-1",children:"Benchmarks"}),"\n",(0,s.jsxs)(i.ul,{children:["\n",(0,s.jsx)(i.li,{children:"HumanEval (in ReCode)"}),"\n",(0,s.jsx)(i.li,{children:"MBPP (in ReCode)"}),"\n"]}),"\n",(0,s.jsx)(i.h2,{id:"3-visualization-similarity-scores",children:"3. Visualization Similarity Scores"}),"\n",(0,s.jsx)(i.h3,{id:"definition-2",children:"Definition"}),"\n",(0,s.jsxs)(i.p,{children:["This metric evaluates the ",(0,s.jsx)(i.strong,{children:"output quality"})," of data science code by comparing the ",(0,s.jsx)(i.em,{children:"rendered image"})," of a generated plot against an expected reference plot. The specific calculation method is often based on image processing techniques (e.g., Structural Similarity Index - SSIM, or Mean Squared Error - MSE), which produce a score quantifying the visual likeness."]}),"\n",(0,s.jsx)(i.h3,{id:"purpose-2",children:"Purpose"}),"\n",(0,s.jsx)(i.p,{children:"To evaluate the correctness of visualization tasks, where the code itself is a means to an end. Different code can produce identical plots, and text-based metrics (like BLEU or Edit Similarity) on the code are poor indicators of the final visual correctness."}),"\n",(0,s.jsx)(i.h3,{id:"applications-2",children:"Applications"}),"\n",(0,s.jsxs)(i.ul,{children:["\n",(0,s.jsxs)(i.li,{children:[(0,s.jsx)(i.strong,{children:"Data Science Code Generation:"})," Specifically for tasks requiring ",(0,s.jsx)(i.code,{children:"matplotlib"}),", ",(0,s.jsx)(i.code,{children:"seaborn"}),", or ",(0,s.jsx)(i.code,{children:"plotly"})," outputs."]}),"\n"]}),"\n",(0,s.jsx)(i.h2,{id:"4-comparative-summary",children:"4. Comparative Summary"}),"\n",(0,s.jsxs)(i.table,{children:[(0,s.jsx)(i.thead,{children:(0,s.jsxs)(i.tr,{children:[(0,s.jsx)(i.th,{children:"Metric"}),(0,s.jsx)(i.th,{children:"Based on"}),(0,s.jsx)(i.th,{children:"Measures"}),(0,s.jsx)(i.th,{children:"Typical Domain"})]})}),(0,s.jsxs)(i.tbody,{children:[(0,s.jsxs)(i.tr,{children:[(0,s.jsx)(i.td,{children:(0,s.jsx)(i.strong,{children:"Levenshtein Edit Similarity"})}),(0,s.jsx)(i.td,{children:"Character Edits"}),(0,s.jsx)(i.td,{children:"Syntactic closeness / Edit effort"}),(0,s.jsx)(i.td,{children:"Code Completion"})]}),(0,s.jsxs)(i.tr,{children:[(0,s.jsx)(i.td,{children:(0,s.jsx)(i.strong,{children:"Sentence Cosine Similarity"})}),(0,s.jsx)(i.td,{children:"Vector Embeddings"}),(0,s.jsx)(i.td,{children:"Semantic meaning"}),(0,s.jsx)(i.td,{children:"Code/Docstring Robustness"})]}),(0,s.jsxs)(i.tr,{children:[(0,s.jsx)(i.td,{children:(0,s.jsx)(i.strong,{children:"Visualization Similarity"})}),(0,s.jsx)(i.td,{children:"Image Comparison"}),(0,s.jsx)(i.td,{children:"Visual output quality"}),(0,s.jsx)(i.td,{children:"Data Science Visualization"})]})]})]}),"\n",(0,s.jsx)(i.h2,{id:"references",children:"References"}),"\n",(0,s.jsxs)(i.ul,{children:["\n",(0,s.jsxs)(i.li,{children:["Lu, S., Guo, D., Ren, S., Huang, J., et al. (2021). ",(0,s.jsx)(i.em,{children:"CodeXGLUE: A Machine Learning Benchmark Dataset for Code Understanding and Generation"}),".\r\n",(0,s.jsx)(i.a,{href:"https://doi.org/10.48550/arXiv.2102.04664",children:"https://doi.org/10.48550/arXiv.2102.04664"})]}),"\n",(0,s.jsxs)(i.li,{children:["Li, Z., Qian, H., Yang, C., Wang, Z., et al. (2022). ",(0,s.jsx)(i.em,{children:"ReCode: Robustness Evaluation of Code Generation Models"}),". ",(0,s.jsx)(i.a,{href:"https://doi.org/10.48550/arXiv.2212.10264",children:"https://doi.org/10.48550/arXiv.2212.10264"})]}),"\n",(0,s.jsxs)(i.li,{children:["Nascimento, N., Guimaraes, E., Chintakunta, S., & Boominathan, A. (2024). ",(0,s.jsx)(i.em,{children:"LLM4DS: Evaluating Large Language Models for Data Science Code Generation"}),". ",(0,s.jsx)(i.a,{href:"https://doi.org/10.48550/arXiv.2411.11908",children:"https://doi.org/10.48550/arXiv.2411.11908"})]}),"\n"]})]})}function h(e={}){const{wrapper:i}={...(0,r.R)(),...e.components};return i?(0,s.jsx)(i,{...e,children:(0,s.jsx)(d,{...e})}):d(e)}}}]);