"use strict";(self.webpackChunkll_ms_metrics_catalog=self.webpackChunkll_ms_metrics_catalog||[]).push([[6411],{6070:(i,e,n)=>{n.d(e,{r:()=>a});var t=n(6540),r=n(4848);const s={1:{id:"1",url:"https://doi.org/10.1109/SWC62898.2024.00231"},2:{id:"2",url:"https://doi.org/10.48550/arXiv.2404.09135"},3:{id:"3",url:"https://elib.dlr.de/217570/1/Bektas_Ali_MA.pdf"},4:{id:"4",url:"https://doi.org/10.48550/arXiv.2211.09110"},5:{id:"5",url:"https://doi.org/10.48550/arXiv.2310.19736"},6:{id:"6",url:"https://doi.org/10.48550/arXiv.2308.10620"},7:{id:"7",url:"https://doi.org/10.48550/arXiv.2505.08903"},8:{id:"8",url:"https://doi.org/10.48550/arXiv.2311.07397"},9:{id:"9",url:"https://doi.org/10.48550/arXiv.2307.03109"},10:{id:"10",url:"https://doi.org/10.48550/arXiv.2408.16498"},11:{id:"11",url:"https://doi.org/10.48550/arXiv.2505.20854"},12:{id:"12",url:"https://doi.org/10.48550/arXiv.2304.14317"},13:{id:"13",url:"https://doi.org/10.48550/arXiv.2403.08604"},14:{id:"14",url:"https://doi.org/10.48550/arXiv.2310.06770"},15:{id:"15",url:"https://doi.org/10.48550/arXiv.2206.04615"},16:{id:"16",url:"https://doi.org/10.1162/coli_a_00524"},17:{id:"17",url:"https://doi.org/10.56038/oprd.v4i1.444"},18:{id:"18",url:"https://doi.org/10.56155/978-81-955020-9-7-24"},19:{id:"19",url:"https://doi.org/10.48550/arXiv.2406.12655"},20:{id:"20",url:"https://doi.org/10.48550/arXiv.2305.01210"},21:{id:"21",url:"https://doi.org/10.4218/etrij.2023-0357"},22:{id:"22",url:"https://doi.org/10.48550/arXiv.2401.06401"},23:{id:"23",url:"https://doi.org/10.48550/arXiv.2212.10264"},24:{id:"24",url:"https://doi.org/10.48550/arXiv.2302.05527"},25:{id:"25",url:"https://doi.org/10.1016/j.jss.2023.111741"},26:{id:"26",url:"https://doi.org/10.48550/arXiv.2406.06902"},27:{id:"27",url:"https://doi.org/10.18653/v1/2024.findings-emnlp.303"},28:{id:"28",url:"https://doi.org/10.1007/s42979-025-04241-5"},29:{id:"29",url:"https://doi.org/10.1007/s10009-025-00798-x"},30:{id:"30",url:"https://doi.org/10.1007/s10710-024-09494-2"},31:{id:"31",url:"https://doi.org/10.48550/arXiv.2107.03374"},32:{id:"32",url:"https://doi.org/10.48550/arXiv.2102.04664"},33:{id:"33",url:"https://doi.org/10.48550/arXiv.2410.12381"},34:{id:"34",url:"https://doi.org/10.48550/arXiv.2108.07732"},35:{id:"35",url:"https://doi.org/10.48550/arXiv.2208.08227"},36:{id:"36",url:"https://doi.org/10.48550/arXiv.2404.00599"},37:{id:"37",url:"https://doi.org/10.48550/arXiv.2301.09043"},38:{id:"38",url:"https://doi.org/10.1145/3650105.3652295"},39:{id:"39",url:"https://doi.org/10.3390/digital4010005"},40:{id:"40",url:"https://doi.org/10.18653/v1/2024.emnlp-main.1118"},41:{id:"41",url:"https://doi.org/10.48550/arXiv.2408.06450"},42:{id:"42",url:"https://doi.org/10.48550/arXiv.2411.11908"},43:{id:"43",url:"https://doi.org/10.18653/v1/2021.emnlp-main.685"},44:{id:"44",url:"https://doi.org/10.48550/arXiv.2207.11280"},45:{id:"45",url:"https://doi.org/10.48550/arXiv.2301.03988"},46:{id:"46",url:"https://doi.org/10.48550/arXiv.2303.17568"},47:{id:"47",url:"https://doi.org/10.48550/arXiv.2206.08474"},48:{id:"48",url:"https://doi.org/10.1007/s41019-025-00296-9"},49:{id:"49",url:"https://doi.org/10.1007/s11704-024-40231-1"},50:{id:"50",url:"https://doi.org/10.1007/s11432-023-4127-5"},51:{id:"51",url:"https://doi.org/10.1007/s44443-025-00074-7"},52:{id:"52",url:"https://doi.org/10.1007/s10515-024-00451-y"},53:{id:"53",url:"https://doi.org/10.1007/s10462-024-10888-y"},54:{id:"54",url:"https://doi.org/10.48550/arXiv.2509.09614"},55:{id:"55",url:"https://doi.org/10.48550/arXiv.2506.10833"},56:{id:"56",url:"https://doi.org/10.1007/s43681-025-00721-9"},57:{id:"57",url:"https://doi.org/10.1109/ACCESS.2024.3482107"},58:{id:"58",url:"https://doi.org/10.1109/ACCESS.2024.3403858"},59:{id:"59",url:"https://doi.org/10.1109/ACCESS.2024.3484947"},60:{id:"60",url:"https://doi.org/10.1109/ACCESS.2025.3553870"},61:{id:"61",url:"https://doi.org/10.1109/ACCESS.2025.3601206"},62:{id:"62",url:"https://doi.org/10.1016/j.csi.2024.103942"},63:{id:"63",url:"https://doi.org/10.1145/3597503.3639219"},64:{id:"64",url:"https://doi.org/10.1109/TSE.2023.3334955"},65:{id:"65",url:"https://doi.org/10.1007/s10664-025-10687-1"},66:{id:"66",url:"https://doi.org/10.48550/arXiv.2506.01793"},67:{id:"67",url:"https://doi.org/10.48550/arXiv.2306.04675"},68:{id:"68",url:"https://doi.org/10.48550/arXiv.2509.12395"}};function a({ids:i}){return(0,r.jsxs)("p",{children:[i.map((e,n)=>{const a=s[e];return a?(0,r.jsxs)(t.Fragment,{children:[(0,r.jsx)("a",{href:a.url,target:"_blank",rel:"noreferrer",children:a.id}),n<i.length-1?", ":null]},e):null}),"\xa0\xa0\xa0\xa0"]})}},6610:(i,e,n)=>{n.r(e),n.d(e,{assets:()=>d,contentTitle:()=>o,default:()=>u,frontMatter:()=>l,metadata:()=>t,toc:()=>c});const t=JSON.parse('{"id":"metrics/semantic/hallucination","title":"Hallucination","description":"Introduction","source":"@site/docs/metrics/semantic/hallucination.md","sourceDirName":"metrics/semantic","slug":"/metrics/semantic/hallucination","permalink":"/LLMs-metrics-catalog/metrics/semantic/hallucination","draft":false,"unlisted":false,"tags":[],"version":"current","frontMatter":{"id":"hallucination","title":"Hallucination","sidebar_label":"Hallucination"},"sidebar":"docsSidebar","previous":{"title":"Reward Score","permalink":"/LLMs-metrics-catalog/metrics/ranking/reward-score"},"next":{"title":"Distinguishability (d)","permalink":"/LLMs-metrics-catalog/metrics/semantic/distinguishability"}}');var r=n(4848),s=n(8453),a=n(6070);const l={id:"hallucination",title:"Hallucination",sidebar_label:"Hallucination"},o=void 0,d={},c=[{value:"Introduction",id:"introduction",level:2},{value:"Formula and Structure",id:"formula-and-structure",level:2},{value:"FEWL-Based Factualness (Wei et al., 2024)",id:"fewl-based-factualness-wei-et-al-2024",level:3},{value:"Variants and Implementations",id:"variants-and-implementations",level:2},{value:"1. Hallucination Rate",id:"1-hallucination-rate",level:3},{value:"2. AMBER Hallucination Categories",id:"2-amber-hallucination-categories",level:3},{value:"3. FEWL Model-Based Factualness",id:"3-fewl-model-based-factualness",level:3},{value:"4. Domain-Specific Hallucination Detection",id:"4-domain-specific-hallucination-detection",level:3},{value:"Application in Software Engineering",id:"application-in-software-engineering",level:2},{value:"Interpretation",id:"interpretation",level:2},{value:"References",id:"references",level:2},{value:"Additional References in Dataset",id:"additional-references-in-dataset",level:3}];function h(i){const e={a:"a",annotation:"annotation",br:"br",em:"em",h2:"h2",h3:"h3",li:"li",math:"math",mfrac:"mfrac",mi:"mi",mo:"mo",mrow:"mrow",msub:"msub",ol:"ol",p:"p",semantics:"semantics",span:"span",ul:"ul",...(0,s.R)(),...i.components};return(0,r.jsxs)(r.Fragment,{children:[(0,r.jsx)(e.h2,{id:"introduction",children:"Introduction"}),"\n",(0,r.jsxs)(e.p,{children:["The Hallucination metric quantifies the extent to which a model produces content that is factually incorrect, ungrounded, irrelevant, or logically inconsistent with respect to the input or known information.",(0,r.jsx)(e.br,{}),"\n","In large language models and software engineering settings, hallucination typically refers to generated statements, code, or explanations that appear coherent but contain inaccuracies, fabricated details, or non-existent elements (e.g., invalid APIs, incorrect parameters, or invented functions).",(0,r.jsx)(e.br,{}),"\n","This metric is essential for evaluating reliability and truthfulness in tasks such as code documentation, automated debugging assistance, requirement generation, and other contexts where factual correctness is critical."]}),"\n",(0,r.jsx)(e.h2,{id:"formula-and-structure",children:"Formula and Structure"}),"\n",(0,r.jsxs)(e.p,{children:["Hallucination is commonly measured using discrete proportions rather than continuous scores.",(0,r.jsx)(e.br,{}),"\n","A general formulation used across benchmarks is the ",(0,r.jsx)(e.em,{children:"hallucination rate"}),":"]}),"\n",(0,r.jsx)(e.span,{className:"katex",children:(0,r.jsx)(e.math,{xmlns:"http://www.w3.org/1998/Math/MathML",display:"block",children:(0,r.jsxs)(e.semantics,{children:[(0,r.jsxs)(e.mrow,{children:[(0,r.jsxs)(e.msub,{children:[(0,r.jsx)(e.mi,{children:"H"}),(0,r.jsxs)(e.mrow,{children:[(0,r.jsx)(e.mi,{children:"r"}),(0,r.jsx)(e.mi,{children:"a"}),(0,r.jsx)(e.mi,{children:"t"}),(0,r.jsx)(e.mi,{children:"e"})]})]}),(0,r.jsx)(e.mo,{children:"="}),(0,r.jsxs)(e.mfrac,{children:[(0,r.jsxs)(e.msub,{children:[(0,r.jsx)(e.mi,{children:"N"}),(0,r.jsxs)(e.mrow,{children:[(0,r.jsx)(e.mi,{children:"h"}),(0,r.jsx)(e.mi,{children:"a"}),(0,r.jsx)(e.mi,{children:"l"}),(0,r.jsx)(e.mi,{children:"l"}),(0,r.jsx)(e.mi,{children:"u"}),(0,r.jsx)(e.mi,{children:"c"}),(0,r.jsx)(e.mi,{children:"i"}),(0,r.jsx)(e.mi,{children:"n"}),(0,r.jsx)(e.mi,{children:"a"}),(0,r.jsx)(e.mi,{children:"t"}),(0,r.jsx)(e.mi,{children:"e"}),(0,r.jsx)(e.mi,{children:"d"})]})]}),(0,r.jsxs)(e.msub,{children:[(0,r.jsx)(e.mi,{children:"N"}),(0,r.jsxs)(e.mrow,{children:[(0,r.jsx)(e.mi,{children:"t"}),(0,r.jsx)(e.mi,{children:"o"}),(0,r.jsx)(e.mi,{children:"t"}),(0,r.jsx)(e.mi,{children:"a"}),(0,r.jsx)(e.mi,{children:"l"})]})]})]})]}),(0,r.jsx)(e.annotation,{encoding:"application/x-tex",children:"H_{rate} = \\frac{N_{hallucinated}}{N_{total}}"})]})})}),"\n",(0,r.jsx)(e.p,{children:"where"}),"\n",(0,r.jsxs)(e.ul,{children:["\n",(0,r.jsxs)(e.li,{children:[(0,r.jsx)(e.span,{className:"katex",children:(0,r.jsx)(e.math,{xmlns:"http://www.w3.org/1998/Math/MathML",children:(0,r.jsxs)(e.semantics,{children:[(0,r.jsx)(e.mrow,{children:(0,r.jsxs)(e.msub,{children:[(0,r.jsx)(e.mi,{children:"N"}),(0,r.jsxs)(e.mrow,{children:[(0,r.jsx)(e.mi,{children:"h"}),(0,r.jsx)(e.mi,{children:"a"}),(0,r.jsx)(e.mi,{children:"l"}),(0,r.jsx)(e.mi,{children:"l"}),(0,r.jsx)(e.mi,{children:"u"}),(0,r.jsx)(e.mi,{children:"c"}),(0,r.jsx)(e.mi,{children:"i"}),(0,r.jsx)(e.mi,{children:"n"}),(0,r.jsx)(e.mi,{children:"a"}),(0,r.jsx)(e.mi,{children:"t"}),(0,r.jsx)(e.mi,{children:"e"}),(0,r.jsx)(e.mi,{children:"d"})]})]})}),(0,r.jsx)(e.annotation,{encoding:"application/x-tex",children:"N_{hallucinated}"})]})})})," is the number of outputs judged to contain hallucinations,"]}),"\n",(0,r.jsxs)(e.li,{children:[(0,r.jsx)(e.span,{className:"katex",children:(0,r.jsx)(e.math,{xmlns:"http://www.w3.org/1998/Math/MathML",children:(0,r.jsxs)(e.semantics,{children:[(0,r.jsx)(e.mrow,{children:(0,r.jsxs)(e.msub,{children:[(0,r.jsx)(e.mi,{children:"N"}),(0,r.jsxs)(e.mrow,{children:[(0,r.jsx)(e.mi,{children:"t"}),(0,r.jsx)(e.mi,{children:"o"}),(0,r.jsx)(e.mi,{children:"t"}),(0,r.jsx)(e.mi,{children:"a"}),(0,r.jsx)(e.mi,{children:"l"})]})]})}),(0,r.jsx)(e.annotation,{encoding:"application/x-tex",children:"N_{total}"})]})})})," is the number of evaluated outputs."]}),"\n"]}),"\n",(0,r.jsxs)(e.p,{children:["This instance-level formulation is consistent across classification-based, content-verification, and multimodal hallucination benchmarks.",(0,r.jsx)(e.br,{}),"\n","Frameworks may apply automatic judgments, human annotation, or external model-based verification."]}),"\n",(0,r.jsx)(e.h3,{id:"fewl-based-factualness-wei-et-al-2024",children:"FEWL-Based Factualness (Wei et al., 2024)"}),"\n",(0,r.jsxs)(e.p,{children:["Some evaluation settings use a model-weighted factualness score to assess hallucination without access to gold-standard answers.",(0,r.jsx)(e.br,{}),"\n","The FEWL framework aggregates judgments from multiple trusted LLMs to estimate the likelihood that an output is factual, producing a continuous hallucination-related score that complements rate-based metrics."]}),"\n",(0,r.jsx)(e.h2,{id:"variants-and-implementations",children:"Variants and Implementations"}),"\n",(0,r.jsx)(e.h3,{id:"1-hallucination-rate",children:"1. Hallucination Rate"}),"\n",(0,r.jsxs)(e.p,{children:["Used in surveys and evaluation frameworks such as HELM and general NLP/LLM assessments, hallucination rate measures the proportion of outputs containing incorrect or ungrounded content.",(0,r.jsx)(e.br,{}),"\n","It is widely applied to factual QA, summarization, reasoning, and text generation."]}),"\n",(0,r.jsx)(e.h3,{id:"2-amber-hallucination-categories",children:"2. AMBER Hallucination Categories"}),"\n",(0,r.jsx)(e.p,{children:"AMBER (2024) introduces a structured taxonomy for multimodal hallucination evaluation consisting of:"}),"\n",(0,r.jsxs)(e.ul,{children:["\n",(0,r.jsxs)(e.li,{children:[(0,r.jsx)(e.em,{children:"Existence Hallucination:"})," Claiming entities that do not exist or are not present."]}),"\n",(0,r.jsxs)(e.li,{children:[(0,r.jsx)(e.em,{children:"Attribute Hallucination:"})," Incorrect or fabricated attributes about existing entities."]}),"\n",(0,r.jsxs)(e.li,{children:[(0,r.jsx)(e.em,{children:"Relation Hallucination:"})," Incorrect relations or interactions between entities."]}),"\n"]}),"\n",(0,r.jsx)(e.p,{children:"AMBER evaluates hallucination by classifying each generated response into correct or hallucinated categories across these dimensions."}),"\n",(0,r.jsx)(e.h3,{id:"3-fewl-model-based-factualness",children:"3. FEWL Model-Based Factualness"}),"\n",(0,r.jsxs)(e.p,{children:["FEWL provides a hallucination-oriented scoring mechanism without requiring reference answers.",(0,r.jsx)(e.br,{}),"\n","It leverages multiple LLM judges and learned weighting to compute a factualness score, penalizing logically inconsistent or fabricated content."]}),"\n",(0,r.jsx)(e.h3,{id:"4-domain-specific-hallucination-detection",children:"4. Domain-Specific Hallucination Detection"}),"\n",(0,r.jsx)(e.p,{children:"Hallucination evaluation appears in specialized software engineering tasks such as:"}),"\n",(0,r.jsxs)(e.ul,{children:["\n",(0,r.jsx)(e.li,{children:"API correctness verification"}),"\n",(0,r.jsx)(e.li,{children:"checking validity of code references"}),"\n",(0,r.jsxs)(e.li,{children:["assessing generated documentation against real codebases",(0,r.jsx)(e.br,{}),"\n","These settings adapt the hallucination rate to code-related units such as statements or API calls."]}),"\n"]}),"\n",(0,r.jsx)(e.h2,{id:"application-in-software-engineering",children:"Application in Software Engineering"}),"\n",(0,r.jsxs)(e.p,{children:["Hallucination metrics are increasingly used to evaluate LLM-generated code, documentation, and technical explanations.",(0,r.jsx)(e.br,{}),"\n","Common manifestations include:"]}),"\n",(0,r.jsxs)(e.ul,{children:["\n",(0,r.jsx)(e.li,{children:"use of non-existent APIs or functions,"}),"\n",(0,r.jsx)(e.li,{children:"incorrect library imports,"}),"\n",(0,r.jsx)(e.li,{children:"fabricated parameter names or values,"}),"\n",(0,r.jsx)(e.li,{children:"logically invalid reasoning in debugging explanations."}),"\n"]}),"\n",(0,r.jsx)(e.p,{children:"Measuring hallucination is essential for assessing robustness of LLM-based software assistants, improving code-generation correctness, and ensuring trustworthiness in automated development pipelines."}),"\n",(0,r.jsx)(e.h2,{id:"interpretation",children:"Interpretation"}),"\n",(0,r.jsxs)(e.ul,{children:["\n",(0,r.jsxs)(e.li,{children:[(0,r.jsx)(e.em,{children:"Low hallucination rate"})," indicates high factual consistency and reliability."]}),"\n",(0,r.jsxs)(e.li,{children:[(0,r.jsx)(e.em,{children:"High hallucination rate"})," reveals model tendencies to invent or distort information."]}),"\n"]}),"\n",(0,r.jsxs)(e.p,{children:["In both natural-language and software-engineering settings, hallucination metrics help quantify truthfulness and prevent deployment risks associated with incorrect or misleading content.",(0,r.jsx)(e.br,{}),"\n","Model behavior is interpreted not only by the presence of factual errors but also by the structural type of hallucination (existence, attribute, relation), providing a more detailed understanding of failure modes."]}),"\n",(0,r.jsx)(e.h2,{id:"references",children:"References"}),"\n",(0,r.jsxs)(e.ol,{children:["\n",(0,r.jsxs)(e.li,{children:["\n",(0,r.jsxs)(e.p,{children:[(0,r.jsx)(e.em,{children:"Ji, Z., Lee, N., Frieske, R., Yu, T., Su, D., Xu, Y., Ishii, E., Bang, Y., Madotto, A., & Fung, P. (2023)."}),(0,r.jsx)(e.br,{}),"\n","A Survey on Hallucination in Large Language Models.",(0,r.jsx)(e.br,{}),"\n",(0,r.jsx)(e.a,{href:"https://arxiv.org/abs/2311.05232",children:"https://arxiv.org/abs/2311.05232"})]}),"\n"]}),"\n",(0,r.jsxs)(e.li,{children:["\n",(0,r.jsxs)(e.p,{children:[(0,r.jsx)(e.em,{children:"Wei, J., Chen, D., Xie, Y., Huang, S., & Xiong, C. (2024)."}),(0,r.jsx)(e.br,{}),"\n","Measuring and Reducing LLM Hallucination without Gold-Standard Answers.",(0,r.jsx)(e.br,{}),"\n",(0,r.jsx)(e.a,{href:"https://arxiv.org/abs/2402.10412",children:"https://arxiv.org/abs/2402.10412"})]}),"\n"]}),"\n"]}),"\n",(0,r.jsx)(e.h3,{id:"additional-references-in-dataset",children:"Additional References in Dataset"}),"\n",(0,r.jsxs)(e.ul,{children:["\n",(0,r.jsxs)(e.li,{children:[(0,r.jsx)(a.r,{ids:["8"]}),": Wang, J. et al. (2023). AMBER: An LLM-free Multi-dimensional Benchmark for MLLMs Hallucination Evaluation"]}),"\n",(0,r.jsxs)(e.li,{children:[(0,r.jsx)(a.r,{ids:["9"]}),": Chang, Y. et al. (2023). A Survey on Evaluation of Large Language Models"]}),"\n",(0,r.jsxs)(e.li,{children:[(0,r.jsx)(a.r,{ids:["48"]}),": Xu, W. et al. (2025). LLM-Based Agents for Tool Learning: A Survey"]}),"\n",(0,r.jsxs)(e.li,{children:[(0,r.jsx)(a.r,{ids:["62"]}),": Li, Y. et al. (2025). Evaluating large language models for software testing."]}),"\n"]})]})}function u(i={}){const{wrapper:e}={...(0,s.R)(),...i.components};return e?(0,r.jsx)(e,{...i,children:(0,r.jsx)(h,{...i})}):h(i)}},8453:(i,e,n)=>{n.d(e,{R:()=>a,x:()=>l});var t=n(6540);const r={},s=t.createContext(r);function a(i){const e=t.useContext(s);return t.useMemo(function(){return"function"==typeof i?i(e):{...e,...i}},[e,i])}function l(i){let e;return e=i.disableParentContext?"function"==typeof i.components?i.components(r):i.components||r:a(i.components),t.createElement(s.Provider,{value:e},i.children)}}}]);