"use strict";(self.webpackChunkll_ms_metrics_catalog=self.webpackChunkll_ms_metrics_catalog||[]).push([[1414],{1612:(e,i,t)=>{t.r(i),t.d(i,{assets:()=>o,contentTitle:()=>r,default:()=>h,frontMatter:()=>l,metadata:()=>s,toc:()=>d});const s=JSON.parse('{"id":"metrics/ranking/llm-evaluation-metrics","title":"LLM-as-Judge and Sample Killings","description":"Introduction","source":"@site/docs/metrics/ranking/llm-evaluation-metrics.md","sourceDirName":"metrics/ranking","slug":"/metrics/ranking/llm-evaluation-metrics","permalink":"/LLMs-metrics-catalog/metrics/ranking/llm-evaluation-metrics","draft":false,"unlisted":false,"tags":[],"version":"current","frontMatter":{"id":"llm-evaluation-metrics","title":"LLM-as-Judge and Sample Killings","sidebar_label":"LLM-as-Judge / Killings"},"sidebar":"docsSidebar","previous":{"title":"Hit-N","permalink":"/LLMs-metrics-catalog/metrics/ranking/hit-n"},"next":{"title":"Language Model Score","permalink":"/LLMs-metrics-catalog/metrics/ranking/language-model-score"}}');var n=t(4848),a=t(8453);const l={id:"llm-evaluation-metrics",title:"LLM-as-Judge and Sample Killings",sidebar_label:"LLM-as-Judge / Killings"},r=void 0,o={},d=[{value:"Introduction",id:"introduction",level:2},{value:"1. LLM Sample Killings",id:"1-llm-sample-killings",level:2},{value:"Definition",id:"definition",level:3},{value:"Purpose",id:"purpose",level:3},{value:"Applications",id:"applications",level:3},{value:"Advantages",id:"advantages",level:3},{value:"Limitations",id:"limitations",level:3},{value:"2. LLM-as-Judge Ratings (1-3 Scale)",id:"2-llm-as-judge-ratings-1-3-scale",level:2},{value:"Definition",id:"definition-1",level:3},{value:"Purpose",id:"purpose-1",level:3},{value:"Applications",id:"applications-1",level:3},{value:"Advantages",id:"advantages-1",level:3},{value:"Limitations",id:"limitations-1",level:3},{value:"3. Comparative Summary",id:"3-comparative-summary",level:2},{value:"References",id:"references",level:2}];function c(e){const i={a:"a",em:"em",h2:"h2",h3:"h3",hr:"hr",li:"li",ol:"ol",p:"p",strong:"strong",table:"table",tbody:"tbody",td:"td",th:"th",thead:"thead",tr:"tr",ul:"ul",...(0,a.R)(),...e.components};return(0,n.jsxs)(n.Fragment,{children:[(0,n.jsx)(i.h2,{id:"introduction",children:"Introduction"}),"\n",(0,n.jsx)(i.p,{children:"This document covers two distinct but related evaluation techniques that use Large Language Models (LLMs) as part of the evaluation process itself."}),"\n",(0,n.jsxs)(i.ol,{children:["\n",(0,n.jsxs)(i.li,{children:[(0,n.jsx)(i.strong,{children:"LLM Sample Killings"})," is a strategy to measure and improve ",(0,n.jsx)(i.strong,{children:"test effectiveness"}),'. It identifies which test cases are most valuable by measuring their ability to "kill" (i.e., detect and falsify) incorrect code samples generated by a set of LLMs.']}),"\n",(0,n.jsxs)(i.li,{children:[(0,n.jsx)(i.strong,{children:"LLM-as-Judge Ratings"})," is a ",(0,n.jsx)(i.strong,{children:"human-aligned evaluation"}),' method. It uses a powerful LLM to act as a "judge" and assign a qualitative score to another model\'s output (such as a textual description), assessing its quality against human-defined criteria.']}),"\n"]}),"\n",(0,n.jsx)(i.p,{children:"These methods represent a shift from traditional evaluation, leveraging LLMs' own outputs or reasoning capabilities to create more robust benchmarks and assessments."}),"\n",(0,n.jsx)(i.hr,{}),"\n",(0,n.jsx)(i.h2,{id:"1-llm-sample-killings",children:"1. LLM Sample Killings"}),"\n",(0,n.jsx)(i.h3,{id:"definition",children:"Definition"}),"\n",(0,n.jsxs)(i.p,{children:[(0,n.jsx)(i.strong,{children:"LLM Sample Killings"})," is a testing requirement used for test-suite reduction, particularly in the ",(0,n.jsx)(i.strong,{children:"HumanEval+"})," benchmark. It is defined as the set of incorrect LLM-generated code samples that a specific test case can successfully detect and falsify."]}),"\n",(0,n.jsx)(i.p,{children:'This empirical metric is used to find the most effective test cases: a test is considered valuable if it "kills" many incorrect LLM solutions that other, simpler tests might miss.'}),"\n",(0,n.jsx)(i.h3,{id:"purpose",children:"Purpose"}),"\n",(0,n.jsxs)(i.p,{children:["The primary purpose of this metric is ",(0,n.jsx)(i.strong,{children:"test-suite reduction"})," and ensuring ",(0,n.jsx)(i.strong,{children:"test effectiveness"}),"."]}),"\n",(0,n.jsx)(i.p,{children:'By identifying the tests that "kill" the most diverse set of empirically wrong LLM samples, a large test suite (like HumanEval+) can be "distilled" into a much smaller one (like HumanEval+-MINI). This reduced suite remains highly effective and can "achieve almost the same pass@1* drop" as the full suite, making rigorous evaluation much more efficient.'}),"\n",(0,n.jsx)(i.h3,{id:"applications",children:"Applications"}),"\n",(0,n.jsxs)(i.ul,{children:["\n",(0,n.jsx)(i.li,{children:(0,n.jsx)(i.strong,{children:"Software Engineering / Code Generation"})}),"\n",(0,n.jsx)(i.li,{children:(0,n.jsx)(i.strong,{children:"Test Effectiveness / Model Robustness"})}),"\n",(0,n.jsx)(i.li,{children:"Benchmark creation and test-suite minimization"}),"\n"]}),"\n",(0,n.jsx)(i.h3,{id:"advantages",children:"Advantages"}),"\n",(0,n.jsxs)(i.ul,{children:["\n",(0,n.jsxs)(i.li,{children:[(0,n.jsx)(i.strong,{children:"Highly Effective:"}),' This strategy was found to be the "most effective" for test-suite reduction, preserving the benchmark\'s ability to find errors.']}),"\n",(0,n.jsxs)(i.li,{children:[(0,n.jsx)(i.strong,{children:"Practical:"})," It is an empirical, practical measure of a test case's value, based on real-world LLM failures."]}),"\n"]}),"\n",(0,n.jsx)(i.h3,{id:"limitations",children:"Limitations"}),"\n",(0,n.jsxs)(i.ul,{children:["\n",(0,n.jsxs)(i.li,{children:[(0,n.jsx)(i.strong,{children:"Requires Cross-Validation:"}),' To evaluate a new LLM, one must use the "sample kills" data gathered from ',(0,n.jsx)(i.em,{children:"other"})," LLMs (a leave-one-out cross-validation approach)."]}),"\n"]}),"\n",(0,n.jsx)(i.hr,{}),"\n",(0,n.jsx)(i.h2,{id:"2-llm-as-judge-ratings-1-3-scale",children:"2. LLM-as-Judge Ratings (1-3 Scale)"}),"\n",(0,n.jsx)(i.h3,{id:"definition-1",children:"Definition"}),"\n",(0,n.jsxs)(i.p,{children:[(0,n.jsx)(i.strong,{children:"LLM-as-Judge Ratings"})," is an evaluation method used in the ",(0,n.jsx)(i.strong,{children:"HumanEval-V"}),' benchmark where a capable LLM (e.g., GPT-4o) acts as a "judge" to rate the quality of problem specifications (PS) generated by other LMMs.']}),"\n",(0,n.jsxs)(i.p,{children:["The judge rates the generated text on a ",(0,n.jsx)(i.strong,{children:"1-3 scale"})," (1 = severe error, 3 = near perfect) across three distinct dimensions:"]}),"\n",(0,n.jsxs)(i.ol,{children:["\n",(0,n.jsxs)(i.li,{children:[(0,n.jsx)(i.strong,{children:"Basic-Level Perception:"})," Identifying basic visual elements (shapes, text, colors, etc.)."]}),"\n",(0,n.jsxs)(i.li,{children:[(0,n.jsx)(i.strong,{children:"High-Level Comprehension:"})," Understanding the relationships, patterns, constraints, and operations depicted in the visual context."]}),"\n",(0,n.jsxs)(i.li,{children:[(0,n.jsx)(i.strong,{children:"Contextual Interpretation:"})," The clarity of the description, ensuring it is free of vagueness or hallucinations."]}),"\n"]}),"\n",(0,n.jsx)(i.h3,{id:"purpose-1",children:"Purpose"}),"\n",(0,n.jsxs)(i.p,{children:["The goal is to provide a scalable, ",(0,n.jsx)(i.strong,{children:"human-aligned evaluation"})," of an LMM's ",(0,n.jsx)(i.em,{children:"visual understanding"})," capabilities, separate from its ",(0,n.jsx)(i.em,{children:"coding"})," proficiency. It assesses the quality of the intermediate textual description that the model generates from a visual diagram."]}),"\n",(0,n.jsx)(i.h3,{id:"applications-1",children:"Applications"}),"\n",(0,n.jsxs)(i.ul,{children:["\n",(0,n.jsx)(i.li,{children:(0,n.jsx)(i.strong,{children:"Multimodal Code Generation"})}),"\n",(0,n.jsx)(i.li,{children:(0,n.jsx)(i.strong,{children:"Visual Reasoning"})}),"\n",(0,n.jsx)(i.li,{children:"Evaluating the quality of intermediate textual representations (e.g., problem specifications)."}),"\n"]}),"\n",(0,n.jsx)(i.h3,{id:"advantages-1",children:"Advantages"}),"\n",(0,n.jsxs)(i.ul,{children:["\n",(0,n.jsxs)(i.li,{children:[(0,n.jsx)(i.strong,{children:"Decouples Skills:"})," It allows for the isolated evaluation of visual comprehension without penalizing a model for poor coding ability."]}),"\n",(0,n.jsxs)(i.li,{children:[(0,n.jsx)(i.strong,{children:"Scalable & Qualitative:"})," It offers a way to get nuanced, human-like qualitative feedback at scale without requiring expensive human annotation for every output."]}),"\n"]}),"\n",(0,n.jsx)(i.h3,{id:"limitations-1",children:"Limitations"}),"\n",(0,n.jsxs)(i.ul,{children:["\n",(0,n.jsxs)(i.li,{children:[(0,n.jsx)(i.strong,{children:"Limited Robustness:"}),' The study found "limitations of using LLM-as-judge as an evaluation tool".']}),"\n",(0,n.jsxs)(i.li,{children:[(0,n.jsx)(i.strong,{children:"Poor Correlation:"})," The ratings difference between problem specifications that led to ",(0,n.jsx)(i.em,{children:"passed"})," tasks versus ",(0,n.jsx)(i.em,{children:"failed"})," tasks was minimal, suggesting the judge's ratings did not strongly correlate with downstream functional correctness."]}),"\n",(0,n.jsxs)(i.li,{children:[(0,n.jsx)(i.strong,{children:"Rigid Comparisons:"}),' The method may suffer from "rigid comparisons" to the human-annotated ground truth, which is why the benchmark emphasizes functional pass rates as the primary metric.']}),"\n"]}),"\n",(0,n.jsx)(i.hr,{}),"\n",(0,n.jsx)(i.h2,{id:"3-comparative-summary",children:"3. Comparative Summary"}),"\n",(0,n.jsxs)(i.table,{children:[(0,n.jsx)(i.thead,{children:(0,n.jsxs)(i.tr,{children:[(0,n.jsx)(i.th,{style:{textAlign:"left"},children:"Metric"}),(0,n.jsx)(i.th,{style:{textAlign:"left"},children:"Core Concept"}),(0,n.jsx)(i.th,{style:{textAlign:"left"},children:"Evaluation Target"}),(0,n.jsx)(i.th,{style:{textAlign:"left"},children:"Primary Goal"}),(0,n.jsx)(i.th,{style:{textAlign:"left"},children:"Domain"})]})}),(0,n.jsxs)(i.tbody,{children:[(0,n.jsxs)(i.tr,{children:[(0,n.jsx)(i.td,{style:{textAlign:"left"},children:(0,n.jsx)(i.strong,{children:"LLM Sample Killings"})}),(0,n.jsx)(i.td,{style:{textAlign:"left"},children:"Using failed LLM outputs"}),(0,n.jsx)(i.td,{style:{textAlign:"left"},children:"Test cases"}),(0,n.jsx)(i.td,{style:{textAlign:"left"},children:"To build an efficient, robust test suite"}),(0,n.jsx)(i.td,{style:{textAlign:"left"},children:"Code Generation"})]}),(0,n.jsxs)(i.tr,{children:[(0,n.jsx)(i.td,{style:{textAlign:"left"},children:(0,n.jsx)(i.strong,{children:"LLM-as-Judge Ratings"})}),(0,n.jsx)(i.td,{style:{textAlign:"left"},children:"Using an LLM's evaluative ability"}),(0,n.jsx)(i.td,{style:{textAlign:"left"},children:"LMM-generated text"}),(0,n.jsx)(i.td,{style:{textAlign:"left"},children:"To provide qualitative, human-aligned ratings"}),(0,n.jsx)(i.td,{style:{textAlign:"left"},children:"Visual Reasoning"})]})]})]}),"\n",(0,n.jsx)(i.hr,{}),"\n",(0,n.jsx)(i.h2,{id:"references",children:"References"}),"\n",(0,n.jsxs)(i.ul,{children:["\n",(0,n.jsxs)(i.li,{children:["Liu, J., Xia, C. S., Wang, Y., & Zhang, L. (2023). Is your code generated by ChatGPT really correct? Rigorous evaluation of large language models for code generation (arXiv:2305.01210v3). arXiv. ",(0,n.jsx)(i.a,{href:"https://doi.org/10.48550/arXiv.2305.01210",children:"https://doi.org/10.48550/arXiv.2305.01210"})," (Paper 20)"]}),"\n",(0,n.jsxs)(i.li,{children:["Zhang, F., Wu, L., Bai, H., Lin, G., Li, X., Yu, X., Wang, Y., Chen, B., & Keung, J. (2025). HumanEval-V: Benchmarking high-level visual reasoning with complex diagrams in coding tasks (arXiv:2410.12381v3). arXiv. ",(0,n.jsx)(i.a,{href:"https://doi.org/10.48550/arXiv.2410.12381",children:"https://doi.org/10.48550/arXiv.2410.12381"})," (Paper 33)"]}),"\n"]})]})}function h(e={}){const{wrapper:i}={...(0,a.R)(),...e.components};return i?(0,n.jsx)(i,{...e,children:(0,n.jsx)(c,{...e})}):c(e)}},8453:(e,i,t)=>{t.d(i,{R:()=>l,x:()=>r});var s=t(6540);const n={},a=s.createContext(n);function l(e){const i=s.useContext(a);return s.useMemo(function(){return"function"==typeof e?e(i):{...i,...e}},[i,e])}function r(e){let i;return i=e.disableParentContext?"function"==typeof e.components?e.components(n):e.components||n:l(e.components),s.createElement(a.Provider,{value:i},e.children)}}}]);