"use strict";(self.webpackChunkll_ms_metrics_catalog=self.webpackChunkll_ms_metrics_catalog||[]).push([[6725],{917:(e,i,n)=>{n.r(i),n.d(i,{assets:()=>l,contentTitle:()=>r,default:()=>u,frontMatter:()=>t,metadata:()=>a,toc:()=>c});const a=JSON.parse('{"id":"metrics/semantic/sentiment-polarity-shift","title":"Sentiment Polarity Shift","description":"Definition","source":"@site/docs/metrics/semantic/sentiment-polarity-shift.md","sourceDirName":"metrics/semantic","slug":"/metrics/semantic/sentiment-polarity-shift","permalink":"/LLMs-metrics-catalog/metrics/semantic/sentiment-polarity-shift","draft":false,"unlisted":false,"tags":[],"version":"current","frontMatter":{"id":"sentiment-polarity-shift","title":"Sentiment Polarity Shift","sidebar_label":"Sentiment Polarity"},"sidebar":"docsSidebar","previous":{"title":"Semantic","permalink":"/LLMs-metrics-catalog/metrics/semantic/"},"next":{"title":"Similarity","permalink":"/LLMs-metrics-catalog/metrics/semantic/similarity"}}');var s=n(4848),o=n(8453);const t={id:"sentiment-polarity-shift",title:"Sentiment Polarity Shift",sidebar_label:"Sentiment Polarity"},r=void 0,l={},c=[{value:"Definition",id:"definition",level:2},{value:"Calculation (General Idea)",id:"calculation-general-idea",level:2},{value:"Purpose",id:"purpose",level:2},{value:"Domains",id:"domains",level:2},{value:"Advantages",id:"advantages",level:2},{value:"Limitations",id:"limitations",level:2},{value:"Key References",id:"key-references",level:2}];function d(e){const i={a:"a",em:"em",h2:"h2",hr:"hr",li:"li",ol:"ol",p:"p",strong:"strong",ul:"ul",...(0,o.R)(),...e.components};return(0,s.jsxs)(s.Fragment,{children:[(0,s.jsx)(i.h2,{id:"definition",children:"Definition"}),"\n",(0,s.jsxs)(i.p,{children:[(0,s.jsx)(i.strong,{children:"Sentiment Polarity Shift"})," no es una m\xe9trica \xfanica, sino una categor\xeda de evaluaci\xf3n dise\xf1ada para medir el sesgo social (Social Bias). Cuantifica c\xf3mo la polaridad del sentimiento (positiva, negativa o neutra) de la respuesta de un LLM cambia cuando se condiciona a diferentes grupos sociales (por ejemplo, por g\xe9nero, raza o religi\xf3n)."]}),"\n",(0,s.jsx)(i.p,{children:"Este enfoque eval\xfaa si el modelo asocia a ciertos grupos con connotaciones sociales m\xe1s negativas o positivas. Las m\xe9tricas espec\xedficas que implementan esta idea incluyen:"}),"\n",(0,s.jsxs)(i.ul,{children:["\n",(0,s.jsxs)(i.li,{children:[(0,s.jsx)(i.strong,{children:"Regard Score"}),': Mide la "polaridad hacia... grupos sociales" o la connotaci\xf3n social positiva/negativa.']}),"\n",(0,s.jsxs)(i.li,{children:[(0,s.jsx)(i.strong,{children:"Counterfactual Sentiment Bias"}),": Compara las distribuciones de sentimiento de dos frases generadas a partir de prompts contraf\xe1cticos (por ejemplo, donde solo se cambia el grupo social)."]}),"\n",(0,s.jsxs)(i.li,{children:[(0,s.jsx)(i.strong,{children:"Score Parity"}),": Mide la consistencia con la que un modelo genera lenguaje (evaluado por un clasificador de sentimiento) con respecto a un atributo protegido."]}),"\n"]}),"\n",(0,s.jsx)(i.hr,{}),"\n",(0,s.jsx)(i.h2,{id:"calculation-general-idea",children:"Calculation (General Idea)"}),"\n",(0,s.jsx)(i.p,{children:"Estas m\xe9tricas generalmente dependen de un modelo clasificador auxiliar para puntuar el texto generado en busca de sentimiento o toxicidad."}),"\n",(0,s.jsxs)(i.ol,{children:["\n",(0,s.jsxs)(i.li,{children:[(0,s.jsx)(i.strong,{children:"Prompting"}),': Se proporcionan al LLM prompts que contienen descriptores de grupos sociales. A menudo, estos se presentan en pares contraf\xe1cticos (p.ej., "El hombre [Grupo A] era..." vs. "El hombre [Grupo B] era...").']}),"\n",(0,s.jsxs)(i.li,{children:[(0,s.jsx)(i.strong,{children:"Generation"}),": El LLM genera texto o continuaciones para cada prompt."]}),"\n",(0,s.jsxs)(i.li,{children:[(0,s.jsx)(i.strong,{children:"Classification"}),": Un clasificador externo (p.ej., un clasificador de sentimiento o toxicidad) punt\xfaa la polaridad de cada texto generado."]}),"\n",(0,s.jsxs)(i.li,{children:[(0,s.jsx)(i.strong,{children:"Comparison"}),': El "cambio" (shift) se calcula comparando las puntuaciones de sentimiento o las distribuciones entre los diferentes grupos sociales. Por ejemplo, ',(0,s.jsx)(i.em,{children:"Counterfactual Sentiment Bias"})," utiliza la distancia de Wasserstein-1 para medir la diferencia entre las distribuciones de sentimiento resultantes."]}),"\n"]}),"\n",(0,s.jsx)(i.hr,{}),"\n",(0,s.jsx)(i.h2,{id:"purpose",children:"Purpose"}),"\n",(0,s.jsx)(i.p,{children:"El objetivo principal es cuantificar los sesgos sociales y culturales mediante la identificaci\xf3n de un sentimiento o polaridad dispar en los resultados del modelo asociados con diferentes grupos."}),"\n",(0,s.jsxs)(i.p,{children:["Esto ayuda a detectar da\xf1os representacionales como la ",(0,s.jsx)(i.strong,{children:"estereotipaci\xf3n"})," (donde un modelo asocia a un grupo con atributos negativos) o la ",(0,s.jsx)(i.strong,{children:"misma representaci\xf3n"})," (donde un modelo clasifica incorrectamente declaraciones sobre grupos estigmatizados como negativas)."]}),"\n",(0,s.jsx)(i.hr,{}),"\n",(0,s.jsx)(i.h2,{id:"domains",children:"Domains"}),"\n",(0,s.jsxs)(i.ul,{children:["\n",(0,s.jsx)(i.li,{children:"Fairness / Bias Evaluation"}),"\n",(0,s.jsx)(i.li,{children:"Social / Cultural Bias"}),"\n",(0,s.jsx)(i.li,{children:"Text Generation (Open-Ended)"}),"\n",(0,s.jsx)(i.li,{children:"Sentiment Analysis"}),"\n"]}),"\n",(0,s.jsx)(i.hr,{}),"\n",(0,s.jsx)(i.h2,{id:"advantages",children:"Advantages"}),"\n",(0,s.jsxs)(i.ul,{children:["\n",(0,s.jsx)(i.li,{children:"Mide directamente un da\xf1o representacional espec\xedfico y bien conocido (sentimiento dispar) en el texto generado."}),"\n",(0,s.jsx)(i.li,{children:"Se puede aplicar a modelos de caja negra, ya que solo requiere el texto de salida para ser puntuado por un clasificador externo."}),"\n",(0,s.jsx)(i.li,{children:"Captura sesgos m\xe1s sutiles que la simple toxicidad, como los estereotipos negativos o las microagresiones."}),"\n"]}),"\n",(0,s.jsx)(i.hr,{}),"\n",(0,s.jsx)(i.h2,{id:"limitations",children:"Limitations"}),"\n",(0,s.jsxs)(i.ul,{children:["\n",(0,s.jsxs)(i.li,{children:["La m\xe9trica es ",(0,s.jsx)(i.strong,{children:"altamente dependiente del clasificador auxiliar"})," (p.ej., de sentimiento o toxicidad) utilizado, el cual puede tener sus propios sesgos."]}),"\n",(0,s.jsx)(i.li,{children:"Los clasificadores de sentimiento pueden clasificar incorrectamente las declaraciones sobre grupos estigmatizados (p.ej., personas con discapacidades o enfermedades mentales) como negativas, sesgando as\xed la m\xe9trica."}),"\n",(0,s.jsx)(i.li,{children:"Los prompts de texto abierto pueden ser ambiguos; el sesgo puede referirse al grupo en el prompt o a un grupo mencionado en la continuaci\xf3n, lo que dificulta la atribuci\xf3n del sesgo."}),"\n",(0,s.jsx)(i.li,{children:"Las elecciones de los par\xe1metros de decodificaci\xf3n (p.ej., temperatura, top-k) pueden cambiar dr\xe1sticamente el nivel de sesgo medido, lo que lleva a resultados contradictorios."}),"\n"]}),"\n",(0,s.jsx)(i.hr,{}),"\n",(0,s.jsx)(i.h2,{id:"key-references",children:"Key References"}),"\n",(0,s.jsxs)(i.ul,{children:["\n",(0,s.jsxs)(i.li,{children:["\n",(0,s.jsxs)(i.p,{children:["Gallegos, I. O., Rossi, R. A., Barrow, J., Tanjim, M. M., Kim, S., Dernoncourt, F., Yu, T., Zhang, R., & Ahmed, N. K. (2024). Bias and fairness in large language models: A survey. Computational Linguistics, 50(3), 1043\u20131108. ",(0,s.jsx)(i.a,{href:"https://doi.org/10.1162/coli_a_00524",children:"https://doi.org/10.1162/coli_a_00524"})]}),"\n"]}),"\n",(0,s.jsxs)(i.li,{children:["\n",(0,s.jsxs)(i.p,{children:["Dhamala, J., Sun, T., Kumar, V., Krishna, S., Pruksachatkun, Y., Chang, K.-W., & Gupta, R. (2021). BOLD: Dataset and metrics for measuring biases in open-ended language generation. arXiv. ",(0,s.jsx)(i.a,{href:"https://doi.org/10.48550/arXiv.2101.11718",children:"https://doi.org/10.48550/arXiv.2101.11718"})]}),"\n"]}),"\n",(0,s.jsxs)(i.li,{children:["\n",(0,s.jsxs)(i.p,{children:["Sheng, E., Chang, K.-W., Natarajan, P., & Peng, N. (2019). The woman worked as a babysitter: On biases in language generation. arXiv. ",(0,s.jsx)(i.a,{href:"https://doi.org/10.48550/arXiv.1909.01326",children:"https://doi.org/10.48550/arXiv.1909.01326"})]}),"\n"]}),"\n",(0,s.jsxs)(i.li,{children:["\n",(0,s.jsxs)(i.p,{children:["Huang, P.-S., Zhang, H., Jiang, R., Stanforth, R., Welbl, J., Rae, J., Maini, V., Yogatama, D., & Kohli, P. (2020). Reducing sentiment bias in language models via counterfactual evaluation. En Findings of the Association for Computational Linguistics: EMNLP 2020 (pp. 65\u201383). Association for Computational Linguistics. ",(0,s.jsx)(i.a,{href:"https://doi.org/10.18653/v1/2020.findings-emnlp.7",children:"https://doi.org/10.18653/v1/2020.findings-emnlp.7"})]}),"\n"]}),"\n"]})]})}function u(e={}){const{wrapper:i}={...(0,o.R)(),...e.components};return i?(0,s.jsx)(i,{...e,children:(0,s.jsx)(d,{...e})}):d(e)}},8453:(e,i,n)=>{n.d(i,{R:()=>t,x:()=>r});var a=n(6540);const s={},o=a.createContext(s);function t(e){const i=a.useContext(o);return a.useMemo(function(){return"function"==typeof e?e(i):{...i,...e}},[i,e])}function r(e){let i;return i=e.disableParentContext?"function"==typeof e.components?e.components(s):e.components||s:t(e.components),a.createElement(o.Provider,{value:i},e.children)}}}]);