"use strict";(self.webpackChunkll_ms_metrics_catalog=self.webpackChunkll_ms_metrics_catalog||[]).push([[9768],{3398:e=>{e.exports=JSON.parse('{"version":{"pluginId":"default","version":"current","label":"Next","banner":null,"badge":false,"noIndex":false,"className":"docs-version-current","isLast":true,"docsSidebars":{"docsSidebar":[{"type":"link","href":"/LLMs-metrics-catalog/intro","label":"Introduction","docId":"intro","unlisted":false},{"type":"category","label":"Core Accuracy & Overlap Metrics","collapsed":false,"items":[{"type":"link","href":"/LLMs-metrics-catalog/metrics/accuracy-overlap/bleu","label":"BLEU","docId":"metrics/accuracy-overlap/bleu","unlisted":false},{"type":"link","href":"/LLMs-metrics-catalog/metrics/accuracy-overlap/accuracy","label":"Accuracy","docId":"metrics/accuracy-overlap/accuracy","unlisted":false},{"type":"link","href":"/LLMs-metrics-catalog/metrics/accuracy-overlap/pass-at-k","label":"Pass@k","docId":"metrics/accuracy-overlap/pass-at-k","unlisted":false},{"type":"link","href":"/LLMs-metrics-catalog/metrics/accuracy-overlap/f1-score","label":"F1-Score","docId":"metrics/accuracy-overlap/f1-score","unlisted":false},{"type":"link","href":"/LLMs-metrics-catalog/metrics/accuracy-overlap/exact-match","label":"Exact Match","docId":"metrics/accuracy-overlap/exact-match","unlisted":false},{"type":"link","href":"/LLMs-metrics-catalog/metrics/accuracy-overlap/rouge","label":"ROUGE","docId":"metrics/accuracy-overlap/rouge","unlisted":false},{"type":"link","href":"/LLMs-metrics-catalog/metrics/accuracy-overlap/recall","label":"Recall","docId":"metrics/accuracy-overlap/recall","unlisted":false},{"type":"link","href":"/LLMs-metrics-catalog/metrics/accuracy-overlap/precision","label":"Precision","docId":"metrics/accuracy-overlap/precision","unlisted":false},{"type":"link","href":"/LLMs-metrics-catalog/metrics/accuracy-overlap/meteor","label":"Meteor","docId":"metrics/accuracy-overlap/meteor","unlisted":false},{"type":"link","href":"/LLMs-metrics-catalog/metrics/accuracy-overlap/edit-distance","label":"Edit Distance","docId":"metrics/accuracy-overlap/edit-distance","unlisted":false},{"type":"link","href":"/LLMs-metrics-catalog/metrics/accuracy-overlap/mrr","label":"Mean Reciprocal Rank","docId":"metrics/accuracy-overlap/mrr","unlisted":false},{"type":"link","href":"/LLMs-metrics-catalog/metrics/accuracy-overlap/swe","label":"SWE-Judge Score","docId":"metrics/accuracy-overlap/swe","unlisted":false},{"type":"link","href":"/LLMs-metrics-catalog/metrics/accuracy-overlap/bertscore","label":"BERTScore","docId":"metrics/accuracy-overlap/bertscore","unlisted":false},{"type":"link","href":"/LLMs-metrics-catalog/metrics/accuracy-overlap/coverage","label":"Coverage","docId":"metrics/accuracy-overlap/coverage","unlisted":false},{"type":"link","href":"/LLMs-metrics-catalog/metrics/accuracy-overlap/chrf","label":"chrF","docId":"metrics/accuracy-overlap/chrf","unlisted":false},{"type":"link","href":"/LLMs-metrics-catalog/metrics/accuracy-overlap/codescore","label":"CodeScore","docId":"metrics/accuracy-overlap/codescore","unlisted":false}],"collapsible":true},{"type":"category","label":"Statistical & Correlation Metrics","collapsed":false,"items":[{"type":"link","href":"/LLMs-metrics-catalog/metrics/statistical/ice-score","label":"ICE-Score","docId":"metrics/statistical/ice-score","unlisted":false},{"type":"link","href":"/LLMs-metrics-catalog/metrics/statistical/kendall","label":"Kendall\u2019s \u03c4","docId":"metrics/statistical/kendall","unlisted":false},{"type":"link","href":"/LLMs-metrics-catalog/metrics/statistical/spearman","label":"Spearman\u2019s \u03c1","docId":"metrics/statistical/spearman","unlisted":false},{"type":"link","href":"/LLMs-metrics-catalog/metrics/statistical/pearson","label":"Pearson\u2019s r","docId":"metrics/statistical/pearson","unlisted":false}],"collapsible":true},{"type":"category","label":"Code Quality & Structural Metrics","collapsed":false,"items":[{"type":"link","href":"/LLMs-metrics-catalog/metrics/code-structural/ast-metrics","label":"AST Metrics","docId":"metrics/code-structural/ast-metrics","unlisted":false}],"collapsible":true},{"type":"category","label":"Functional & Test-based Evaluation","collapsed":false,"items":[{"type":"link","href":"/LLMs-metrics-catalog/metrics/functional-test/error","label":"Error Metrics","docId":"metrics/functional-test/error","unlisted":false}],"collapsible":true},{"type":"category","label":"Human & Subjective Evaluation","collapsed":true,"items":[{"type":"link","href":"/LLMs-metrics-catalog/metrics/human/","label":"Human Metrics","docId":"metrics/human/human","unlisted":false},{"type":"link","href":"/LLMs-metrics-catalog/metrics/human/toxicity","label":"Toxicity","docId":"metrics/human/toxicity","unlisted":false}],"collapsible":true},{"type":"category","label":"Generative & Distribution Metrics","collapsed":true,"items":[{"type":"link","href":"/LLMs-metrics-catalog/metrics/generative/amber-score","label":"AMBER Score","docId":"metrics/generative/amber-score","unlisted":false}],"collapsible":true},{"type":"category","label":"Logical Reasoning & Verification","collapsed":true,"items":[{"type":"link","href":"/LLMs-metrics-catalog/metrics/logical/cog-metric","label":"Cog Metric","docId":"metrics/logical/cog-metric","unlisted":false}],"collapsible":true},{"type":"category","label":"Robustness, Security & Reliability","collapsed":true,"items":[{"type":"link","href":"/LLMs-metrics-catalog/metrics/robustness/ct-score","label":"CT Score","docId":"metrics/robustness/ct-score","unlisted":false}],"collapsible":true},{"type":"category","label":"Efficiency & Resource Usage","collapsed":true,"items":[{"type":"link","href":"/LLMs-metrics-catalog/metrics/efficiency/time","label":"Time Metrics","docId":"metrics/efficiency/time","unlisted":false},{"type":"link","href":"/LLMs-metrics-catalog/metrics/efficiency/memory","label":"Memory Metrics","docId":"metrics/efficiency/memory","unlisted":false}],"collapsible":true},{"type":"category","label":"Architectural & System-level Metrics","collapsed":true,"items":[{"type":"link","href":"/LLMs-metrics-catalog/metrics/architectural/composite","label":"Composite","docId":"metrics/architectural/composite","unlisted":false}],"collapsible":true},{"type":"category","label":"Creativity, Diversity & Novelty","collapsed":true,"items":[{"type":"link","href":"/LLMs-metrics-catalog/metrics/creativity/dialogue","label":"Dialogue Similarities","docId":"metrics/creativity/dialogue","unlisted":false}],"collapsible":true},{"type":"category","label":"Ranking, Reward & Optimization","collapsed":true,"items":[{"type":"link","href":"/LLMs-metrics-catalog/metrics/ranking/elo-score","label":"Elo Score","docId":"metrics/ranking/elo-score","unlisted":false}],"collapsible":true},{"type":"category","label":"Semantic, Coherence & Hallucination","collapsed":true,"items":[{"type":"link","href":"/LLMs-metrics-catalog/metrics/semantic/hallucination","label":"Hallucination","docId":"metrics/semantic/hallucination","unlisted":false}],"collapsible":true},{"type":"link","href":"/LLMs-metrics-catalog/references","label":"References","docId":"references","unlisted":false}]},"docs":{"intro":{"id":"intro","title":"Introduction","description":"Welcome to the LLMs Metrics Catalog, a structured repository designed to document, classify, and analyze the evaluation metrics used to assess Large Language Models (LLMs) in software engineering tasks.","sidebar":"docsSidebar"},"metrics/accuracy-overlap/accuracy":{"id":"metrics/accuracy-overlap/accuracy","title":"Accuracy","description":"Introduction","sidebar":"docsSidebar"},"metrics/accuracy-overlap/bertscore":{"id":"metrics/accuracy-overlap/bertscore","title":"BERTScore","description":"Introduction","sidebar":"docsSidebar"},"metrics/accuracy-overlap/bleu":{"id":"metrics/accuracy-overlap/bleu","title":"BLEU","description":"Introduction","sidebar":"docsSidebar"},"metrics/accuracy-overlap/chrf":{"id":"metrics/accuracy-overlap/chrf","title":"chrF","description":"Introduction","sidebar":"docsSidebar"},"metrics/accuracy-overlap/codescore":{"id":"metrics/accuracy-overlap/codescore","title":"CodeScore","description":"Overview","sidebar":"docsSidebar"},"metrics/accuracy-overlap/coverage":{"id":"metrics/accuracy-overlap/coverage","title":"Coverage","description":"Introduction","sidebar":"docsSidebar"},"metrics/accuracy-overlap/edit-distance":{"id":"metrics/accuracy-overlap/edit-distance","title":"Edit Distance","description":"Introduction","sidebar":"docsSidebar"},"metrics/accuracy-overlap/exact-match":{"id":"metrics/accuracy-overlap/exact-match","title":"Exact Match","description":"Introduction","sidebar":"docsSidebar"},"metrics/accuracy-overlap/f1-score":{"id":"metrics/accuracy-overlap/f1-score","title":"F1-Score","description":"Introduction","sidebar":"docsSidebar"},"metrics/accuracy-overlap/meteor":{"id":"metrics/accuracy-overlap/meteor","title":"Meteor","description":"Introduction","sidebar":"docsSidebar"},"metrics/accuracy-overlap/mrr":{"id":"metrics/accuracy-overlap/mrr","title":"Mean Reciprocal Rank","description":"Introduction","sidebar":"docsSidebar"},"metrics/accuracy-overlap/pass-at-k":{"id":"metrics/accuracy-overlap/pass-at-k","title":"Pass@k","description":"Introduction","sidebar":"docsSidebar"},"metrics/accuracy-overlap/precision":{"id":"metrics/accuracy-overlap/precision","title":"Precision","description":"Introduction","sidebar":"docsSidebar"},"metrics/accuracy-overlap/recall":{"id":"metrics/accuracy-overlap/recall","title":"Recall","description":"Introduction","sidebar":"docsSidebar"},"metrics/accuracy-overlap/rouge":{"id":"metrics/accuracy-overlap/rouge","title":"ROUGE","description":"Introduction","sidebar":"docsSidebar"},"metrics/accuracy-overlap/swe":{"id":"metrics/accuracy-overlap/swe","title":"SWE-Judge Score","description":"Introduction","sidebar":"docsSidebar"},"metrics/architectural/composite":{"id":"metrics/architectural/composite","title":"Composite","description":"","sidebar":"docsSidebar"},"metrics/code-structural/ast-metrics":{"id":"metrics/code-structural/ast-metrics","title":"AST Metrics","description":"","sidebar":"docsSidebar"},"metrics/creativity/dialogue":{"id":"metrics/creativity/dialogue","title":"Dialogue Similarities","description":"","sidebar":"docsSidebar"},"metrics/efficiency/memory":{"id":"metrics/efficiency/memory","title":"Memory Metrics","description":"Overview","sidebar":"docsSidebar"},"metrics/efficiency/time":{"id":"metrics/efficiency/time","title":"Time Metrics","description":"Introduction","sidebar":"docsSidebar"},"metrics/functional-test/error":{"id":"metrics/functional-test/error","title":"Error Metrics","description":"Introduction","sidebar":"docsSidebar"},"metrics/generative/amber-score":{"id":"metrics/generative/amber-score","title":"AMBER Score","description":"","sidebar":"docsSidebar"},"metrics/human/human":{"id":"metrics/human/human","title":"Human Metrics","description":"Overview","sidebar":"docsSidebar"},"metrics/human/toxicity":{"id":"metrics/human/toxicity","title":"Toxicity","description":"Overview","sidebar":"docsSidebar"},"metrics/logical/cog-metric":{"id":"metrics/logical/cog-metric","title":"Cog Metric","description":"","sidebar":"docsSidebar"},"metrics/ranking/elo-score":{"id":"metrics/ranking/elo-score","title":"Elo Score","description":"","sidebar":"docsSidebar"},"metrics/robustness/ct-score":{"id":"metrics/robustness/ct-score","title":"CT Score","description":"","sidebar":"docsSidebar"},"metrics/semantic/hallucination":{"id":"metrics/semantic/hallucination","title":"Hallucination","description":"","sidebar":"docsSidebar"},"metrics/statistical/ice-score":{"id":"metrics/statistical/ice-score","title":"ICE-Score","description":"Introduction","sidebar":"docsSidebar"},"metrics/statistical/kendall":{"id":"metrics/statistical/kendall","title":"Kendall\u2019s \u03c4","description":"Introduction","sidebar":"docsSidebar"},"metrics/statistical/pearson":{"id":"metrics/statistical/pearson","title":"Pearson\u2019s r","description":"Introduction","sidebar":"docsSidebar"},"metrics/statistical/spearman":{"id":"metrics/statistical/spearman","title":"Spearman\u2019s \u03c1","description":"Introduction","sidebar":"docsSidebar"},"references":{"id":"references","title":"References","description":"This page lists all source papers used in the LLMs Metrics Catalog. Click each ID to open the corresponding DOI link.","sidebar":"docsSidebar"},"tutorial-basics/congratulations":{"id":"tutorial-basics/congratulations","title":"Congratulations!","description":"You have just learned the basics of Docusaurus and made some changes to the initial template."},"tutorial-basics/create-a-blog-post":{"id":"tutorial-basics/create-a-blog-post","title":"Create a Blog Post","description":"Docusaurus creates a page for each blog post, but also a blog index page, a tag system, an RSS feed..."},"tutorial-basics/create-a-document":{"id":"tutorial-basics/create-a-document","title":"Create a Document","description":"Documents are groups of pages connected through:"},"tutorial-basics/create-a-page":{"id":"tutorial-basics/create-a-page","title":"Create a Page","description":"Add Markdown or React files to src/pages to create a standalone page:"},"tutorial-basics/deploy-your-site":{"id":"tutorial-basics/deploy-your-site","title":"Deploy your site","description":"Docusaurus is a static-site-generator (also called Jamstack)."},"tutorial-basics/markdown-features":{"id":"tutorial-basics/markdown-features","title":"Markdown Features","description":"Docusaurus supports Markdown and a few additional features."},"tutorial-extras/manage-docs-versions":{"id":"tutorial-extras/manage-docs-versions","title":"Manage Docs Versions","description":"Docusaurus can manage multiple versions of your docs."},"tutorial-extras/translate-your-site":{"id":"tutorial-extras/translate-your-site","title":"Translate your site","description":"Let\'s translate docs/intro.md to French."}}}}')}}]);