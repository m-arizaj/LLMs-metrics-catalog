---
id: edition-metrics
title: Edition Metrics (Patch Edit Size / Scope)
sidebar_label: Edition Metrics
---

## Introduction

**Edition Metrics** are a category of descriptive statistics used in software engineering benchmarks like **SWE-bench**  to characterize and evaluate the code patches generated by Large Language Models.

Instead of a single performance score, these metrics quantify the **size, scope, and complexity** of a generated patch (the proposed solution to a programming issue). They are used to compare the model-generated patches against the "gold" (human-written reference) patches.

These metrics are grouped into two main categories: **Patch Edit Size** (lines) and **Structural Scope** (files/functions).

## 1. Patch Edit Size (Lines)

### Definition

This category measures the *length* of the code patch by counting the number of lines affected. It is defined by three related metrics:

* **Lines Added:** Refers to the number of new lines that are introduced by the patch.
* **Lines Removed:** Refers to the number of pre-existing lines taken out by the solution.
* **Lines Edited / Total Lines:** The sum of all lines added and removed to create the patch.

### Purpose

The primary purpose is to quantify the size of a solution. In the **SWE-bench** benchmark, these metrics revealed that LLMs "tend to generate shorter, simpler edits". Model-generated patches that applied correctly were, on average, less than half the total length of the gold reference patches.

## 2. Structural Scope (Files / Functions)

### Definition

This category measures the *breadth* and *complexity* of a patch by quantifying how many distinct structural components of the codebase are modified.

* **Files Edited:** The number of unique files that the patch makes changes to.
* **Functions Edited:** The number of unique functions or methods that the patch modifies.

### Purpose

The purpose is to measure a model's ability to handle complex tasks that are not self-contained. Resolving issues in **SWE-bench** "frequently requires understanding and coordinating changes across multiple functions, classes, and even files simultaneously".

For instance, the reference solutions in SWE-bench edit an average of **1.7 files** and **3.0 functions** per task.

## 3. Comparative Summary

| Metric | Category | Measures... |
| :--- | :--- | :--- |
| **Lines Added** | Patch Edit Size | The number of new lines introduced by the patch. |
| **Lines Removed** | Patch Edit Size | The number of pre-existing lines taken out by the patch. |
| **Lines Edited** | Patch Edit Size | The total lines added and removed; the overall length of the patch. |
| **Files Edited** | Structural Scope | The number of distinct files modified to solve the issue. |
| **Functions Edited** | Structural Scope | The number of distinct functions modified to solve the issue. |

## Domains

* Software Engineering
* Program Repair

## Benchmarks

* **SWE-bench**

## Key References

* Jimenez, C. E., Yang, J., Wettig, A., et al. (2024). *SWE-BENCH: CAN LANGUAGE MODELS RESOLVE REAL-WORLD GITHUB ISSUES?* [https://doi.org/10.48550/arXiv.2310.06770](https://doi.org/10.48550/arXiv.2310.06770)
* (Excel Data: Paper 14)
