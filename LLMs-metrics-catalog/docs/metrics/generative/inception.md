---
id: inception
title: Inception Score (IS)
sidebar_label: Inception Score (IS)
---
import { ReferencesIndex } from '@site/src/components/References';

## Definition

The **Inception Score (IS)** is a well-known metric used to evaluate the quality of images generated by generative models, particularly Generative Adversarial Networks (GANs). Introduced by Salimans et al. (2016) , the metric is designed to measure two desirable properties simultaneously:

1.  **Fidelity (Image Quality):** Images should be sharp, clear, and look like a specific object. The IS measures this by checking if the conditional label distribution $p(y|x)$ (the probability of labels given a generated image $x$) has **low entropy**. A low entropy score means the Inception-V3 model is confident the image belongs to one specific class.
2.  **Diversity:** The model should generate a wide variety of images covering all classes. The IS measures this by checking if the marginal distribution $p(y)$ (the average distribution of labels over all generated images) has **high entropy**.

The score is maximized when both conditions are met: generated images are individually distinct (low entropy) but collectively cover many classes (high entropy).

***

## Formula (General Idea)

The Inception Score is calculated as the exponential of the Kullback-Leibler (KL) divergence between the conditional label distribution $p(y|x_i^g)$ and the marginal label distribution $p(y)$ for a set of $n$ generated images $\{x_i^g\}$.

$$
IS(\{x_{i}^{g}\}_{i=1}^{n})= \exp \left( \frac{1}{n}\sum_{i=1}^{n} D_{KL}(p(y|x_{i}^{g}) \ || \ p(y)) \right)
$$

Where:
* $p(y|x_i^g)$ is the label probability distribution for a single generated image $x_i^g$, as predicted by the Inception-V3 network.
* $p(y)$ is the marginal distribution, calculated by averaging the label probabilities over all generated samples.
* $D_{KL}$ is the KL divergence, which measures the difference between the two distributions.

***

## Purpose

The IS is a ranking metric used to assess the "overall quality" of generative models. It attempts to group both image fidelity and sample diversity into a single numerical score, which was historically used to rank models against each other.

***

## Domains

* Generative Models
* Image Generation
* Ranking / Overall Quality Evaluation

***

## Benchmarks

* The Inception Score is **intrinsically tied to the Inception-V3 classification model**. It cannot be computed with other network architectures.
* It is used to evaluate models trained on various image datasets, such as CIFAR-10 and ImageNet.

***

## Advantages

* **Combined Metric:** It was one of the first widely adopted metrics to attempt to quantify both fidelity and diversity in a single score.
* **Automated:** It provides an automated, quantitative measure of performance without requiring human evaluation.

***

## Limitations

* **Inception-V3 Dependency:** The metric is *exclusively* dependent on the Inception-V3 model. This model has several known flaws:
    * It is biased towards the 1,000 classes of ImageNet and is "agnostic to features unrelated" to them.
    * ImageNet classifiers, in general, are known to be biased towards **texture over shape**.
* **Poor Human Correlation:** The Inception Score (IS) does not correlate well with human evaluations of image realism, particularly on complex, high-resolution datasets.
* **Sensitivity:** The score can be "gamed" by models that learn to generate one high-quality, high-confidence image for each of the 1,000 ImageNet classes, even if those are the *only* images the model can produce.

***

## Key References

* Salimans, T., Goodfellow, I., Zaremba, W., Cheung, V., Radford, A., & Chen, X. (2016). *Improved techniques for training GANs*. In *Advances in Neural Information Processing Systems, volume 29*. https://doi.org/10.48550/arXiv.1606.03498

### Additional References in Dataset 
- <ReferencesIndex ids={['67']}Â />
